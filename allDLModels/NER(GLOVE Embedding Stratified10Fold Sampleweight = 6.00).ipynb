{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras.backend as K\n",
    "from tensorflow.python.keras.backend import get_session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import imblearn\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence</th>\n",
       "      <th>Word</th>\n",
       "      <th>Tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sentence: 1</td>\n",
       "      <td>RECORD</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sentence: 2</td>\n",
       "      <td>OC</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>AM</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>gallstone</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>pancreatitis</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>949802</th>\n",
       "      <td>NaN</td>\n",
       "      <td>M.D.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>949803</th>\n",
       "      <td>Sentence: 132094</td>\n",
       "      <td>END</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>949804</th>\n",
       "      <td>NaN</td>\n",
       "      <td>OF</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>949805</th>\n",
       "      <td>NaN</td>\n",
       "      <td>DISCHARGE</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>949806</th>\n",
       "      <td>NaN</td>\n",
       "      <td>ORDERS</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>949807 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                Sentence          Word  Tag\n",
       "0            Sentence: 1        RECORD    0\n",
       "1            Sentence: 2            OC    0\n",
       "2                    NaN            AM    0\n",
       "3                    NaN     gallstone    0\n",
       "4                    NaN  pancreatitis    0\n",
       "...                  ...           ...  ...\n",
       "949802               NaN          M.D.    0\n",
       "949803  Sentence: 132094           END    0\n",
       "949804               NaN            OF    0\n",
       "949805               NaN     DISCHARGE    0\n",
       "949806               NaN        ORDERS    0\n",
       "\n",
       "[949807 rows x 3 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('./OUTPUT/dataset.csv', encoding= 'unicode_escape')\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Groupby"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-4-73aff18756c8>:2: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
      "  data_group = data_fillna.groupby(['Sentence'],as_index=False\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence</th>\n",
       "      <th>Word</th>\n",
       "      <th>Tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sentence: 1</td>\n",
       "      <td>[RECORD]</td>\n",
       "      <td>[0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sentence: 10</td>\n",
       "      <td>[WILL, D/C, ORDER, BE, USED, AS, THE, D/C, SUM...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Sentence: 100</td>\n",
       "      <td>[prandial, N/V/severe, upper, abdominal, pain....</td>\n",
       "      <td>[0, 1, 0, 1, 1, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Sentence: 1000</td>\n",
       "      <td>[normal, limits., Cardiac, catheterization, da...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sentence: 10000</td>\n",
       "      <td>[year, old, Black, female, with, significant, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132089</th>\n",
       "      <td>Sentence: 99995</td>\n",
       "      <td>[Height, foot, inch, and, weight, kg., Tempera...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132090</th>\n",
       "      <td>Sentence: 99996</td>\n",
       "      <td>[degrees, heart, rate, and, sinus, blood, pres...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132091</th>\n",
       "      <td>Sentence: 99997</td>\n",
       "      <td>[blood, pressure, left, arm, and, oxygen, satu...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132092</th>\n",
       "      <td>Sentence: 99998</td>\n",
       "      <td>[No, carotid, bruits, regular, rate, and, rhyt...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132093</th>\n",
       "      <td>Sentence: 99999</td>\n",
       "      <td>[systolic, murmur, along, the, right, upper, s...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>132094 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               Sentence                                               Word  \\\n",
       "0           Sentence: 1                                           [RECORD]   \n",
       "1          Sentence: 10  [WILL, D/C, ORDER, BE, USED, AS, THE, D/C, SUM...   \n",
       "2         Sentence: 100  [prandial, N/V/severe, upper, abdominal, pain....   \n",
       "3        Sentence: 1000  [normal, limits., Cardiac, catheterization, da...   \n",
       "4       Sentence: 10000  [year, old, Black, female, with, significant, ...   \n",
       "...                 ...                                                ...   \n",
       "132089  Sentence: 99995  [Height, foot, inch, and, weight, kg., Tempera...   \n",
       "132090  Sentence: 99996  [degrees, heart, rate, and, sinus, blood, pres...   \n",
       "132091  Sentence: 99997  [blood, pressure, left, arm, and, oxygen, satu...   \n",
       "132092  Sentence: 99998  [No, carotid, bruits, regular, rate, and, rhyt...   \n",
       "132093  Sentence: 99999  [systolic, murmur, along, the, right, upper, s...   \n",
       "\n",
       "                                   Tag  \n",
       "0                                  [0]  \n",
       "1       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]  \n",
       "2          [0, 1, 0, 1, 1, 0, 0, 0, 0]  \n",
       "3             [0, 0, 0, 0, 0, 0, 0, 0]  \n",
       "4       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]  \n",
       "...                                ...  \n",
       "132089           [0, 0, 0, 0, 0, 0, 0]  \n",
       "132090     [0, 0, 0, 0, 0, 0, 0, 0, 0]  \n",
       "132091           [0, 0, 0, 0, 0, 0, 0]  \n",
       "132092     [0, 0, 0, 0, 0, 0, 0, 0, 0]  \n",
       "132093     [0, 0, 0, 0, 0, 0, 0, 0, 0]  \n",
       "\n",
       "[132094 rows x 3 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_fillna = data.fillna(method='ffill', axis=0)\n",
    "data_group = data_fillna.groupby(['Sentence'],as_index=False\n",
    "                                )['Word', 'Tag'].agg(lambda x: list(x))\n",
    "\n",
    "#data_fillna\n",
    "data_group"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = data_group['Word'].tolist()  \n",
    "labels = data_group['Tag'].tolist()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 34275 unique tokens.\n",
      "[[  115     0     0 ...     0     0     0]\n",
      " [   44   145   106 ...     0     0     0]\n",
      " [ 6315 15212   259 ...     0     0     0]\n",
      " ...\n",
      " [   42    70    33 ...     0     0     0]\n",
      " [   13   421  1398 ...     0     0     0]\n",
      " [  327   561  1373 ...     0     0     0]]\n",
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 1 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n",
      "Shape of data tensor: (132094, 49)\n",
      "Shape of label tensor: (132094, 49)\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(texts)\n",
    "sequences = tokenizer.texts_to_sequences(texts)\n",
    "\n",
    "word_index = tokenizer.word_index\n",
    "print('Found %s unique tokens.' % len(word_index))\n",
    "\n",
    "pad_tokens = pad_sequences(sequences, maxlen=49, dtype='int32', padding='post', value= 0)\n",
    "print(pad_tokens)\n",
    "pad_tags = pad_sequences(labels, maxlen=49, dtype='int32', padding='post', value= 0)\n",
    "train_tokens, test_tokens, train_tags, test_tags = train_test_split(pad_tokens, pad_tags, test_size=0.3, train_size=0.7, random_state=2020)\n",
    "print(pad_tags)\n",
    "print('Shape of data tensor:', pad_tokens.shape)\n",
    "print('Shape of label tensor:', pad_tags.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GLOVE Embedding Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 400000 word vectors.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "embeddings_index = {}\n",
    "f = open(os.path.join(r'./GLOVE', 'glove.6B.300d.txt'), encoding=\"utf8\")\n",
    "for line in f:\n",
    "    values = line.split()\n",
    "    word = values[0]\n",
    "    coefs = np.asarray(values[1:], dtype='float32')\n",
    "    embeddings_index[word] = coefs\n",
    "f.close()\n",
    "\n",
    "print('Found %s word vectors.' % len(embeddings_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_matrix = np.zeros((len(word_index) + 1, 300))\n",
    "for word, i in word_index.items():\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        # words not found in embedding index will be all-zeros.\n",
    "        embedding_matrix[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Embedding\n",
    "\n",
    "embedding_layer = Embedding(len(word_index) + 1,\n",
    "                            300,\n",
    "                            weights=[embedding_matrix],\n",
    "                            input_length=49,\n",
    "                            trainable=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import Sequential, Model, Input\n",
    "from tensorflow.keras.layers import LSTM, Embedding, Dense, TimeDistributed, Dropout, Bidirectional\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from keras import backend as K\n",
    "import keras as keras\n",
    "from keras.datasets import mnist\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from keras import metrics\n",
    "from sklearn.utils import class_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recall_m(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    recall = true_positives / (possible_positives + K.epsilon())\n",
    "    return recall\n",
    "\n",
    "def precision_m(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\n",
    "    return precision\n",
    "\n",
    "def f1_m(y_true, y_pred):\n",
    "    precision = precision_m(y_true, y_pred)\n",
    "    recall = recall_m(y_true, y_pred)\n",
    "    return 2*((precision*recall)/(precision+recall+K.epsilon()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bilstm_lstm_model():\n",
    "    model = Sequential()\n",
    "\n",
    "    # Add Embedding layer\n",
    "    model.add(embedding_layer)\n",
    "    # Add bidirectional LSTM\n",
    "    model.add(Bidirectional(LSTM(units=32, return_sequences=True, dropout=0.5, recurrent_dropout=0.5), merge_mode = 'concat'))\n",
    "\n",
    "    \n",
    "    # Add LSTM\n",
    "    model.add(LSTM(units=32, return_sequences=True, dropout=0.5, recurrent_dropout=0.5))\n",
    "    model.add(LSTM(units=32, return_sequences=True, dropout=0.5, recurrent_dropout=0.5))\n",
    "    # Add timeDistributed Layer\n",
    "    model.add(TimeDistributed(Dense(1, activation=\"sigmoid\")))\n",
    "    \n",
    "    #Optimiser \n",
    "    adam = tf.keras.optimizers.Adam(learning_rate=0.001, beta_1=0.9, beta_2=0.999)\n",
    "    \n",
    "    # Compile model\n",
    "    model.compile(loss='binary_crossentropy', sample_weight_mode=\"temporal\", optimizer='adam', metrics=['acc', precision_m, recall_m, f1_m])\n",
    "    model.summary()\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jonat\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:666: UserWarning: The least populated class in y has only 3 members, which is less than n_splits=10.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on fold 1/10..........\n",
      "1: started assigning sample weights\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jonat\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:70: FutureWarning: Pass classes=[0 1], y=[0 0 0 ... 0 0 0] as keyword args. From version 1.0 (renaming of 0.25) passing these as positional arguments will result in an error\n",
      "  warnings.warn(f\"Pass {args_msg} as keyword args. From version \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1: finished assigning sample weights\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 49, 300)           10282800  \n",
      "                                                                 \n",
      " bidirectional (Bidirectiona  (None, 49, 64)           85248     \n",
      " l)                                                              \n",
      "                                                                 \n",
      " lstm_1 (LSTM)               (None, 49, 32)            12416     \n",
      "                                                                 \n",
      " lstm_2 (LSTM)               (None, 49, 32)            8320      \n",
      "                                                                 \n",
      " time_distributed (TimeDistr  (None, 49, 1)            33        \n",
      " ibuted)                                                         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 10,388,817\n",
      "Trainable params: 10,388,817\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "1858/1858 [==============================] - 554s 286ms/step - loss: 0.0173 - acc: 0.9968 - precision_m: 0.5288 - recall_m: 0.3712 - f1_m: 0.4094\n",
      "Epoch 2/20\n",
      "1858/1858 [==============================] - 534s 288ms/step - loss: 0.0063 - acc: 0.9982 - precision_m: 0.7587 - recall_m: 0.6938 - f1_m: 0.7060\n",
      "Epoch 3/20\n",
      "1858/1858 [==============================] - 546s 294ms/step - loss: 0.0052 - acc: 0.9984 - precision_m: 0.8012 - recall_m: 0.7375 - f1_m: 0.7505\n",
      "Epoch 4/20\n",
      "1858/1858 [==============================] - 545s 293ms/step - loss: 0.0045 - acc: 0.9986 - precision_m: 0.8211 - recall_m: 0.7707 - f1_m: 0.7802\n",
      "Epoch 5/20\n",
      "1858/1858 [==============================] - 525s 283ms/step - loss: 0.0041 - acc: 0.9988 - precision_m: 0.8387 - recall_m: 0.7910 - f1_m: 0.8002\n",
      "Epoch 6/20\n",
      "1858/1858 [==============================] - 525s 283ms/step - loss: 0.0037 - acc: 0.9988 - precision_m: 0.8455 - recall_m: 0.7977 - f1_m: 0.8089\n",
      "Epoch 7/20\n",
      "1858/1858 [==============================] - 531s 286ms/step - loss: 0.0034 - acc: 0.9989 - precision_m: 0.8650 - recall_m: 0.8204 - f1_m: 0.8310\n",
      "Epoch 8/20\n",
      "1858/1858 [==============================] - 533s 287ms/step - loss: 0.0032 - acc: 0.9990 - precision_m: 0.8702 - recall_m: 0.8294 - f1_m: 0.8391\n",
      "Epoch 9/20\n",
      "1858/1858 [==============================] - 533s 287ms/step - loss: 0.0030 - acc: 0.9991 - precision_m: 0.8810 - recall_m: 0.8447 - f1_m: 0.8522\n",
      "Epoch 10/20\n",
      "1858/1858 [==============================] - 535s 288ms/step - loss: 0.0028 - acc: 0.9991 - precision_m: 0.8800 - recall_m: 0.8465 - f1_m: 0.8538\n",
      "Epoch 11/20\n",
      "1858/1858 [==============================] - 535s 288ms/step - loss: 0.0027 - acc: 0.9992 - precision_m: 0.8895 - recall_m: 0.8633 - f1_m: 0.8669\n",
      "Epoch 12/20\n",
      "1858/1858 [==============================] - 536s 289ms/step - loss: 0.0025 - acc: 0.9992 - precision_m: 0.8907 - recall_m: 0.8649 - f1_m: 0.8687\n",
      "Epoch 13/20\n",
      "1858/1858 [==============================] - 538s 289ms/step - loss: 0.0024 - acc: 0.9992 - precision_m: 0.8960 - recall_m: 0.8750 - f1_m: 0.8770\n",
      "Epoch 14/20\n",
      "1858/1858 [==============================] - 539s 290ms/step - loss: 0.0023 - acc: 0.9993 - precision_m: 0.9002 - recall_m: 0.8734 - f1_m: 0.8785\n",
      "Epoch 15/20\n",
      "1858/1858 [==============================] - 540s 290ms/step - loss: 0.0023 - acc: 0.9993 - precision_m: 0.9034 - recall_m: 0.8868 - f1_m: 0.8873\n",
      "Epoch 16/20\n",
      "1858/1858 [==============================] - 539s 290ms/step - loss: 0.0022 - acc: 0.9993 - precision_m: 0.9038 - recall_m: 0.8853 - f1_m: 0.8874\n",
      "Epoch 17/20\n",
      "1858/1858 [==============================] - 537s 289ms/step - loss: 0.0021 - acc: 0.9993 - precision_m: 0.9133 - recall_m: 0.8937 - f1_m: 0.8967\n",
      "Epoch 18/20\n",
      "1858/1858 [==============================] - 542s 292ms/step - loss: 0.0021 - acc: 0.9994 - precision_m: 0.9123 - recall_m: 0.8914 - f1_m: 0.8949\n",
      "Epoch 19/20\n",
      "1858/1858 [==============================] - 540s 291ms/step - loss: 0.0020 - acc: 0.9994 - precision_m: 0.9155 - recall_m: 0.9006 - f1_m: 0.9017\n",
      "Epoch 20/20\n",
      "1858/1858 [==============================] - 539s 290ms/step - loss: 0.0019 - acc: 0.9994 - precision_m: 0.9117 - recall_m: 0.9036 - f1_m: 0.9013\n",
      "Score for fold 1: loss of 0.008731890469789505; acc of 0.9979530572891235; precision_m of 0.6661249399185181; recall_m of 0.6925951838493347; f1_m of 0.6524550914764404 %\n",
      "Training on fold 2/10..........\n",
      "2: started assigning sample weights\n",
      "2: finished assigning sample weights\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 49, 300)           10282800  \n",
      "                                                                 \n",
      " bidirectional_1 (Bidirectio  (None, 49, 64)           85248     \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " lstm_4 (LSTM)               (None, 49, 32)            12416     \n",
      "                                                                 \n",
      " lstm_5 (LSTM)               (None, 49, 32)            8320      \n",
      "                                                                 \n",
      " time_distributed_1 (TimeDis  (None, 49, 1)            33        \n",
      " tributed)                                                       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 10,388,817\n",
      "Trainable params: 10,388,817\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "1858/1858 [==============================] - 521s 271ms/step - loss: 0.0125 - acc: 0.9975 - precision_m: 0.6674 - recall_m: 0.5231 - f1_m: 0.5561\n",
      "Epoch 2/20\n",
      "1858/1858 [==============================] - 505s 272ms/step - loss: 0.0042 - acc: 0.9987 - precision_m: 0.8298 - recall_m: 0.8099 - f1_m: 0.8064\n",
      "Epoch 3/20\n",
      "1858/1858 [==============================] - 484s 261ms/step - loss: 0.0033 - acc: 0.9990 - precision_m: 0.8615 - recall_m: 0.8457 - f1_m: 0.8432\n",
      "Epoch 4/20\n",
      "1858/1858 [==============================] - 532s 287ms/step - loss: 0.0029 - acc: 0.9991 - precision_m: 0.8814 - recall_m: 0.8576 - f1_m: 0.8600\n",
      "Epoch 5/20\n",
      "1858/1858 [==============================] - 533s 287ms/step - loss: 0.0027 - acc: 0.9992 - precision_m: 0.8896 - recall_m: 0.8689 - f1_m: 0.8708\n",
      "Epoch 6/20\n",
      "1858/1858 [==============================] - 533s 287ms/step - loss: 0.0025 - acc: 0.9993 - precision_m: 0.8988 - recall_m: 0.8784 - f1_m: 0.8813\n",
      "Epoch 7/20\n",
      "1858/1858 [==============================] - 533s 287ms/step - loss: 0.0023 - acc: 0.9993 - precision_m: 0.9058 - recall_m: 0.8875 - f1_m: 0.8897\n",
      "Epoch 8/20\n",
      "1858/1858 [==============================] - 533s 287ms/step - loss: 0.0022 - acc: 0.9993 - precision_m: 0.9074 - recall_m: 0.8919 - f1_m: 0.8928\n",
      "Epoch 9/20\n",
      "1858/1858 [==============================] - 532s 286ms/step - loss: 0.0020 - acc: 0.9994 - precision_m: 0.9167 - recall_m: 0.8941 - f1_m: 0.8986\n",
      "Epoch 10/20\n",
      "1858/1858 [==============================] - 532s 286ms/step - loss: 0.0020 - acc: 0.9994 - precision_m: 0.9172 - recall_m: 0.9025 - f1_m: 0.9035\n",
      "Epoch 11/20\n",
      "1858/1858 [==============================] - 532s 287ms/step - loss: 0.0019 - acc: 0.9994 - precision_m: 0.9192 - recall_m: 0.9076 - f1_m: 0.9071\n",
      "Epoch 12/20\n",
      "1858/1858 [==============================] - 532s 286ms/step - loss: 0.0018 - acc: 0.9994 - precision_m: 0.9211 - recall_m: 0.9078 - f1_m: 0.9082\n",
      "Epoch 13/20\n",
      "1858/1858 [==============================] - 532s 286ms/step - loss: 0.0018 - acc: 0.9994 - precision_m: 0.9209 - recall_m: 0.9068 - f1_m: 0.9083\n",
      "Epoch 14/20\n",
      "1858/1858 [==============================] - 533s 287ms/step - loss: 0.0017 - acc: 0.9995 - precision_m: 0.9235 - recall_m: 0.9103 - f1_m: 0.9112\n",
      "Epoch 15/20\n",
      "1858/1858 [==============================] - 532s 287ms/step - loss: 0.0017 - acc: 0.9995 - precision_m: 0.9263 - recall_m: 0.9130 - f1_m: 0.9139\n",
      "Epoch 16/20\n",
      "1858/1858 [==============================] - 531s 286ms/step - loss: 0.0016 - acc: 0.9995 - precision_m: 0.9296 - recall_m: 0.9200 - f1_m: 0.9198\n",
      "Epoch 17/20\n",
      "1858/1858 [==============================] - 533s 287ms/step - loss: 0.0016 - acc: 0.9995 - precision_m: 0.9314 - recall_m: 0.9228 - f1_m: 0.9222\n",
      "Epoch 18/20\n",
      "1858/1858 [==============================] - 532s 286ms/step - loss: 0.0015 - acc: 0.9995 - precision_m: 0.9301 - recall_m: 0.9209 - f1_m: 0.9210\n",
      "Epoch 19/20\n",
      "1858/1858 [==============================] - 533s 287ms/step - loss: 0.0015 - acc: 0.9995 - precision_m: 0.9255 - recall_m: 0.9211 - f1_m: 0.9182\n",
      "Epoch 20/20\n",
      "1858/1858 [==============================] - 538s 290ms/step - loss: 0.0015 - acc: 0.9995 - precision_m: 0.9358 - recall_m: 0.9234 - f1_m: 0.9243\n",
      "Score for fold 2: loss of 0.004619639832526445; acc of 0.9988755583763123; precision_m of 0.7796337008476257; recall_m of 0.7546238303184509; f1_m of 0.7495155334472656 %\n",
      "Training on fold 3/10..........\n",
      "3: started assigning sample weights\n",
      "3: finished assigning sample weights\n",
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 49, 300)           10282800  \n",
      "                                                                 \n",
      " bidirectional_2 (Bidirectio  (None, 49, 64)           85248     \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " lstm_7 (LSTM)               (None, 49, 32)            12416     \n",
      "                                                                 \n",
      " lstm_8 (LSTM)               (None, 49, 32)            8320      \n",
      "                                                                 \n",
      " time_distributed_2 (TimeDis  (None, 49, 1)            33        \n",
      " tributed)                                                       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 10,388,817\n",
      "Trainable params: 10,388,817\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "1858/1858 [==============================] - 529s 275ms/step - loss: 0.0122 - acc: 0.9973 - precision_m: 0.6711 - recall_m: 0.5311 - f1_m: 0.5654\n",
      "Epoch 2/20\n",
      "1858/1858 [==============================] - 511s 275ms/step - loss: 0.0037 - acc: 0.9989 - precision_m: 0.8480 - recall_m: 0.8352 - f1_m: 0.8300\n",
      "Epoch 3/20\n",
      "1858/1858 [==============================] - 487s 262ms/step - loss: 0.0029 - acc: 0.9991 - precision_m: 0.8816 - recall_m: 0.8659 - f1_m: 0.8644\n",
      "Epoch 4/20\n",
      "1858/1858 [==============================] - 438s 236ms/step - loss: 0.0025 - acc: 0.9992 - precision_m: 0.8942 - recall_m: 0.8734 - f1_m: 0.8747\n",
      "Epoch 5/20\n",
      "1858/1858 [==============================] - 447s 240ms/step - loss: 0.0022 - acc: 0.9993 - precision_m: 0.9098 - recall_m: 0.8902 - f1_m: 0.8935\n",
      "Epoch 6/20\n",
      "1858/1858 [==============================] - 447s 241ms/step - loss: 0.0020 - acc: 0.9994 - precision_m: 0.9127 - recall_m: 0.8954 - f1_m: 0.8972\n",
      "Epoch 7/20\n",
      "1858/1858 [==============================] - 447s 241ms/step - loss: 0.0019 - acc: 0.9994 - precision_m: 0.9178 - recall_m: 0.9071 - f1_m: 0.9067\n",
      "Epoch 8/20\n",
      "1858/1858 [==============================] - 447s 241ms/step - loss: 0.0018 - acc: 0.9994 - precision_m: 0.9219 - recall_m: 0.9085 - f1_m: 0.9085\n",
      "Epoch 9/20\n",
      "1858/1858 [==============================] - 447s 241ms/step - loss: 0.0017 - acc: 0.9995 - precision_m: 0.9274 - recall_m: 0.9132 - f1_m: 0.9149\n",
      "Epoch 10/20\n",
      "1858/1858 [==============================] - 447s 241ms/step - loss: 0.0016 - acc: 0.9995 - precision_m: 0.9289 - recall_m: 0.9144 - f1_m: 0.9162\n",
      "Epoch 11/20\n",
      "1858/1858 [==============================] - 446s 240ms/step - loss: 0.0016 - acc: 0.9995 - precision_m: 0.9287 - recall_m: 0.9169 - f1_m: 0.9174\n",
      "Epoch 12/20\n",
      "1858/1858 [==============================] - 447s 241ms/step - loss: 0.0016 - acc: 0.9995 - precision_m: 0.9298 - recall_m: 0.9184 - f1_m: 0.9188\n",
      "Epoch 13/20\n",
      "1858/1858 [==============================] - 448s 241ms/step - loss: 0.0015 - acc: 0.9995 - precision_m: 0.9308 - recall_m: 0.9232 - f1_m: 0.9221\n",
      "Epoch 14/20\n",
      "1858/1858 [==============================] - 447s 241ms/step - loss: 0.0015 - acc: 0.9995 - precision_m: 0.9362 - recall_m: 0.9215 - f1_m: 0.9235\n",
      "Epoch 15/20\n",
      "1858/1858 [==============================] - 447s 241ms/step - loss: 0.0015 - acc: 0.9995 - precision_m: 0.9314 - recall_m: 0.9240 - f1_m: 0.9231\n",
      "Epoch 16/20\n",
      "1858/1858 [==============================] - 448s 241ms/step - loss: 0.0014 - acc: 0.9995 - precision_m: 0.9368 - recall_m: 0.9276 - f1_m: 0.9275\n",
      "Epoch 17/20\n",
      "1858/1858 [==============================] - 447s 241ms/step - loss: 0.0014 - acc: 0.9996 - precision_m: 0.9361 - recall_m: 0.9257 - f1_m: 0.9262\n",
      "Epoch 18/20\n",
      "1858/1858 [==============================] - 447s 240ms/step - loss: 0.0013 - acc: 0.9996 - precision_m: 0.9386 - recall_m: 0.9326 - f1_m: 0.9311\n",
      "Epoch 19/20\n",
      "1858/1858 [==============================] - 446s 240ms/step - loss: 0.0014 - acc: 0.9996 - precision_m: 0.9388 - recall_m: 0.9337 - f1_m: 0.9326\n",
      "Epoch 20/20\n",
      "1858/1858 [==============================] - 447s 240ms/step - loss: 0.0013 - acc: 0.9996 - precision_m: 0.9373 - recall_m: 0.9314 - f1_m: 0.9300\n",
      "Score for fold 3: loss of 0.0038018280174583197; acc of 0.9990332126617432; precision_m of 0.7725365161895752; recall_m of 0.7495949268341064; f1_m of 0.7432667016983032 %\n",
      "Training on fold 4/10..........\n",
      "4: started assigning sample weights\n",
      "4: finished assigning sample weights\n",
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 49, 300)           10282800  \n",
      "                                                                 \n",
      " bidirectional_3 (Bidirectio  (None, 49, 64)           85248     \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " lstm_10 (LSTM)              (None, 49, 32)            12416     \n",
      "                                                                 \n",
      " lstm_11 (LSTM)              (None, 49, 32)            8320      \n",
      "                                                                 \n",
      " time_distributed_3 (TimeDis  (None, 49, 1)            33        \n",
      " tributed)                                                       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 10,388,817\n",
      "Trainable params: 10,388,817\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "1858/1858 [==============================] - 579s 304ms/step - loss: 0.0119 - acc: 0.9974 - precision_m: 0.6617 - recall_m: 0.5391 - f1_m: 0.5664\n",
      "Epoch 2/20\n",
      "1858/1858 [==============================] - 572s 308ms/step - loss: 0.0035 - acc: 0.9989 - precision_m: 0.8485 - recall_m: 0.8427 - f1_m: 0.8345\n",
      "Epoch 3/20\n",
      "1858/1858 [==============================] - 572s 308ms/step - loss: 0.0026 - acc: 0.9992 - precision_m: 0.8829 - recall_m: 0.8739 - f1_m: 0.8699\n",
      "Epoch 4/20\n",
      "1858/1858 [==============================] - 572s 308ms/step - loss: 0.0022 - acc: 0.9993 - precision_m: 0.9041 - recall_m: 0.8949 - f1_m: 0.8931\n",
      "Epoch 5/20\n",
      "1858/1858 [==============================] - 573s 308ms/step - loss: 0.0020 - acc: 0.9994 - precision_m: 0.9177 - recall_m: 0.9062 - f1_m: 0.9060\n",
      "Epoch 6/20\n",
      "1858/1858 [==============================] - 573s 308ms/step - loss: 0.0019 - acc: 0.9994 - precision_m: 0.9136 - recall_m: 0.9030 - f1_m: 0.9024\n",
      "Epoch 7/20\n",
      "1858/1858 [==============================] - 573s 309ms/step - loss: 0.0018 - acc: 0.9994 - precision_m: 0.9185 - recall_m: 0.9139 - f1_m: 0.9104\n",
      "Epoch 8/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1858/1858 [==============================] - 573s 308ms/step - loss: 0.0017 - acc: 0.9995 - precision_m: 0.9252 - recall_m: 0.9151 - f1_m: 0.9146\n",
      "Epoch 9/20\n",
      "1858/1858 [==============================] - 574s 309ms/step - loss: 0.0017 - acc: 0.9995 - precision_m: 0.9260 - recall_m: 0.9197 - f1_m: 0.9179\n",
      "Epoch 10/20\n",
      "1858/1858 [==============================] - 574s 309ms/step - loss: 0.0015 - acc: 0.9995 - precision_m: 0.9330 - recall_m: 0.9269 - f1_m: 0.9254\n",
      "Epoch 11/20\n",
      "1858/1858 [==============================] - 573s 308ms/step - loss: 0.0015 - acc: 0.9995 - precision_m: 0.9293 - recall_m: 0.9200 - f1_m: 0.9189\n",
      "Epoch 12/20\n",
      "1858/1858 [==============================] - 573s 308ms/step - loss: 0.0015 - acc: 0.9995 - precision_m: 0.9304 - recall_m: 0.9266 - f1_m: 0.9232\n",
      "Epoch 13/20\n",
      "1858/1858 [==============================] - 571s 308ms/step - loss: 0.0014 - acc: 0.9995 - precision_m: 0.9286 - recall_m: 0.9202 - f1_m: 0.9196\n",
      "Epoch 14/20\n",
      "1858/1858 [==============================] - 577s 310ms/step - loss: 0.0014 - acc: 0.9995 - precision_m: 0.9357 - recall_m: 0.9304 - f1_m: 0.9285\n",
      "Epoch 15/20\n",
      "1858/1858 [==============================] - 599s 323ms/step - loss: 0.0014 - acc: 0.9996 - precision_m: 0.9382 - recall_m: 0.9316 - f1_m: 0.9302\n",
      "Epoch 16/20\n",
      "1858/1858 [==============================] - 599s 322ms/step - loss: 0.0014 - acc: 0.9996 - precision_m: 0.9340 - recall_m: 0.9310 - f1_m: 0.9279\n",
      "Epoch 17/20\n",
      "1858/1858 [==============================] - 598s 322ms/step - loss: 0.0013 - acc: 0.9996 - precision_m: 0.9383 - recall_m: 0.9296 - f1_m: 0.9295\n",
      "Epoch 18/20\n",
      "1858/1858 [==============================] - 597s 321ms/step - loss: 0.0013 - acc: 0.9996 - precision_m: 0.9401 - recall_m: 0.9340 - f1_m: 0.9332\n",
      "Epoch 19/20\n",
      "1858/1858 [==============================] - 597s 321ms/step - loss: 0.0013 - acc: 0.9996 - precision_m: 0.9371 - recall_m: 0.9304 - f1_m: 0.9293\n",
      "Epoch 20/20\n",
      "1858/1858 [==============================] - 598s 322ms/step - loss: 0.0013 - acc: 0.9996 - precision_m: 0.9417 - recall_m: 0.9335 - f1_m: 0.9332\n",
      "Score for fold 4: loss of 0.0030736096668988466; acc of 0.9992074966430664; precision_m of 0.8228378295898438; recall_m of 0.7872909903526306; f1_m of 0.7916290760040283 %\n",
      "Training on fold 5/10..........\n",
      "5: started assigning sample weights\n",
      "5: finished assigning sample weights\n",
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 49, 300)           10282800  \n",
      "                                                                 \n",
      " bidirectional_4 (Bidirectio  (None, 49, 64)           85248     \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " lstm_13 (LSTM)              (None, 49, 32)            12416     \n",
      "                                                                 \n",
      " lstm_14 (LSTM)              (None, 49, 32)            8320      \n",
      "                                                                 \n",
      " time_distributed_4 (TimeDis  (None, 49, 1)            33        \n",
      " tributed)                                                       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 10,388,817\n",
      "Trainable params: 10,388,817\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "1858/1858 [==============================] - 556s 291ms/step - loss: 0.0117 - acc: 0.9975 - precision_m: 0.6658 - recall_m: 0.5114 - f1_m: 0.5480\n",
      "Epoch 2/20\n",
      "1858/1858 [==============================] - 539s 290ms/step - loss: 0.0033 - acc: 0.9990 - precision_m: 0.8625 - recall_m: 0.8514 - f1_m: 0.8467\n",
      "Epoch 3/20\n",
      "1858/1858 [==============================] - 540s 290ms/step - loss: 0.0025 - acc: 0.9992 - precision_m: 0.8908 - recall_m: 0.8839 - f1_m: 0.8795\n",
      "Epoch 4/20\n",
      "1858/1858 [==============================] - 539s 290ms/step - loss: 0.0021 - acc: 0.9993 - precision_m: 0.9090 - recall_m: 0.9012 - f1_m: 0.8982\n",
      "Epoch 5/20\n",
      "1858/1858 [==============================] - 542s 292ms/step - loss: 0.0019 - acc: 0.9994 - precision_m: 0.9157 - recall_m: 0.9077 - f1_m: 0.9055\n",
      "Epoch 6/20\n",
      "1858/1858 [==============================] - 542s 292ms/step - loss: 0.0017 - acc: 0.9995 - precision_m: 0.9186 - recall_m: 0.9141 - f1_m: 0.9107\n",
      "Epoch 7/20\n",
      "1858/1858 [==============================] - 541s 291ms/step - loss: 0.0016 - acc: 0.9995 - precision_m: 0.9225 - recall_m: 0.9153 - f1_m: 0.9135\n",
      "Epoch 8/20\n",
      "1858/1858 [==============================] - 542s 291ms/step - loss: 0.0015 - acc: 0.9995 - precision_m: 0.9318 - recall_m: 0.9217 - f1_m: 0.9211\n",
      "Epoch 9/20\n",
      "1858/1858 [==============================] - 544s 293ms/step - loss: 0.0015 - acc: 0.9995 - precision_m: 0.9313 - recall_m: 0.9222 - f1_m: 0.9218\n",
      "Epoch 10/20\n",
      "1858/1858 [==============================] - 544s 293ms/step - loss: 0.0014 - acc: 0.9995 - precision_m: 0.9332 - recall_m: 0.9284 - f1_m: 0.9260\n",
      "Epoch 11/20\n",
      "1858/1858 [==============================] - 542s 292ms/step - loss: 0.0014 - acc: 0.9995 - precision_m: 0.9362 - recall_m: 0.9305 - f1_m: 0.9287\n",
      "Epoch 12/20\n",
      "1858/1858 [==============================] - 544s 293ms/step - loss: 0.0014 - acc: 0.9996 - precision_m: 0.9337 - recall_m: 0.9303 - f1_m: 0.9276\n",
      "Epoch 13/20\n",
      "1858/1858 [==============================] - 545s 293ms/step - loss: 0.0013 - acc: 0.9996 - precision_m: 0.9385 - recall_m: 0.9300 - f1_m: 0.9298\n",
      "Epoch 14/20\n",
      "1858/1858 [==============================] - 545s 293ms/step - loss: 0.0013 - acc: 0.9996 - precision_m: 0.9399 - recall_m: 0.9326 - f1_m: 0.9322\n",
      "Epoch 15/20\n",
      "1858/1858 [==============================] - 533s 287ms/step - loss: 0.0013 - acc: 0.9996 - precision_m: 0.9402 - recall_m: 0.9337 - f1_m: 0.9329\n",
      "Epoch 16/20\n",
      "1858/1858 [==============================] - 457s 246ms/step - loss: 0.0012 - acc: 0.9996 - precision_m: 0.9418 - recall_m: 0.9317 - f1_m: 0.9323\n",
      "Epoch 17/20\n",
      "1858/1858 [==============================] - 475s 256ms/step - loss: 0.0012 - acc: 0.9996 - precision_m: 0.9406 - recall_m: 0.9339 - f1_m: 0.9332\n",
      "Epoch 18/20\n",
      "1858/1858 [==============================] - 477s 257ms/step - loss: 0.0012 - acc: 0.9996 - precision_m: 0.9415 - recall_m: 0.9374 - f1_m: 0.9350\n",
      "Epoch 19/20\n",
      "1858/1858 [==============================] - 477s 256ms/step - loss: 0.0012 - acc: 0.9996 - precision_m: 0.9458 - recall_m: 0.9379 - f1_m: 0.9377\n",
      "Epoch 20/20\n",
      "1858/1858 [==============================] - 477s 257ms/step - loss: 0.0012 - acc: 0.9996 - precision_m: 0.9454 - recall_m: 0.9387 - f1_m: 0.9381\n",
      "Score for fold 5: loss of 0.0025577140040695667; acc of 0.9992725253105164; precision_m of 0.8347023725509644; recall_m of 0.8311446905136108; f1_m of 0.8211787939071655 %\n",
      "Training on fold 6/10..........\n",
      "6: started assigning sample weights\n",
      "6: finished assigning sample weights\n",
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 49, 300)           10282800  \n",
      "                                                                 \n",
      " bidirectional_5 (Bidirectio  (None, 49, 64)           85248     \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " lstm_16 (LSTM)              (None, 49, 32)            12416     \n",
      "                                                                 \n",
      " lstm_17 (LSTM)              (None, 49, 32)            8320      \n",
      "                                                                 \n",
      " time_distributed_5 (TimeDis  (None, 49, 1)            33        \n",
      " tributed)                                                       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 10,388,817\n",
      "Trainable params: 10,388,817\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1858/1858 [==============================] - 699s 370ms/step - loss: 0.0120 - acc: 0.9973 - precision_m: 0.6782 - recall_m: 0.5508 - f1_m: 0.5811\n",
      "Epoch 2/20\n",
      "1858/1858 [==============================] - 692s 372ms/step - loss: 0.0034 - acc: 0.9990 - precision_m: 0.8608 - recall_m: 0.8534 - f1_m: 0.8466\n",
      "Epoch 3/20\n",
      "1858/1858 [==============================] - 693s 373ms/step - loss: 0.0025 - acc: 0.9993 - precision_m: 0.8958 - recall_m: 0.8867 - f1_m: 0.8840\n",
      "Epoch 4/20\n",
      "1858/1858 [==============================] - 692s 372ms/step - loss: 0.0020 - acc: 0.9994 - precision_m: 0.9095 - recall_m: 0.9022 - f1_m: 0.8992\n",
      "Epoch 5/20\n",
      "1858/1858 [==============================] - 692s 372ms/step - loss: 0.0018 - acc: 0.9994 - precision_m: 0.9174 - recall_m: 0.9081 - f1_m: 0.9061\n",
      "Epoch 6/20\n",
      "1858/1858 [==============================] - 692s 372ms/step - loss: 0.0016 - acc: 0.9995 - precision_m: 0.9269 - recall_m: 0.9186 - f1_m: 0.9173\n",
      "Epoch 7/20\n",
      "1858/1858 [==============================] - 692s 372ms/step - loss: 0.0015 - acc: 0.9995 - precision_m: 0.9315 - recall_m: 0.9238 - f1_m: 0.9227\n",
      "Epoch 8/20\n",
      "1858/1858 [==============================] - 692s 373ms/step - loss: 0.0015 - acc: 0.9995 - precision_m: 0.9342 - recall_m: 0.9316 - f1_m: 0.9280\n",
      "Epoch 9/20\n",
      "1858/1858 [==============================] - 692s 372ms/step - loss: 0.0014 - acc: 0.9995 - precision_m: 0.9342 - recall_m: 0.9280 - f1_m: 0.9262\n",
      "Epoch 10/20\n",
      "1858/1858 [==============================] - 694s 373ms/step - loss: 0.0014 - acc: 0.9995 - precision_m: 0.9306 - recall_m: 0.9276 - f1_m: 0.9242\n",
      "Epoch 11/20\n",
      "1858/1858 [==============================] - 692s 372ms/step - loss: 0.0014 - acc: 0.9996 - precision_m: 0.9331 - recall_m: 0.9297 - f1_m: 0.9269\n",
      "Epoch 12/20\n",
      "1858/1858 [==============================] - 692s 372ms/step - loss: 0.0013 - acc: 0.9996 - precision_m: 0.9371 - recall_m: 0.9337 - f1_m: 0.9307\n",
      "Epoch 13/20\n",
      "1858/1858 [==============================] - 691s 372ms/step - loss: 0.0013 - acc: 0.9996 - precision_m: 0.9355 - recall_m: 0.9323 - f1_m: 0.9290\n",
      "Epoch 14/20\n",
      "1858/1858 [==============================] - 691s 372ms/step - loss: 0.0012 - acc: 0.9996 - precision_m: 0.9456 - recall_m: 0.9375 - f1_m: 0.9373\n",
      "Epoch 15/20\n",
      "1858/1858 [==============================] - 678s 365ms/step - loss: 0.0012 - acc: 0.9996 - precision_m: 0.9407 - recall_m: 0.9376 - f1_m: 0.9347\n",
      "Epoch 16/20\n",
      "1858/1858 [==============================] - 723s 389ms/step - loss: 0.0012 - acc: 0.9996 - precision_m: 0.9417 - recall_m: 0.9356 - f1_m: 0.9344\n",
      "Epoch 17/20\n",
      "1858/1858 [==============================] - 729s 392ms/step - loss: 0.0012 - acc: 0.9996 - precision_m: 0.9447 - recall_m: 0.9422 - f1_m: 0.9397\n",
      "Epoch 18/20\n",
      "1858/1858 [==============================] - 731s 393ms/step - loss: 0.0012 - acc: 0.9996 - precision_m: 0.9449 - recall_m: 0.9379 - f1_m: 0.9375\n",
      "Epoch 19/20\n",
      "1858/1858 [==============================] - 731s 394ms/step - loss: 0.0011 - acc: 0.9996 - precision_m: 0.9471 - recall_m: 0.9426 - f1_m: 0.9413\n",
      "Epoch 20/20\n",
      "1858/1858 [==============================] - 721s 388ms/step - loss: 0.0011 - acc: 0.9996 - precision_m: 0.9484 - recall_m: 0.9430 - f1_m: 0.9419\n",
      "Score for fold 6: loss of 0.002410390181466937; acc of 0.9993482232093811; precision_m of 0.8420485258102417; recall_m of 0.8117166757583618; f1_m of 0.815839409828186 %\n",
      "Training on fold 7/10..........\n",
      "7: started assigning sample weights\n",
      "7: finished assigning sample weights\n",
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 49, 300)           10282800  \n",
      "                                                                 \n",
      " bidirectional_6 (Bidirectio  (None, 49, 64)           85248     \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " lstm_19 (LSTM)              (None, 49, 32)            12416     \n",
      "                                                                 \n",
      " lstm_20 (LSTM)              (None, 49, 32)            8320      \n",
      "                                                                 \n",
      " time_distributed_6 (TimeDis  (None, 49, 1)            33        \n",
      " tributed)                                                       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 10,388,817\n",
      "Trainable params: 10,388,817\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "1858/1858 [==============================] - 759s 398ms/step - loss: 0.0128 - acc: 0.9971 - precision_m: 0.6662 - recall_m: 0.5309 - f1_m: 0.5633\n",
      "Epoch 2/20\n",
      "1858/1858 [==============================] - 742s 399ms/step - loss: 0.0034 - acc: 0.9990 - precision_m: 0.8628 - recall_m: 0.8450 - f1_m: 0.8421\n",
      "Epoch 3/20\n",
      "1858/1858 [==============================] - 747s 402ms/step - loss: 0.0023 - acc: 0.9993 - precision_m: 0.9064 - recall_m: 0.8907 - f1_m: 0.8915\n",
      "Epoch 4/20\n",
      "1858/1858 [==============================] - 744s 401ms/step - loss: 0.0019 - acc: 0.9994 - precision_m: 0.9200 - recall_m: 0.9087 - f1_m: 0.9081\n",
      "Epoch 5/20\n",
      "1858/1858 [==============================] - 739s 398ms/step - loss: 0.0017 - acc: 0.9995 - precision_m: 0.9253 - recall_m: 0.9184 - f1_m: 0.9163\n",
      "Epoch 6/20\n",
      "1858/1858 [==============================] - 740s 398ms/step - loss: 0.0015 - acc: 0.9995 - precision_m: 0.9332 - recall_m: 0.9224 - f1_m: 0.9227\n",
      "Epoch 7/20\n",
      "1858/1858 [==============================] - 738s 397ms/step - loss: 0.0015 - acc: 0.9995 - precision_m: 0.9312 - recall_m: 0.9212 - f1_m: 0.9214\n",
      "Epoch 8/20\n",
      "1858/1858 [==============================] - 739s 398ms/step - loss: 0.0014 - acc: 0.9995 - precision_m: 0.9337 - recall_m: 0.9280 - f1_m: 0.9263\n",
      "Epoch 9/20\n",
      "1858/1858 [==============================] - 741s 399ms/step - loss: 0.0014 - acc: 0.9996 - precision_m: 0.9375 - recall_m: 0.9302 - f1_m: 0.9294\n",
      "Epoch 10/20\n",
      "1858/1858 [==============================] - 743s 400ms/step - loss: 0.0013 - acc: 0.9996 - precision_m: 0.9401 - recall_m: 0.9288 - f1_m: 0.9297\n",
      "Epoch 11/20\n",
      "1858/1858 [==============================] - 744s 400ms/step - loss: 0.0013 - acc: 0.9996 - precision_m: 0.9464 - recall_m: 0.9386 - f1_m: 0.9384\n",
      "Epoch 12/20\n",
      "1858/1858 [==============================] - 745s 401ms/step - loss: 0.0012 - acc: 0.9996 - precision_m: 0.9430 - recall_m: 0.9352 - f1_m: 0.9349\n",
      "Epoch 13/20\n",
      "1858/1858 [==============================] - 742s 400ms/step - loss: 0.0012 - acc: 0.9996 - precision_m: 0.9436 - recall_m: 0.9368 - f1_m: 0.9358\n",
      "Epoch 14/20\n",
      "1858/1858 [==============================] - 743s 400ms/step - loss: 0.0012 - acc: 0.9996 - precision_m: 0.9429 - recall_m: 0.9352 - f1_m: 0.9341\n",
      "Epoch 15/20\n",
      "1858/1858 [==============================] - 743s 400ms/step - loss: 0.0012 - acc: 0.9996 - precision_m: 0.9490 - recall_m: 0.9391 - f1_m: 0.9401\n",
      "Epoch 16/20\n",
      "1858/1858 [==============================] - 744s 400ms/step - loss: 0.0012 - acc: 0.9996 - precision_m: 0.9425 - recall_m: 0.9403 - f1_m: 0.9370\n",
      "Epoch 17/20\n",
      "1858/1858 [==============================] - 746s 401ms/step - loss: 0.0011 - acc: 0.9996 - precision_m: 0.9464 - recall_m: 0.9391 - f1_m: 0.9386\n",
      "Epoch 18/20\n",
      "1858/1858 [==============================] - 747s 402ms/step - loss: 0.0011 - acc: 0.9996 - precision_m: 0.9482 - recall_m: 0.9411 - f1_m: 0.9408\n",
      "Epoch 19/20\n",
      "1858/1858 [==============================] - 892s 480ms/step - loss: 0.0011 - acc: 0.9996 - precision_m: 0.9502 - recall_m: 0.9464 - f1_m: 0.9446\n",
      "Epoch 20/20\n",
      "1858/1858 [==============================] - 912s 491ms/step - loss: 0.0011 - acc: 0.9996 - precision_m: 0.9439 - recall_m: 0.9403 - f1_m: 0.9384\n",
      "Score for fold 7: loss of 0.002085842425003648; acc of 0.9994579553604126; precision_m of 0.8384072780609131; recall_m of 0.8094987869262695; f1_m of 0.8155106902122498 %\n",
      "Training on fold 8/10..........\n",
      "8: started assigning sample weights\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jonat\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:70: FutureWarning: Pass classes=[0 1], y=[0 1 0 ... 0 0 0] as keyword args. From version 1.0 (renaming of 0.25) passing these as positional arguments will result in an error\n",
      "  warnings.warn(f\"Pass {args_msg} as keyword args. From version \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8: finished assigning sample weights\n",
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 49, 300)           10282800  \n",
      "                                                                 \n",
      " bidirectional_7 (Bidirectio  (None, 49, 64)           85248     \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " lstm_22 (LSTM)              (None, 49, 32)            12416     \n",
      "                                                                 \n",
      " lstm_23 (LSTM)              (None, 49, 32)            8320      \n",
      "                                                                 \n",
      " time_distributed_7 (TimeDis  (None, 49, 1)            33        \n",
      " tributed)                                                       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 10,388,817\n",
      "Trainable params: 10,388,817\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "1858/1858 [==============================] - 823s 430ms/step - loss: 0.0114 - acc: 0.9978 - precision_m: 0.7022 - recall_m: 0.5788 - f1_m: 0.6078\n",
      "Epoch 2/20\n",
      "1858/1858 [==============================] - 705s 380ms/step - loss: 0.0031 - acc: 0.9991 - precision_m: 0.8701 - recall_m: 0.8633 - f1_m: 0.8575\n",
      "Epoch 3/20\n",
      "1858/1858 [==============================] - 707s 381ms/step - loss: 0.0022 - acc: 0.9993 - precision_m: 0.9056 - recall_m: 0.8938 - f1_m: 0.8921\n",
      "Epoch 4/20\n",
      "1858/1858 [==============================] - 706s 380ms/step - loss: 0.0018 - acc: 0.9994 - precision_m: 0.9208 - recall_m: 0.9132 - f1_m: 0.9113\n",
      "Epoch 5/20\n",
      "1858/1858 [==============================] - 704s 379ms/step - loss: 0.0017 - acc: 0.9995 - precision_m: 0.9324 - recall_m: 0.9175 - f1_m: 0.9197\n",
      "Epoch 6/20\n",
      "1858/1858 [==============================] - 703s 379ms/step - loss: 0.0015 - acc: 0.9995 - precision_m: 0.9318 - recall_m: 0.9237 - f1_m: 0.9223\n",
      "Epoch 7/20\n",
      "1858/1858 [==============================] - 704s 379ms/step - loss: 0.0014 - acc: 0.9995 - precision_m: 0.9324 - recall_m: 0.9248 - f1_m: 0.9234\n",
      "Epoch 8/20\n",
      "1858/1858 [==============================] - 703s 378ms/step - loss: 0.0014 - acc: 0.9996 - precision_m: 0.9401 - recall_m: 0.9332 - f1_m: 0.9320\n",
      "Epoch 9/20\n",
      "1858/1858 [==============================] - 703s 378ms/step - loss: 0.0013 - acc: 0.9996 - precision_m: 0.9401 - recall_m: 0.9380 - f1_m: 0.9352\n",
      "Epoch 10/20\n",
      "1858/1858 [==============================] - 703s 378ms/step - loss: 0.0013 - acc: 0.9996 - precision_m: 0.9410 - recall_m: 0.9338 - f1_m: 0.9333\n",
      "Epoch 11/20\n",
      "1858/1858 [==============================] - 703s 378ms/step - loss: 0.0012 - acc: 0.9996 - precision_m: 0.9465 - recall_m: 0.9375 - f1_m: 0.9381\n",
      "Epoch 12/20\n",
      "1858/1858 [==============================] - 719s 387ms/step - loss: 0.0012 - acc: 0.9996 - precision_m: 0.9446 - recall_m: 0.9372 - f1_m: 0.9366\n",
      "Epoch 13/20\n",
      "1858/1858 [==============================] - 722s 388ms/step - loss: 0.0012 - acc: 0.9996 - precision_m: 0.9469 - recall_m: 0.9410 - f1_m: 0.9399\n",
      "Epoch 14/20\n",
      "1858/1858 [==============================] - 695s 374ms/step - loss: 0.0012 - acc: 0.9996 - precision_m: 0.9480 - recall_m: 0.9383 - f1_m: 0.9390\n",
      "Epoch 15/20\n",
      "1858/1858 [==============================] - 682s 367ms/step - loss: 0.0011 - acc: 0.9996 - precision_m: 0.9519 - recall_m: 0.9440 - f1_m: 0.9445\n",
      "Epoch 16/20\n",
      "1858/1858 [==============================] - 662s 357ms/step - loss: 0.0011 - acc: 0.9996 - precision_m: 0.9494 - recall_m: 0.9408 - f1_m: 0.9411\n",
      "Epoch 17/20\n",
      "1858/1858 [==============================] - 667s 359ms/step - loss: 0.0011 - acc: 0.9996 - precision_m: 0.9506 - recall_m: 0.9452 - f1_m: 0.9441\n",
      "Epoch 18/20\n",
      "1858/1858 [==============================] - 667s 359ms/step - loss: 0.0011 - acc: 0.9996 - precision_m: 0.9502 - recall_m: 0.9455 - f1_m: 0.9445\n",
      "Epoch 19/20\n",
      "1858/1858 [==============================] - 667s 359ms/step - loss: 0.0011 - acc: 0.9997 - precision_m: 0.9491 - recall_m: 0.9434 - f1_m: 0.9421\n",
      "Epoch 20/20\n",
      "1858/1858 [==============================] - 667s 359ms/step - loss: 0.0011 - acc: 0.9997 - precision_m: 0.9513 - recall_m: 0.9469 - f1_m: 0.9460\n",
      "Score for fold 8: loss of 0.0017076304648071527; acc of 0.9994827508926392; precision_m of 0.8526481986045837; recall_m of 0.8317635655403137; f1_m of 0.8315951228141785 %\n",
      "Training on fold 9/10..........\n",
      "9: started assigning sample weights\n",
      "9: finished assigning sample weights\n",
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 49, 300)           10282800  \n",
      "                                                                 \n",
      " bidirectional_8 (Bidirectio  (None, 49, 64)           85248     \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " lstm_25 (LSTM)              (None, 49, 32)            12416     \n",
      "                                                                 \n",
      " lstm_26 (LSTM)              (None, 49, 32)            8320      \n",
      "                                                                 \n",
      " time_distributed_8 (TimeDis  (None, 49, 1)            33        \n",
      " tributed)                                                       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 10,388,817\n",
      "Trainable params: 10,388,817\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "1858/1858 [==============================] - 775s 410ms/step - loss: 0.0115 - acc: 0.9973 - precision_m: 0.6994 - recall_m: 0.5750 - f1_m: 0.6038\n",
      "Epoch 2/20\n",
      "1858/1858 [==============================] - 757s 408ms/step - loss: 0.0032 - acc: 0.9991 - precision_m: 0.8669 - recall_m: 0.8546 - f1_m: 0.8507\n",
      "Epoch 3/20\n",
      "1858/1858 [==============================] - 781s 421ms/step - loss: 0.0022 - acc: 0.9993 - precision_m: 0.9046 - recall_m: 0.8935 - f1_m: 0.8924\n",
      "Epoch 4/20\n",
      "1858/1858 [==============================] - 788s 424ms/step - loss: 0.0018 - acc: 0.9994 - precision_m: 0.9189 - recall_m: 0.9118 - f1_m: 0.9095\n",
      "Epoch 5/20\n",
      "1858/1858 [==============================] - 787s 424ms/step - loss: 0.0016 - acc: 0.9995 - precision_m: 0.9217 - recall_m: 0.9195 - f1_m: 0.9149\n",
      "Epoch 6/20\n",
      "1858/1858 [==============================] - 788s 424ms/step - loss: 0.0015 - acc: 0.9995 - precision_m: 0.9289 - recall_m: 0.9230 - f1_m: 0.9211\n",
      "Epoch 7/20\n",
      "1858/1858 [==============================] - 788s 424ms/step - loss: 0.0014 - acc: 0.9995 - precision_m: 0.9296 - recall_m: 0.9239 - f1_m: 0.9218\n",
      "Epoch 8/20\n",
      "1858/1858 [==============================] - 788s 424ms/step - loss: 0.0013 - acc: 0.9996 - precision_m: 0.9371 - recall_m: 0.9323 - f1_m: 0.9302\n",
      "Epoch 9/20\n",
      "1858/1858 [==============================] - 787s 424ms/step - loss: 0.0014 - acc: 0.9996 - precision_m: 0.9377 - recall_m: 0.9296 - f1_m: 0.9288\n",
      "Epoch 10/20\n",
      "1858/1858 [==============================] - 788s 424ms/step - loss: 0.0012 - acc: 0.9996 - precision_m: 0.9401 - recall_m: 0.9328 - f1_m: 0.9322\n",
      "Epoch 11/20\n",
      "1858/1858 [==============================] - 788s 424ms/step - loss: 0.0012 - acc: 0.9996 - precision_m: 0.9406 - recall_m: 0.9370 - f1_m: 0.9343\n",
      "Epoch 12/20\n",
      "1858/1858 [==============================] - 788s 424ms/step - loss: 0.0012 - acc: 0.9996 - precision_m: 0.9451 - recall_m: 0.9411 - f1_m: 0.9395\n",
      "Epoch 13/20\n",
      "1858/1858 [==============================] - 788s 424ms/step - loss: 0.0012 - acc: 0.9996 - precision_m: 0.9454 - recall_m: 0.9388 - f1_m: 0.9378\n",
      "Epoch 14/20\n",
      "1858/1858 [==============================] - 788s 424ms/step - loss: 0.0012 - acc: 0.9996 - precision_m: 0.9442 - recall_m: 0.9378 - f1_m: 0.9374\n",
      "Epoch 15/20\n",
      "1858/1858 [==============================] - 788s 424ms/step - loss: 0.0011 - acc: 0.9996 - precision_m: 0.9418 - recall_m: 0.9414 - f1_m: 0.9373\n",
      "Epoch 16/20\n",
      "1858/1858 [==============================] - 788s 424ms/step - loss: 0.0012 - acc: 0.9996 - precision_m: 0.9484 - recall_m: 0.9412 - f1_m: 0.9412\n",
      "Epoch 17/20\n",
      "1858/1858 [==============================] - 788s 424ms/step - loss: 0.0011 - acc: 0.9996 - precision_m: 0.9489 - recall_m: 0.9442 - f1_m: 0.9429\n",
      "Epoch 18/20\n",
      "1858/1858 [==============================] - 788s 424ms/step - loss: 0.0011 - acc: 0.9996 - precision_m: 0.9465 - recall_m: 0.9431 - f1_m: 0.9410\n",
      "Epoch 19/20\n",
      "1858/1858 [==============================] - 745s 401ms/step - loss: 0.0011 - acc: 0.9997 - precision_m: 0.9489 - recall_m: 0.9418 - f1_m: 0.9415\n",
      "Epoch 20/20\n",
      "1858/1858 [==============================] - 760s 409ms/step - loss: 0.0011 - acc: 0.9996 - precision_m: 0.9490 - recall_m: 0.9445 - f1_m: 0.9433\n",
      "Score for fold 9: loss of 0.0015016439137980342; acc of 0.9995416402816772; precision_m of 0.8695082664489746; recall_m of 0.8700157403945923; f1_m of 0.8621650338172913 %\n",
      "Training on fold 10/10..........\n",
      "10: started assigning sample weights\n",
      "10: finished assigning sample weights\n",
      "Model: \"sequential_9\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 49, 300)           10282800  \n",
      "                                                                 \n",
      " bidirectional_9 (Bidirectio  (None, 49, 64)           85248     \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " lstm_28 (LSTM)              (None, 49, 32)            12416     \n",
      "                                                                 \n",
      " lstm_29 (LSTM)              (None, 49, 32)            8320      \n",
      "                                                                 \n",
      " time_distributed_9 (TimeDis  (None, 49, 1)            33        \n",
      " tributed)                                                       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 10,388,817\n",
      "Trainable params: 10,388,817\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "1858/1858 [==============================] - 740s 392ms/step - loss: 0.0110 - acc: 0.9978 - precision_m: 0.6955 - recall_m: 0.6034 - f1_m: 0.6223\n",
      "Epoch 2/20\n",
      "1858/1858 [==============================] - 733s 395ms/step - loss: 0.0030 - acc: 0.9991 - precision_m: 0.8722 - recall_m: 0.8591 - f1_m: 0.8564\n",
      "Epoch 3/20\n",
      "1858/1858 [==============================] - 733s 395ms/step - loss: 0.0022 - acc: 0.9993 - precision_m: 0.9046 - recall_m: 0.8966 - f1_m: 0.8932\n",
      "Epoch 4/20\n",
      "1858/1858 [==============================] - 732s 394ms/step - loss: 0.0018 - acc: 0.9994 - precision_m: 0.9169 - recall_m: 0.9079 - f1_m: 0.9065\n",
      "Epoch 5/20\n",
      "1858/1858 [==============================] - 733s 394ms/step - loss: 0.0016 - acc: 0.9995 - precision_m: 0.9299 - recall_m: 0.9208 - f1_m: 0.9197\n",
      "Epoch 6/20\n",
      "1858/1858 [==============================] - 733s 394ms/step - loss: 0.0015 - acc: 0.9995 - precision_m: 0.9332 - recall_m: 0.9251 - f1_m: 0.9241\n",
      "Epoch 7/20\n",
      "1858/1858 [==============================] - 732s 394ms/step - loss: 0.0014 - acc: 0.9996 - precision_m: 0.9360 - recall_m: 0.9285 - f1_m: 0.9275\n",
      "Epoch 8/20\n",
      "1858/1858 [==============================] - 732s 394ms/step - loss: 0.0013 - acc: 0.9996 - precision_m: 0.9406 - recall_m: 0.9332 - f1_m: 0.9320\n",
      "Epoch 9/20\n",
      "1858/1858 [==============================] - 732s 394ms/step - loss: 0.0013 - acc: 0.9996 - precision_m: 0.9404 - recall_m: 0.9343 - f1_m: 0.9331\n",
      "Epoch 10/20\n",
      "1858/1858 [==============================] - 733s 394ms/step - loss: 0.0012 - acc: 0.9996 - precision_m: 0.9445 - recall_m: 0.9361 - f1_m: 0.9364\n",
      "Epoch 11/20\n",
      "1858/1858 [==============================] - 733s 394ms/step - loss: 0.0012 - acc: 0.9996 - precision_m: 0.9451 - recall_m: 0.9388 - f1_m: 0.9381\n",
      "Epoch 12/20\n",
      "1858/1858 [==============================] - 734s 395ms/step - loss: 0.0012 - acc: 0.9996 - precision_m: 0.9465 - recall_m: 0.9393 - f1_m: 0.9387\n",
      "Epoch 13/20\n",
      "1858/1858 [==============================] - 732s 394ms/step - loss: 0.0012 - acc: 0.9996 - precision_m: 0.9475 - recall_m: 0.9369 - f1_m: 0.9382\n",
      "Epoch 14/20\n",
      "1858/1858 [==============================] - 733s 394ms/step - loss: 0.0012 - acc: 0.9996 - precision_m: 0.9446 - recall_m: 0.9429 - f1_m: 0.9396\n",
      "Epoch 15/20\n",
      "1858/1858 [==============================] - 747s 402ms/step - loss: 0.0011 - acc: 0.9996 - precision_m: 0.9484 - recall_m: 0.9391 - f1_m: 0.9399\n",
      "Epoch 16/20\n",
      "1858/1858 [==============================] - 787s 424ms/step - loss: 0.0011 - acc: 0.9997 - precision_m: 0.9490 - recall_m: 0.9432 - f1_m: 0.9422\n",
      "Epoch 17/20\n",
      "1858/1858 [==============================] - 787s 424ms/step - loss: 0.0011 - acc: 0.9996 - precision_m: 0.9507 - recall_m: 0.9425 - f1_m: 0.9431\n",
      "Epoch 18/20\n",
      "1858/1858 [==============================] - 787s 424ms/step - loss: 0.0011 - acc: 0.9997 - precision_m: 0.9510 - recall_m: 0.9464 - f1_m: 0.9451\n",
      "Epoch 19/20\n",
      "1858/1858 [==============================] - 767s 413ms/step - loss: 0.0010 - acc: 0.9996 - precision_m: 0.9486 - recall_m: 0.9433 - f1_m: 0.9422\n",
      "Epoch 20/20\n",
      "1858/1858 [==============================] - 778s 419ms/step - loss: 0.0011 - acc: 0.9997 - precision_m: 0.9521 - recall_m: 0.9446 - f1_m: 0.9444\n",
      "Score for fold 10: loss of 0.0017295769648626447; acc of 0.9995213747024536; precision_m of 0.8559173345565796; recall_m of 0.8478076457977295; f1_m of 0.8455421328544617 %\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "skf = StratifiedKFold(n_splits = 10, shuffle = True, random_state = 999)\n",
    "\n",
    "fold_number = 1\n",
    "f1_per_fold = []\n",
    "recall_per_fold = []\n",
    "precision_per_fold = []\n",
    "acc_per_fold = []\n",
    "loss_per_fold = []\n",
    "\n",
    "for i, (train_index, val_index) in enumerate(skf.split(pad_tokens, np.sum(pad_tags, axis = 1))):\n",
    "    \n",
    "    print(\"Training on fold \" + str(i+1) + \"/10..........\")\n",
    "    \n",
    "    #Split training set and validation set\n",
    "    x_train, x_val = pad_tokens[train_index], pad_tokens[val_index]\n",
    "    y_train, y_val = pad_tags[train_index], pad_tags[val_index]\n",
    "    \n",
    "    #Assigning sample weights in training set\n",
    "    print(str(fold_number) + \": started assigning sample weights\")\n",
    "    weights = class_weight.compute_class_weight('balanced',\n",
    "                                                 np.unique(np.ravel(y_train,order='C')),\n",
    "                                                 np.ravel(y_train,order='C'))\n",
    "    \n",
    "    train_tags2 = np.copy(y_train)\n",
    "    train_tokens2 = np.copy(x_train)\n",
    "    train_tags2 = train_tags2.astype(float)\n",
    "    \n",
    "    indexTotal = 0\n",
    "    for tags in train_tags2:\n",
    "        indexTags = 0\n",
    "        for symptom in tags:\n",
    "            if symptom == 1:\n",
    "                train_tags2[indexTotal][indexTags] = float(weights[1]+6.00)\n",
    "            else:\n",
    "                train_tags2[indexTotal][indexTags] = float(weights[0])\n",
    "            indexTags = indexTags+1\n",
    "        indexTotal = indexTotal + 1\n",
    "   \n",
    "    weights = train_tags2.reshape((-1, 49, 1))\n",
    "    print(str(fold_number) + \": finished assigning sample weights\")\n",
    "    \n",
    "    #Getting Model Architecture\n",
    "    model = get_bilstm_lstm_model()\n",
    "    \n",
    "    #Running Model\n",
    "    history = model.fit(x_train, y_train, sample_weight = weights, batch_size=64, verbose=1, epochs=20)\n",
    "    \n",
    "    #Evaluate model\n",
    "    scores = model.evaluate(x_val, y_val, verbose = 0)\n",
    "    print(f'Score for fold {fold_number}: {model.metrics_names[0]} of {scores[0]}; {model.metrics_names[1]} of {scores[1]}; {model.metrics_names[2]} of {scores[2]}; {model.metrics_names[3]} of {scores[3]}; {model.metrics_names[4]} of {scores[4]} %')\n",
    "    f1_per_fold.append(scores[4])\n",
    "    recall_per_fold.append(scores[3])\n",
    "    precision_per_fold.append(scores[2])\n",
    "    acc_per_fold.append(scores[1])\n",
    "    loss_per_fold.append(scores[0])\n",
    "    \n",
    "    #Increase fold number\n",
    "    fold_number = fold_number + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score per fold\n",
      "-----------\n",
      "> Fold 1 - Loss: 0.008731890469789505 - Accuracy: 0.9979530572891235 - Precision: 0.6661249399185181 - Recall: 0.6925951838493347 - F1: 0.6524550914764404%\n",
      "-----------\n",
      "> Fold 2 - Loss: 0.004619639832526445 - Accuracy: 0.9988755583763123 - Precision: 0.7796337008476257 - Recall: 0.7546238303184509 - F1: 0.7495155334472656%\n",
      "-----------\n",
      "> Fold 3 - Loss: 0.0038018280174583197 - Accuracy: 0.9990332126617432 - Precision: 0.7725365161895752 - Recall: 0.7495949268341064 - F1: 0.7432667016983032%\n",
      "-----------\n",
      "> Fold 4 - Loss: 0.0030736096668988466 - Accuracy: 0.9992074966430664 - Precision: 0.8228378295898438 - Recall: 0.7872909903526306 - F1: 0.7916290760040283%\n",
      "-----------\n",
      "> Fold 5 - Loss: 0.0025577140040695667 - Accuracy: 0.9992725253105164 - Precision: 0.8347023725509644 - Recall: 0.8311446905136108 - F1: 0.8211787939071655%\n",
      "-----------\n",
      "> Fold 6 - Loss: 0.002410390181466937 - Accuracy: 0.9993482232093811 - Precision: 0.8420485258102417 - Recall: 0.8117166757583618 - F1: 0.815839409828186%\n",
      "-----------\n",
      "> Fold 7 - Loss: 0.002085842425003648 - Accuracy: 0.9994579553604126 - Precision: 0.8384072780609131 - Recall: 0.8094987869262695 - F1: 0.8155106902122498%\n",
      "-----------\n",
      "> Fold 8 - Loss: 0.0017076304648071527 - Accuracy: 0.9994827508926392 - Precision: 0.8526481986045837 - Recall: 0.8317635655403137 - F1: 0.8315951228141785%\n",
      "-----------\n",
      "> Fold 9 - Loss: 0.0015016439137980342 - Accuracy: 0.9995416402816772 - Precision: 0.8695082664489746 - Recall: 0.8700157403945923 - F1: 0.8621650338172913%\n",
      "-----------\n",
      "> Fold 10 - Loss: 0.0017295769648626447 - Accuracy: 0.9995213747024536 - Precision: 0.8559173345565796 - Recall: 0.8478076457977295 - F1: 0.8455421328544617%\n",
      "------------\n",
      "Average scores for all folds:\n",
      "> Accuracy: 0.9991693794727325 (+- 0.0004552302052267624)\n",
      "> Precision: 0.813436496257782 (+- 0.05743271311369618)\n",
      "> Recall: 0.79860520362854 (+- 0.05066727272299974)\n",
      "> F1: 0.792869758605957 (+- 0.059139966420104904)\n",
      "> Loss: 0.00322197659406811\n",
      "------------\n"
     ]
    }
   ],
   "source": [
    "print('Score per fold')\n",
    "for i in range(0, len(acc_per_fold)):\n",
    "    print(\"-----------\")\n",
    "    print(f'> Fold {i+1} - Loss: {loss_per_fold[i]} - Accuracy: {acc_per_fold[i]} - Precision: {precision_per_fold[i]} - Recall: {recall_per_fold[i]} - F1: {f1_per_fold[i]}%')\n",
    "print('------------')\n",
    "print('Average scores for all folds:')\n",
    "print(f'> Accuracy: {np.mean(acc_per_fold)} (+- {np.std(acc_per_fold)})')\n",
    "print(f'> Precision: {np.mean(precision_per_fold)} (+- {np.std(precision_per_fold)})')\n",
    "print(f'> Recall: {np.mean(recall_per_fold)} (+- {np.std(recall_per_fold)})')\n",
    "print(f'> F1: {np.mean(f1_per_fold)} (+- {np.std(f1_per_fold)})')\n",
    "print(f'> Loss: {np.mean(loss_per_fold)}')\n",
    "print('------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Self Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_tags = model.predict(test_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "truePositive = 0 \n",
    "falsePositive = 0\n",
    "trueNegative = 0 \n",
    "falseNegative = 0\n",
    "index = 0\n",
    "for tag, predTag in zip(test_tags, predict_tags):\n",
    "    for symptomTag, symptomPred in zip (tag, predTag):\n",
    "        if symptomPred >= 0.50 and symptomTag == 1:\n",
    "            truePositive = truePositive + 1\n",
    "        elif symptomPred >= 0.50 and symptomTag == 0:\n",
    "            falsePositive = falsePositive + 1\n",
    "        elif symptomPred < 0.50 and symptomTag == 0:\n",
    "            trueNegative = trueNegative + 1\n",
    "        elif symptomPred < 0.50 and symptomTag == 1:\n",
    "            falseNegative = falseNegative + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True postitive: 6887\n",
      "False postitive: 359\n",
      "True negative: 1934322\n",
      "False negative: 253\n"
     ]
    }
   ],
   "source": [
    "print('True postitive: ' + str(truePositive))\n",
    "print('False postitive: ' + str(falsePositive))\n",
    "print('True negative: ' + str(trueNegative))\n",
    "print('False negative: ' + str(falseNegative))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision = (truePositive)/(truePositive+falsePositive)\n",
    "recall = (truePositive)/(truePositive+falseNegative)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.999684831918081\n",
      "Precision: 0.9504554236820315\n",
      "Recall: 0.9645658263305322\n",
      "F1: 0.9574586403447796\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy: ' + str((truePositive+trueNegative)/(truePositive+trueNegative+falsePositive+falseNegative)))\n",
    "print('Precision: ' + str((truePositive)/(truePositive+falsePositive)))\n",
    "print('Recall: ' + str((truePositive)/(truePositive+falseNegative)))\n",
    "print('F1: ' + str((2*precision*recall)/(precision+recall)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4128/4128 [==============================] - 215s 52ms/step - loss: 0.0010 - acc: 0.9997 - precision_m: 0.6882 - recall_m: 0.6997 - f1_m: 0.6890\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.0010336712002754211,\n",
       " 0.9996744990348816,\n",
       " 0.6881966590881348,\n",
       " 0.6996971368789673,\n",
       " 0.6890236735343933]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(pad_tokens, pad_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
