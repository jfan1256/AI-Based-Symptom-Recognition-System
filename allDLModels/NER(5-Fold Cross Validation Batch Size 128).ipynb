{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import imblearn\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence</th>\n",
       "      <th>Word</th>\n",
       "      <th>Tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sentence: 1</td>\n",
       "      <td>RECORD</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sentence: 2</td>\n",
       "      <td>OC</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>AM</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>gallstone</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>pancreatitis</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>949802</th>\n",
       "      <td>NaN</td>\n",
       "      <td>M.D.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>949803</th>\n",
       "      <td>Sentence: 132094</td>\n",
       "      <td>END</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>949804</th>\n",
       "      <td>NaN</td>\n",
       "      <td>OF</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>949805</th>\n",
       "      <td>NaN</td>\n",
       "      <td>DISCHARGE</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>949806</th>\n",
       "      <td>NaN</td>\n",
       "      <td>ORDERS</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>949807 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                Sentence          Word  Tag\n",
       "0            Sentence: 1        RECORD    0\n",
       "1            Sentence: 2            OC    0\n",
       "2                    NaN            AM    0\n",
       "3                    NaN     gallstone    0\n",
       "4                    NaN  pancreatitis    0\n",
       "...                  ...           ...  ...\n",
       "949802               NaN          M.D.    0\n",
       "949803  Sentence: 132094           END    0\n",
       "949804               NaN            OF    0\n",
       "949805               NaN     DISCHARGE    0\n",
       "949806               NaN        ORDERS    0\n",
       "\n",
       "[949807 rows x 3 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('./OUTPUT/dataset.csv', encoding= 'unicode_escape')\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Extract mappings required for the neural network\n",
    "To train a neural network, we will use two mappings as given below. The neural network will only take integers as input. So lets convert all the unique tokens in the corpus to its respective index.\n",
    "- {token} to {token id}: address the row in embeddings matrix for the current token.\n",
    "- {tag} to {tag id}: one-hot ground truth probability distribution vectors for computing the loss at the output of the network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import chain\n",
    "def get_dict_map(data, token_or_tag):\n",
    "    tok2idx = {}\n",
    "    idx2tok = {}\n",
    "    \n",
    "    if token_or_tag == 'token':\n",
    "        vocab = list(set(data['Word'].to_list()))\n",
    "    else:\n",
    "        vocab = list(set(data['Tag'].to_list()))\n",
    "    \n",
    "    idx2tok = {idx:tok for  idx, tok in enumerate(vocab)}\n",
    "    tok2idx = {tok:idx for  idx, tok in enumerate(vocab)}\n",
    "    return tok2idx, idx2tok\n",
    "\n",
    "\n",
    "token2idx, idx2token = get_dict_map(data, 'token')\n",
    "tag2idx, idx2tag = get_dict_map(data, 'tag')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Word_idx'] = data['Word'].map(token2idx)\n",
    "data['Tag_idx'] = data['Tag'].map(tag2idx) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence</th>\n",
       "      <th>Word</th>\n",
       "      <th>Tag</th>\n",
       "      <th>Word_idx</th>\n",
       "      <th>Tag_idx</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sentence: 1</td>\n",
       "      <td>RECORD</td>\n",
       "      <td>0</td>\n",
       "      <td>3322</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sentence: 2</td>\n",
       "      <td>OC</td>\n",
       "      <td>0</td>\n",
       "      <td>23718</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>AM</td>\n",
       "      <td>0</td>\n",
       "      <td>11324</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>gallstone</td>\n",
       "      <td>0</td>\n",
       "      <td>327</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>pancreatitis</td>\n",
       "      <td>0</td>\n",
       "      <td>11296</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>949802</th>\n",
       "      <td>NaN</td>\n",
       "      <td>M.D.</td>\n",
       "      <td>0</td>\n",
       "      <td>14432</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>949803</th>\n",
       "      <td>Sentence: 132094</td>\n",
       "      <td>END</td>\n",
       "      <td>0</td>\n",
       "      <td>32614</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>949804</th>\n",
       "      <td>NaN</td>\n",
       "      <td>OF</td>\n",
       "      <td>0</td>\n",
       "      <td>40271</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>949805</th>\n",
       "      <td>NaN</td>\n",
       "      <td>DISCHARGE</td>\n",
       "      <td>0</td>\n",
       "      <td>6213</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>949806</th>\n",
       "      <td>NaN</td>\n",
       "      <td>ORDERS</td>\n",
       "      <td>0</td>\n",
       "      <td>4817</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>949807 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                Sentence          Word  Tag  Word_idx  Tag_idx\n",
       "0            Sentence: 1        RECORD    0      3322        0\n",
       "1            Sentence: 2            OC    0     23718        0\n",
       "2                    NaN            AM    0     11324        0\n",
       "3                    NaN     gallstone    0       327        0\n",
       "4                    NaN  pancreatitis    0     11296        0\n",
       "...                  ...           ...  ...       ...      ...\n",
       "949802               NaN          M.D.    0     14432        0\n",
       "949803  Sentence: 132094           END    0     32614        0\n",
       "949804               NaN            OF    0     40271        0\n",
       "949805               NaN     DISCHARGE    0      6213        0\n",
       "949806               NaN        ORDERS    0      4817        0\n",
       "\n",
       "[949807 rows x 5 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv('./OUTPUT/view.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Transform columns to extract sequential data\n",
    "Next, lets fill NaN in 'sentence #' column using method ffill in fillna. Thereafter groupby on the sentence column to get a list of tokens and tags for each sentence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-6-2d54414e46a7>:2: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
      "  data_group = data_fillna.groupby(['Sentence'],as_index=False\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence</th>\n",
       "      <th>Word</th>\n",
       "      <th>Tag</th>\n",
       "      <th>Word_idx</th>\n",
       "      <th>Tag_idx</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sentence: 1</td>\n",
       "      <td>[RECORD]</td>\n",
       "      <td>[0]</td>\n",
       "      <td>[3322]</td>\n",
       "      <td>[0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sentence: 10</td>\n",
       "      <td>[WILL, D/C, ORDER, BE, USED, AS, THE, D/C, SUM...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>[33533, 5502, 31556, 3833, 24497, 31037, 5537,...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Sentence: 100</td>\n",
       "      <td>[prandial, N/V/severe, upper, abdominal, pain....</td>\n",
       "      <td>[0, 1, 0, 1, 1, 0, 0, 0, 0]</td>\n",
       "      <td>[34043, 14095, 8237, 13007, 38468, 1729, 11672...</td>\n",
       "      <td>[0, 1, 0, 1, 1, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Sentence: 1000</td>\n",
       "      <td>[normal, limits., Cardiac, catheterization, da...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>[9810, 13280, 15881, 34130, 18661, 2125, 33378...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sentence: 10000</td>\n",
       "      <td>[year, old, Black, female, with, significant, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>[22990, 4600, 20380, 13125, 9608, 27507, 10529...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132089</th>\n",
       "      <td>Sentence: 99995</td>\n",
       "      <td>[Height, foot, inch, and, weight, kg., Tempera...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>[22469, 7532, 40233, 15685, 26763, 2407, 18714]</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132090</th>\n",
       "      <td>Sentence: 99996</td>\n",
       "      <td>[degrees, heart, rate, and, sinus, blood, pres...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>[9731, 25006, 35610, 15685, 27085, 37761, 8893...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132091</th>\n",
       "      <td>Sentence: 99997</td>\n",
       "      <td>[blood, pressure, left, arm, and, oxygen, satu...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>[37761, 8893, 29464, 30408, 15685, 6508, 40516]</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132092</th>\n",
       "      <td>Sentence: 99998</td>\n",
       "      <td>[No, carotid, bruits, regular, rate, and, rhyt...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>[25422, 41014, 5214, 24181, 35610, 15685, 5256...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132093</th>\n",
       "      <td>Sentence: 99999</td>\n",
       "      <td>[systolic, murmur, along, the, right, upper, s...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>[23593, 20243, 9464, 5738, 36469, 8237, 3100, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>132094 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               Sentence                                               Word  \\\n",
       "0           Sentence: 1                                           [RECORD]   \n",
       "1          Sentence: 10  [WILL, D/C, ORDER, BE, USED, AS, THE, D/C, SUM...   \n",
       "2         Sentence: 100  [prandial, N/V/severe, upper, abdominal, pain....   \n",
       "3        Sentence: 1000  [normal, limits., Cardiac, catheterization, da...   \n",
       "4       Sentence: 10000  [year, old, Black, female, with, significant, ...   \n",
       "...                 ...                                                ...   \n",
       "132089  Sentence: 99995  [Height, foot, inch, and, weight, kg., Tempera...   \n",
       "132090  Sentence: 99996  [degrees, heart, rate, and, sinus, blood, pres...   \n",
       "132091  Sentence: 99997  [blood, pressure, left, arm, and, oxygen, satu...   \n",
       "132092  Sentence: 99998  [No, carotid, bruits, regular, rate, and, rhyt...   \n",
       "132093  Sentence: 99999  [systolic, murmur, along, the, right, upper, s...   \n",
       "\n",
       "                                   Tag  \\\n",
       "0                                  [0]   \n",
       "1       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]   \n",
       "2          [0, 1, 0, 1, 1, 0, 0, 0, 0]   \n",
       "3             [0, 0, 0, 0, 0, 0, 0, 0]   \n",
       "4       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]   \n",
       "...                                ...   \n",
       "132089           [0, 0, 0, 0, 0, 0, 0]   \n",
       "132090     [0, 0, 0, 0, 0, 0, 0, 0, 0]   \n",
       "132091           [0, 0, 0, 0, 0, 0, 0]   \n",
       "132092     [0, 0, 0, 0, 0, 0, 0, 0, 0]   \n",
       "132093     [0, 0, 0, 0, 0, 0, 0, 0, 0]   \n",
       "\n",
       "                                                 Word_idx  \\\n",
       "0                                                  [3322]   \n",
       "1       [33533, 5502, 31556, 3833, 24497, 31037, 5537,...   \n",
       "2       [34043, 14095, 8237, 13007, 38468, 1729, 11672...   \n",
       "3       [9810, 13280, 15881, 34130, 18661, 2125, 33378...   \n",
       "4       [22990, 4600, 20380, 13125, 9608, 27507, 10529...   \n",
       "...                                                   ...   \n",
       "132089    [22469, 7532, 40233, 15685, 26763, 2407, 18714]   \n",
       "132090  [9731, 25006, 35610, 15685, 27085, 37761, 8893...   \n",
       "132091    [37761, 8893, 29464, 30408, 15685, 6508, 40516]   \n",
       "132092  [25422, 41014, 5214, 24181, 35610, 15685, 5256...   \n",
       "132093  [23593, 20243, 9464, 5738, 36469, 8237, 3100, ...   \n",
       "\n",
       "                               Tag_idx  \n",
       "0                                  [0]  \n",
       "1       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]  \n",
       "2          [0, 1, 0, 1, 1, 0, 0, 0, 0]  \n",
       "3             [0, 0, 0, 0, 0, 0, 0, 0]  \n",
       "4       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]  \n",
       "...                                ...  \n",
       "132089           [0, 0, 0, 0, 0, 0, 0]  \n",
       "132090     [0, 0, 0, 0, 0, 0, 0, 0, 0]  \n",
       "132091           [0, 0, 0, 0, 0, 0, 0]  \n",
       "132092     [0, 0, 0, 0, 0, 0, 0, 0, 0]  \n",
       "132093     [0, 0, 0, 0, 0, 0, 0, 0, 0]  \n",
       "\n",
       "[132094 rows x 5 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_fillna = data.fillna(method='ffill', axis=0)\n",
    "data_group = data_fillna.groupby(['Sentence'],as_index=False\n",
    "                                )['Word', 'Tag', 'Word_idx', 'Tag_idx'].agg(lambda x: list(x))\n",
    "\n",
    "#data_fillna\n",
    "data_group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_group.to_csv('./OUTPUT/datagroup.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Pad sequences and split the dataset into train, test\n",
    "Padding: The LSTM layers accept sequences of same length only. Therefore we will want to transform our list of token_sequences ('Word_idx') which is lists of integers into a matrix of shape (token_sequences, max_len). We can use any length as max_len. In this project we will be using length of the longest sequence as max_len. The sequences that are shorter than max_len are padded with a specified value at the end.\n",
    "Import required packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_padTokens_padTags(data_group, data):\n",
    "    n_token = len(list(set(data['Word'].to_list())))\n",
    "    n_tag = len(list(set(data['Tag'].to_list())))\n",
    "    tokens = data_group['Word_idx'].tolist()\n",
    "    maxlen = max([len(s) for s in tokens])\n",
    "    pad_tokens = pad_sequences(tokens, maxlen=maxlen, dtype='int32', padding='post', value= 0)\n",
    "    tags = data_group['Tag_idx'].tolist()\n",
    "    pad_tags = pad_sequences(tags, maxlen=maxlen, dtype='int32', padding='post', value= 0)\n",
    "\n",
    "    return pad_tokens, pad_tags\n",
    "\n",
    "pad_tokens, pad_tags = get_padTokens_padTags(data_group, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of tokens 132094\n",
      "length of tags 132094\n"
     ]
    }
   ],
   "source": [
    "print('length of tokens ' + str(len(pad_tokens)))\n",
    "print('length of tags ' + str(len(pad_tags)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## StratifiedKFold Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import Sequential, Model, Input\n",
    "from tensorflow.keras.layers import LSTM, Embedding, Dense, TimeDistributed, Dropout, Bidirectional\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from keras import backend as K\n",
    "import keras as keras\n",
    "from keras.datasets import mnist\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from keras import metrics\n",
    "from sklearn.utils import class_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy.random import seed\n",
    "seed(1)\n",
    "tf.random.set_seed(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_dim:  42057 \n",
      "output_dim:  32 \n",
      "input_length:  49 \n",
      "n_tags:  2\n"
     ]
    }
   ],
   "source": [
    "input_dim = len(list(set(data['Word'].to_list())))+1\n",
    "output_dim = 32\n",
    "input_length = max([len(s) for s in data_group['Word_idx'].tolist()])\n",
    "n_tags = len(tag2idx)\n",
    "print('input_dim: ', input_dim, '\\noutput_dim: ', output_dim, '\\ninput_length: ', input_length, '\\nn_tags: ', n_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recall_m(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    recall = true_positives / (possible_positives + K.epsilon())\n",
    "    return recall\n",
    "\n",
    "def precision_m(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\n",
    "    return precision\n",
    "\n",
    "def f1_m(y_true, y_pred):\n",
    "    precision = precision_m(y_true, y_pred)\n",
    "    recall = recall_m(y_true, y_pred)\n",
    "    return 2*((precision*recall)/(precision+recall+K.epsilon()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bilstm_lstm_model():\n",
    "    model = Sequential()\n",
    "\n",
    "    # Add Embedding layer\n",
    "    model.add(Embedding(input_dim=input_dim, output_dim=output_dim, input_length=input_length))\n",
    "\n",
    "    # Add bidirectional LSTM\n",
    "    model.add(Bidirectional(LSTM(units=output_dim, return_sequences=True, dropout=0.2, recurrent_dropout=0.2), merge_mode = 'concat'))\n",
    "\n",
    "    \n",
    "    # Add LSTM\n",
    "    model.add(LSTM(units=output_dim, return_sequences=True, dropout=0.5, recurrent_dropout=0.5))\n",
    "\n",
    "    # Add timeDistributed Layer\n",
    "    model.add(TimeDistributed(Dense(1, activation=\"sigmoid\")))\n",
    "    \n",
    "    #Optimiser \n",
    "    adam = tf.keras.optimizers.Adam(learning_rate=0.0005, beta_1=0.9, beta_2=0.999)\n",
    "    \n",
    "    # Compile model\n",
    "    model.compile(loss='binary_crossentropy', sample_weight_mode=\"temporal\", optimizer='adam', metrics=['acc', precision_m, recall_m, f1_m])\n",
    "    model.summary()\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jonat\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:666: UserWarning: The least populated class in y has only 3 members, which is less than n_splits=5.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on fold 1/5..........\n",
      "1: started oversampling\n",
      "1: finished assigning sample weights\n",
      "1: started oversampling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jonat\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:70: FutureWarning: Pass classes=[0 1], y=[0 1 1 ... 0 0 0] as keyword args. From version 1.0 (renaming of 0.25) passing these as positional arguments will result in an error\n",
      "  warnings.warn(f\"Pass {args_msg} as keyword args. From version \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1: finished assigning sample weights\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 49, 32)            1345824   \n",
      "                                                                 \n",
      " bidirectional (Bidirectiona  (None, 49, 64)           16640     \n",
      " l)                                                              \n",
      "                                                                 \n",
      " lstm_1 (LSTM)               (None, 49, 32)            12416     \n",
      "                                                                 \n",
      " time_distributed (TimeDistr  (None, 49, 1)            33        \n",
      " ibuted)                                                         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,374,913\n",
      "Trainable params: 1,374,913\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "2245/2245 [==============================] - 222s 97ms/step - loss: 0.0302 - acc: 0.9905 - precision_m: 0.8091 - recall_m: 0.7653 - f1_m: 0.7763\n",
      "Epoch 2/20\n",
      "2245/2245 [==============================] - 226s 101ms/step - loss: 0.0094 - acc: 0.9969 - precision_m: 0.9371 - recall_m: 0.9540 - f1_m: 0.9453\n",
      "Epoch 3/20\n",
      "2245/2245 [==============================] - 228s 102ms/step - loss: 0.0065 - acc: 0.9979 - precision_m: 0.9546 - recall_m: 0.9711 - f1_m: 0.9626\n",
      "Epoch 4/20\n",
      "2245/2245 [==============================] - 230s 102ms/step - loss: 0.0050 - acc: 0.9984 - precision_m: 0.9647 - recall_m: 0.9784 - f1_m: 0.9714\n",
      "Epoch 5/20\n",
      "2245/2245 [==============================] - 230s 103ms/step - loss: 0.0040 - acc: 0.9987 - precision_m: 0.9714 - recall_m: 0.9830 - f1_m: 0.9771\n",
      "Epoch 6/20\n",
      "2245/2245 [==============================] - 231s 103ms/step - loss: 0.0033 - acc: 0.9989 - precision_m: 0.9758 - recall_m: 0.9853 - f1_m: 0.9804\n",
      "Epoch 7/20\n",
      "2245/2245 [==============================] - 228s 102ms/step - loss: 0.0028 - acc: 0.9991 - precision_m: 0.9796 - recall_m: 0.9875 - f1_m: 0.9835\n",
      "Epoch 8/20\n",
      "2245/2245 [==============================] - 227s 101ms/step - loss: 0.0025 - acc: 0.9992 - precision_m: 0.9820 - recall_m: 0.9890 - f1_m: 0.9854\n",
      "Epoch 9/20\n",
      "2245/2245 [==============================] - 226s 101ms/step - loss: 0.0022 - acc: 0.9993 - precision_m: 0.9840 - recall_m: 0.9900 - f1_m: 0.9870\n",
      "Epoch 10/20\n",
      "2245/2245 [==============================] - 227s 101ms/step - loss: 0.0020 - acc: 0.9993 - precision_m: 0.9858 - recall_m: 0.9911 - f1_m: 0.9884\n",
      "Epoch 11/20\n",
      "2245/2245 [==============================] - 228s 102ms/step - loss: 0.0018 - acc: 0.9994 - precision_m: 0.9870 - recall_m: 0.9918 - f1_m: 0.9893\n",
      "Epoch 12/20\n",
      "2245/2245 [==============================] - 235s 105ms/step - loss: 0.0017 - acc: 0.9994 - precision_m: 0.9881 - recall_m: 0.9923 - f1_m: 0.9902\n",
      "Epoch 13/20\n",
      "2245/2245 [==============================] - 227s 101ms/step - loss: 0.0016 - acc: 0.9995 - precision_m: 0.9892 - recall_m: 0.9930 - f1_m: 0.9911\n",
      "Epoch 14/20\n",
      "2245/2245 [==============================] - 227s 101ms/step - loss: 0.0015 - acc: 0.9995 - precision_m: 0.9899 - recall_m: 0.9935 - f1_m: 0.9917\n",
      "Epoch 15/20\n",
      "2245/2245 [==============================] - 229s 102ms/step - loss: 0.0014 - acc: 0.9996 - precision_m: 0.9907 - recall_m: 0.9939 - f1_m: 0.9923\n",
      "Epoch 16/20\n",
      "2245/2245 [==============================] - 229s 102ms/step - loss: 0.0013 - acc: 0.9996 - precision_m: 0.9910 - recall_m: 0.9940 - f1_m: 0.9925\n",
      "Epoch 17/20\n",
      "2245/2245 [==============================] - 229s 102ms/step - loss: 0.0012 - acc: 0.9996 - precision_m: 0.9917 - recall_m: 0.9943 - f1_m: 0.9930\n",
      "Epoch 18/20\n",
      "2245/2245 [==============================] - 229s 102ms/step - loss: 0.0012 - acc: 0.9996 - precision_m: 0.9916 - recall_m: 0.9946 - f1_m: 0.9931\n",
      "Epoch 19/20\n",
      "2245/2245 [==============================] - 238s 106ms/step - loss: 0.0011 - acc: 0.9996 - precision_m: 0.9924 - recall_m: 0.9951 - f1_m: 0.9937\n",
      "Epoch 20/20\n",
      "2245/2245 [==============================] - 277s 123ms/step - loss: 0.0011 - acc: 0.9996 - precision_m: 0.9927 - recall_m: 0.9950 - f1_m: 0.9938\n",
      "Score for fold 1: loss of 0.017037667334079742; acc of 0.9976851940155029; precision_m of 0.5922558903694153; recall_m of 0.6298075914382935; f1_m of 0.5819063782691956 %\n",
      "Training on fold 2/5..........\n",
      "2: started oversampling\n",
      "2: finished assigning sample weights\n",
      "2: started oversampling\n",
      "2: finished assigning sample weights\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_1 (Embedding)     (None, 49, 32)            1345824   \n",
      "                                                                 \n",
      " bidirectional_1 (Bidirectio  (None, 49, 64)           16640     \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " lstm_3 (LSTM)               (None, 49, 32)            12416     \n",
      "                                                                 \n",
      " time_distributed_1 (TimeDis  (None, 49, 1)            33        \n",
      " tributed)                                                       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,374,913\n",
      "Trainable params: 1,374,913\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "2245/2245 [==============================] - 343s 147ms/step - loss: 0.0304 - acc: 0.9905 - precision_m: 0.8041 - recall_m: 0.7601 - f1_m: 0.7719\n",
      "Epoch 2/20\n",
      "2245/2245 [==============================] - 317s 141ms/step - loss: 0.0093 - acc: 0.9968 - precision_m: 0.9376 - recall_m: 0.9526 - f1_m: 0.9448\n",
      "Epoch 3/20\n",
      "2245/2245 [==============================] - 343s 153ms/step - loss: 0.0066 - acc: 0.9978 - precision_m: 0.9549 - recall_m: 0.9699 - f1_m: 0.9622\n",
      "Epoch 4/20\n",
      "2245/2245 [==============================] - 272s 121ms/step - loss: 0.0050 - acc: 0.9984 - precision_m: 0.9653 - recall_m: 0.9776 - f1_m: 0.9713\n",
      "Epoch 5/20\n",
      "2245/2245 [==============================] - 254s 113ms/step - loss: 0.0039 - acc: 0.9987 - precision_m: 0.9720 - recall_m: 0.9821 - f1_m: 0.9769\n",
      "Epoch 6/20\n",
      "2245/2245 [==============================] - 262s 117ms/step - loss: 0.0033 - acc: 0.9989 - precision_m: 0.9766 - recall_m: 0.9856 - f1_m: 0.9810\n",
      "Epoch 7/20\n",
      "2245/2245 [==============================] - 262s 117ms/step - loss: 0.0028 - acc: 0.9991 - precision_m: 0.9799 - recall_m: 0.9873 - f1_m: 0.9835\n",
      "Epoch 8/20\n",
      "2245/2245 [==============================] - 279s 124ms/step - loss: 0.0025 - acc: 0.9992 - precision_m: 0.9824 - recall_m: 0.9889 - f1_m: 0.9856\n",
      "Epoch 9/20\n",
      "2245/2245 [==============================] - 350s 156ms/step - loss: 0.0022 - acc: 0.9993 - precision_m: 0.9844 - recall_m: 0.9904 - f1_m: 0.9873\n",
      "Epoch 10/20\n",
      "2245/2245 [==============================] - 334s 149ms/step - loss: 0.0020 - acc: 0.9993 - precision_m: 0.9861 - recall_m: 0.9911 - f1_m: 0.9885\n",
      "Epoch 11/20\n",
      "2245/2245 [==============================] - 351s 156ms/step - loss: 0.0018 - acc: 0.9994 - precision_m: 0.9871 - recall_m: 0.9920 - f1_m: 0.9895\n",
      "Epoch 12/20\n",
      "2245/2245 [==============================] - 246s 110ms/step - loss: 0.0017 - acc: 0.9994 - precision_m: 0.9884 - recall_m: 0.9924 - f1_m: 0.9903\n",
      "Epoch 13/20\n",
      "2245/2245 [==============================] - 234s 104ms/step - loss: 0.0015 - acc: 0.9995 - precision_m: 0.9892 - recall_m: 0.9930 - f1_m: 0.9911\n",
      "Epoch 14/20\n",
      "2245/2245 [==============================] - 234s 104ms/step - loss: 0.0014 - acc: 0.9995 - precision_m: 0.9900 - recall_m: 0.9934 - f1_m: 0.9917\n",
      "Epoch 15/20\n",
      "2245/2245 [==============================] - 232s 103ms/step - loss: 0.0014 - acc: 0.9995 - precision_m: 0.9904 - recall_m: 0.9938 - f1_m: 0.9921\n",
      "Epoch 16/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2245/2245 [==============================] - 233s 104ms/step - loss: 0.0013 - acc: 0.9996 - precision_m: 0.9911 - recall_m: 0.9942 - f1_m: 0.9926\n",
      "Epoch 17/20\n",
      "2245/2245 [==============================] - 232s 103ms/step - loss: 0.0012 - acc: 0.9996 - precision_m: 0.9915 - recall_m: 0.9944 - f1_m: 0.9930\n",
      "Epoch 18/20\n",
      "2245/2245 [==============================] - 232s 104ms/step - loss: 0.0012 - acc: 0.9996 - precision_m: 0.9920 - recall_m: 0.9947 - f1_m: 0.9933\n",
      "Epoch 19/20\n",
      "2245/2245 [==============================] - 231s 103ms/step - loss: 0.0011 - acc: 0.9996 - precision_m: 0.9924 - recall_m: 0.9950 - f1_m: 0.9937\n",
      "Epoch 20/20\n",
      "2245/2245 [==============================] - 232s 103ms/step - loss: 0.0011 - acc: 0.9996 - precision_m: 0.9927 - recall_m: 0.9950 - f1_m: 0.9938\n",
      "Score for fold 2: loss of 0.01665506139397621; acc of 0.9977908730506897; precision_m of 0.6134408116340637; recall_m of 0.6505417823791504; f1_m of 0.6020514965057373 %\n",
      "Training on fold 3/5..........\n",
      "3: started oversampling\n",
      "3: finished assigning sample weights\n",
      "3: started oversampling\n",
      "3: finished assigning sample weights\n",
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_2 (Embedding)     (None, 49, 32)            1345824   \n",
      "                                                                 \n",
      " bidirectional_2 (Bidirectio  (None, 49, 64)           16640     \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " lstm_5 (LSTM)               (None, 49, 32)            12416     \n",
      "                                                                 \n",
      " time_distributed_2 (TimeDis  (None, 49, 1)            33        \n",
      " tributed)                                                       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,374,913\n",
      "Trainable params: 1,374,913\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "2245/2245 [==============================] - 214s 93ms/step - loss: 0.0284 - acc: 0.9909 - precision_m: 0.8251 - recall_m: 0.7818 - f1_m: 0.7922\n",
      "Epoch 2/20\n",
      "2245/2245 [==============================] - 215s 96ms/step - loss: 0.0091 - acc: 0.9970 - precision_m: 0.9386 - recall_m: 0.9555 - f1_m: 0.9468\n",
      "Epoch 3/20\n",
      "2245/2245 [==============================] - 218s 97ms/step - loss: 0.0063 - acc: 0.9979 - precision_m: 0.9560 - recall_m: 0.9719 - f1_m: 0.96373s - loss: 0.0063 - acc: 0.9979 - precision_m: 0.955\n",
      "Epoch 4/20\n",
      "2245/2245 [==============================] - 219s 98ms/step - loss: 0.0047 - acc: 0.9984 - precision_m: 0.9662 - recall_m: 0.9788 - f1_m: 0.9724\n",
      "Epoch 5/20\n",
      "2245/2245 [==============================] - 218s 97ms/step - loss: 0.0037 - acc: 0.9987 - precision_m: 0.9726 - recall_m: 0.9823 - f1_m: 0.9774\n",
      "Epoch 6/20\n",
      "2245/2245 [==============================] - 219s 97ms/step - loss: 0.0031 - acc: 0.9989 - precision_m: 0.9768 - recall_m: 0.9852 - f1_m: 0.9809\n",
      "Epoch 7/20\n",
      "2245/2245 [==============================] - 220s 98ms/step - loss: 0.0027 - acc: 0.9991 - precision_m: 0.9801 - recall_m: 0.9869 - f1_m: 0.9834\n",
      "Epoch 8/20\n",
      "2245/2245 [==============================] - 220s 98ms/step - loss: 0.0024 - acc: 0.9992 - precision_m: 0.9824 - recall_m: 0.9884 - f1_m: 0.9854\n",
      "Epoch 9/20\n",
      "2245/2245 [==============================] - 220s 98ms/step - loss: 0.0021 - acc: 0.9993 - precision_m: 0.9843 - recall_m: 0.9896 - f1_m: 0.9869\n",
      "Epoch 10/20\n",
      "2245/2245 [==============================] - 220s 98ms/step - loss: 0.0019 - acc: 0.9993 - precision_m: 0.9862 - recall_m: 0.9907 - f1_m: 0.9884\n",
      "Epoch 11/20\n",
      "2245/2245 [==============================] - 221s 99ms/step - loss: 0.0018 - acc: 0.9994 - precision_m: 0.9874 - recall_m: 0.9916 - f1_m: 0.9895\n",
      "Epoch 12/20\n",
      "2245/2245 [==============================] - 221s 99ms/step - loss: 0.0017 - acc: 0.9994 - precision_m: 0.9882 - recall_m: 0.9922 - f1_m: 0.9901\n",
      "Epoch 13/20\n",
      "2245/2245 [==============================] - 221s 98ms/step - loss: 0.0015 - acc: 0.9995 - precision_m: 0.9893 - recall_m: 0.9929 - f1_m: 0.9911\n",
      "Epoch 14/20\n",
      "2245/2245 [==============================] - 222s 99ms/step - loss: 0.0014 - acc: 0.9995 - precision_m: 0.9898 - recall_m: 0.9933 - f1_m: 0.9915\n",
      "Epoch 15/20\n",
      "2245/2245 [==============================] - 199s 89ms/step - loss: 0.0013 - acc: 0.9995 - precision_m: 0.9905 - recall_m: 0.9936 - f1_m: 0.9920\n",
      "Epoch 16/20\n",
      "2245/2245 [==============================] - 194s 86ms/step - loss: 0.0013 - acc: 0.9996 - precision_m: 0.9910 - recall_m: 0.9939 - f1_m: 0.9924\n",
      "Epoch 17/20\n",
      "2245/2245 [==============================] - 193s 86ms/step - loss: 0.0012 - acc: 0.9996 - precision_m: 0.9919 - recall_m: 0.9945 - f1_m: 0.9932\n",
      "Epoch 18/20\n",
      "2245/2245 [==============================] - 223s 99ms/step - loss: 0.0012 - acc: 0.9996 - precision_m: 0.9918 - recall_m: 0.9945 - f1_m: 0.9931\n",
      "Epoch 19/20\n",
      "2245/2245 [==============================] - 229s 102ms/step - loss: 0.0011 - acc: 0.9996 - precision_m: 0.9923 - recall_m: 0.9948 - f1_m: 0.9935\n",
      "Epoch 20/20\n",
      "2245/2245 [==============================] - 225s 100ms/step - loss: 0.0011 - acc: 0.9996 - precision_m: 0.9925 - recall_m: 0.9951 - f1_m: 0.9937\n",
      "Score for fold 3: loss of 0.017834406346082687; acc of 0.9976081848144531; precision_m of 0.568251371383667; recall_m of 0.6278537511825562; f1_m of 0.5686147809028625 %\n",
      "Training on fold 4/5..........\n",
      "4: started oversampling\n",
      "4: finished assigning sample weights\n",
      "4: started oversampling\n",
      "4: finished assigning sample weights\n",
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_3 (Embedding)     (None, 49, 32)            1345824   \n",
      "                                                                 \n",
      " bidirectional_3 (Bidirectio  (None, 49, 64)           16640     \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " lstm_7 (LSTM)               (None, 49, 32)            12416     \n",
      "                                                                 \n",
      " time_distributed_3 (TimeDis  (None, 49, 1)            33        \n",
      " tributed)                                                       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,374,913\n",
      "Trainable params: 1,374,913\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "2245/2245 [==============================] - 207s 89ms/step - loss: 0.0294 - acc: 0.9909 - precision_m: 0.8159 - recall_m: 0.7720 - f1_m: 0.7837\n",
      "Epoch 2/20\n",
      "2245/2245 [==============================] - 207s 92ms/step - loss: 0.0094 - acc: 0.9968 - precision_m: 0.9361 - recall_m: 0.9525 - f1_m: 0.9440\n",
      "Epoch 3/20\n",
      "2245/2245 [==============================] - 209s 93ms/step - loss: 0.0064 - acc: 0.9979 - precision_m: 0.9555 - recall_m: 0.9712 - f1_m: 0.9632\n",
      "Epoch 4/20\n",
      "2245/2245 [==============================] - 213s 95ms/step - loss: 0.0049 - acc: 0.9984 - precision_m: 0.9655 - recall_m: 0.9788 - f1_m: 0.9720\n",
      "Epoch 5/20\n",
      "2245/2245 [==============================] - 214s 95ms/step - loss: 0.0040 - acc: 0.9987 - precision_m: 0.9715 - recall_m: 0.9824 - f1_m: 0.9769\n",
      "Epoch 6/20\n",
      "2245/2245 [==============================] - 214s 95ms/step - loss: 0.0033 - acc: 0.9989 - precision_m: 0.9763 - recall_m: 0.9855 - f1_m: 0.9808\n",
      "Epoch 7/20\n",
      "2245/2245 [==============================] - 215s 96ms/step - loss: 0.0028 - acc: 0.9991 - precision_m: 0.9796 - recall_m: 0.9874 - f1_m: 0.9834\n",
      "Epoch 8/20\n",
      "2245/2245 [==============================] - 214s 95ms/step - loss: 0.0025 - acc: 0.9992 - precision_m: 0.9821 - recall_m: 0.9889 - f1_m: 0.9854\n",
      "Epoch 9/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2245/2245 [==============================] - 215s 96ms/step - loss: 0.0022 - acc: 0.9992 - precision_m: 0.9839 - recall_m: 0.9899 - f1_m: 0.9869\n",
      "Epoch 10/20\n",
      "2245/2245 [==============================] - 215s 96ms/step - loss: 0.0020 - acc: 0.9993 - precision_m: 0.9855 - recall_m: 0.9909 - f1_m: 0.9882\n",
      "Epoch 11/20\n",
      "2245/2245 [==============================] - 215s 96ms/step - loss: 0.0018 - acc: 0.9994 - precision_m: 0.9869 - recall_m: 0.9916 - f1_m: 0.9892\n",
      "Epoch 12/20\n",
      "2245/2245 [==============================] - 214s 95ms/step - loss: 0.0017 - acc: 0.9994 - precision_m: 0.9879 - recall_m: 0.9924 - f1_m: 0.9901\n",
      "Epoch 13/20\n",
      "2245/2245 [==============================] - 215s 96ms/step - loss: 0.0016 - acc: 0.9995 - precision_m: 0.9888 - recall_m: 0.9929 - f1_m: 0.9908\n",
      "Epoch 14/20\n",
      "2245/2245 [==============================] - 214s 95ms/step - loss: 0.0015 - acc: 0.9995 - precision_m: 0.9897 - recall_m: 0.9935 - f1_m: 0.99165s - loss: 0.0015 - acc:\n",
      "Epoch 15/20\n",
      "2245/2245 [==============================] - 217s 96ms/step - loss: 0.0014 - acc: 0.9995 - precision_m: 0.9902 - recall_m: 0.9939 - f1_m: 0.9920\n",
      "Epoch 16/20\n",
      "2245/2245 [==============================] - 215s 96ms/step - loss: 0.0013 - acc: 0.9996 - precision_m: 0.9907 - recall_m: 0.9940 - f1_m: 0.9924\n",
      "Epoch 17/20\n",
      "2245/2245 [==============================] - 215s 96ms/step - loss: 0.0012 - acc: 0.9996 - precision_m: 0.9914 - recall_m: 0.9945 - f1_m: 0.99291s - loss: 0.0012 - acc: 0.9996 - precision_m: 0.9914 - recall_m: \n",
      "Epoch 18/20\n",
      "2245/2245 [==============================] - 215s 96ms/step - loss: 0.0012 - acc: 0.9996 - precision_m: 0.9916 - recall_m: 0.9946 - f1_m: 0.9931\n",
      "Epoch 19/20\n",
      "2245/2245 [==============================] - 215s 96ms/step - loss: 0.0011 - acc: 0.9996 - precision_m: 0.9920 - recall_m: 0.9950 - f1_m: 0.99352s - loss: 0.0011 - acc: 0.9996 - precision_m: 0.9921 - recall\n",
      "Epoch 20/20\n",
      "2245/2245 [==============================] - 215s 96ms/step - loss: 0.0011 - acc: 0.9997 - precision_m: 0.9926 - recall_m: 0.9954 - f1_m: 0.9939\n",
      "Score for fold 4: loss of 0.018074942752718925; acc of 0.9976130127906799; precision_m of 0.5596749186515808; recall_m of 0.6129063367843628; f1_m of 0.5587538480758667 %\n",
      "Training on fold 5/5..........\n",
      "5: started oversampling\n",
      "5: finished assigning sample weights\n",
      "5: started oversampling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jonat\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:70: FutureWarning: Pass classes=[0 1], y=[0 0 0 ... 0 0 0] as keyword args. From version 1.0 (renaming of 0.25) passing these as positional arguments will result in an error\n",
      "  warnings.warn(f\"Pass {args_msg} as keyword args. From version \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5: finished assigning sample weights\n",
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_4 (Embedding)     (None, 49, 32)            1345824   \n",
      "                                                                 \n",
      " bidirectional_4 (Bidirectio  (None, 49, 64)           16640     \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " lstm_9 (LSTM)               (None, 49, 32)            12416     \n",
      "                                                                 \n",
      " time_distributed_4 (TimeDis  (None, 49, 1)            33        \n",
      " tributed)                                                       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,374,913\n",
      "Trainable params: 1,374,913\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "2245/2245 [==============================] - 229s 99ms/step - loss: 0.0314 - acc: 0.9899 - precision_m: 0.7909 - recall_m: 0.7533 - f1_m: 0.7621\n",
      "Epoch 2/20\n",
      "2245/2245 [==============================] - 223s 99ms/step - loss: 0.0104 - acc: 0.9964 - precision_m: 0.9290 - recall_m: 0.9460 - f1_m: 0.9372\n",
      "Epoch 3/20\n",
      "2245/2245 [==============================] - 206s 92ms/step - loss: 0.0066 - acc: 0.9978 - precision_m: 0.9542 - recall_m: 0.9693 - f1_m: 0.9615\n",
      "Epoch 4/20\n",
      "2245/2245 [==============================] - 207s 92ms/step - loss: 0.0049 - acc: 0.9984 - precision_m: 0.9654 - recall_m: 0.9774 - f1_m: 0.9713\n",
      "Epoch 5/20\n",
      "2245/2245 [==============================] - 220s 98ms/step - loss: 0.0038 - acc: 0.9987 - precision_m: 0.9726 - recall_m: 0.9820 - f1_m: 0.9772\n",
      "Epoch 6/20\n",
      "2245/2245 [==============================] - 233s 104ms/step - loss: 0.0032 - acc: 0.9989 - precision_m: 0.9771 - recall_m: 0.9850 - f1_m: 0.9810\n",
      "Epoch 7/20\n",
      "2245/2245 [==============================] - 230s 103ms/step - loss: 0.0027 - acc: 0.9991 - precision_m: 0.9803 - recall_m: 0.9875 - f1_m: 0.9838\n",
      "Epoch 8/20\n",
      "2245/2245 [==============================] - 229s 102ms/step - loss: 0.0024 - acc: 0.9992 - precision_m: 0.9828 - recall_m: 0.9890 - f1_m: 0.9859\n",
      "Epoch 9/20\n",
      "2245/2245 [==============================] - 229s 102ms/step - loss: 0.0021 - acc: 0.9993 - precision_m: 0.9847 - recall_m: 0.9903 - f1_m: 0.9875\n",
      "Epoch 10/20\n",
      "2245/2245 [==============================] - 228s 102ms/step - loss: 0.0019 - acc: 0.9994 - precision_m: 0.9863 - recall_m: 0.9912 - f1_m: 0.9887\n",
      "Epoch 11/20\n",
      "2245/2245 [==============================] - 228s 102ms/step - loss: 0.0018 - acc: 0.9994 - precision_m: 0.9874 - recall_m: 0.9922 - f1_m: 0.9897\n",
      "Epoch 12/20\n",
      "2245/2245 [==============================] - 228s 102ms/step - loss: 0.0016 - acc: 0.9995 - precision_m: 0.9887 - recall_m: 0.9928 - f1_m: 0.9907\n",
      "Epoch 13/20\n",
      "2245/2245 [==============================] - 230s 103ms/step - loss: 0.0015 - acc: 0.9995 - precision_m: 0.9892 - recall_m: 0.9932 - f1_m: 0.9912\n",
      "Epoch 14/20\n",
      "2245/2245 [==============================] - 248s 110ms/step - loss: 0.0014 - acc: 0.9995 - precision_m: 0.9901 - recall_m: 0.9937 - f1_m: 0.9919\n",
      "Epoch 15/20\n",
      "2245/2245 [==============================] - 278s 124ms/step - loss: 0.0013 - acc: 0.9996 - precision_m: 0.9905 - recall_m: 0.9941 - f1_m: 0.9923\n",
      "Epoch 16/20\n",
      "2245/2245 [==============================] - 252s 112ms/step - loss: 0.0013 - acc: 0.9996 - precision_m: 0.9911 - recall_m: 0.9944 - f1_m: 0.9927\n",
      "Epoch 17/20\n",
      "2245/2245 [==============================] - 308s 137ms/step - loss: 0.0012 - acc: 0.9996 - precision_m: 0.9914 - recall_m: 0.9947 - f1_m: 0.9930\n",
      "Epoch 18/20\n",
      "2245/2245 [==============================] - 323s 144ms/step - loss: 0.0011 - acc: 0.9996 - precision_m: 0.9920 - recall_m: 0.9947 - f1_m: 0.9933\n",
      "Epoch 19/20\n",
      "2245/2245 [==============================] - 329s 146ms/step - loss: 0.0011 - acc: 0.9996 - precision_m: 0.9922 - recall_m: 0.9950 - f1_m: 0.9936\n",
      "Epoch 20/20\n",
      "2245/2245 [==============================] - 313s 140ms/step - loss: 0.0010 - acc: 0.9997 - precision_m: 0.9927 - recall_m: 0.9953 - f1_m: 0.9940\n",
      "Score for fold 5: loss of 0.0173063725233078; acc of 0.9976599216461182; precision_m of 0.5783995985984802; recall_m of 0.6454018950462341; f1_m of 0.583759605884552 %\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "skf = StratifiedKFold(n_splits = 5, shuffle = True)\n",
    "\n",
    "fold_number = 1\n",
    "f1_per_fold = []\n",
    "recall_per_fold = []\n",
    "precision_per_fold = []\n",
    "acc_per_fold = []\n",
    "loss_per_fold = []\n",
    "\n",
    "for i, (train_index, val_index) in enumerate(skf.split(pad_tokens, np.sum(pad_tags, axis = 1))):\n",
    "    \n",
    "    print(\"Training on fold \" + str(i+1) + \"/5..........\")\n",
    "    \n",
    "    #Split training set and validation set\n",
    "    x_train, x_val = pad_tokens[train_index], pad_tokens[val_index]\n",
    "    y_train, y_val = pad_tags[train_index], pad_tags[val_index]\n",
    "    \n",
    "    #Oversample minority class in training set\n",
    "    print(str(fold_number) + \": started oversampling\")\n",
    "    index = 0\n",
    "    for token, tag in zip(x_train, y_train):\n",
    "        if np.sum(tag) >= 1:\n",
    "            token_arr = np.tile(token, 20).reshape((-1, len(token)))\n",
    "            tag_arr = np.tile(tag, 20).reshape((-1, len(tag)))\n",
    "            x_train = np.append(token_arr, x_train, axis=0)\n",
    "            y_train = np.append(tag_arr, y_train, axis=0)\n",
    "        index = index + 1\n",
    "    print(str(fold_number) + \": finished assigning sample weights\")\n",
    "    \n",
    "    #Assigning sample weights in training set\n",
    "    print(str(fold_number) + \": started oversampling\")\n",
    "    weights = class_weight.compute_class_weight('balanced',\n",
    "                                                 np.unique(np.ravel(y_train,order='C')),\n",
    "                                                 np.ravel(y_train,order='C'))\n",
    "    \n",
    "    train_tags2 = np.copy(y_train)\n",
    "    train_tokens2 = np.copy(x_train)\n",
    "    train_tags2 = train_tags2.astype(float)\n",
    "    \n",
    "    indexTotal = 0\n",
    "    for tags in train_tags2:\n",
    "        indexTags = 0\n",
    "        for symptom in tags:\n",
    "            if symptom == 1:\n",
    "                train_tags2[indexTotal][indexTags] = float(weights[1])\n",
    "            else:\n",
    "                train_tags2[indexTotal][indexTags] = float(weights[0])\n",
    "            indexTags = indexTags+1\n",
    "        indexTotal = indexTotal + 1\n",
    "   \n",
    "    weights = train_tags2.reshape((-1, 49, 1))\n",
    "    print(str(fold_number) + \": finished assigning sample weights\")\n",
    "    \n",
    "    #Getting Model Architecture\n",
    "    model = get_bilstm_lstm_model()\n",
    "    \n",
    "    #Running Model\n",
    "    history = model.fit(x_train, y_train, sample_weight = weights, batch_size=128, verbose=1, epochs=20)\n",
    "    \n",
    "    #Evaluate model\n",
    "    scores = model.evaluate(x_val, y_val, verbose = 0)\n",
    "    print(f'Score for fold {fold_number}: {model.metrics_names[0]} of {scores[0]}; {model.metrics_names[1]} of {scores[1]}; {model.metrics_names[2]} of {scores[2]}; {model.metrics_names[3]} of {scores[3]}; {model.metrics_names[4]} of {scores[4]} %')\n",
    "    f1_per_fold.append(scores[4])\n",
    "    recall_per_fold.append(scores[3])\n",
    "    precision_per_fold.append(scores[2])\n",
    "    acc_per_fold.append(scores[1])\n",
    "    loss_per_fold.append(scores[0])\n",
    "    \n",
    "    #Increase fold number\n",
    "    fold_number = fold_number + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score per fold\n",
      "-----------\n",
      "> Fold 1 - Loss: 0.017037667334079742 - Accuracy: 0.9976851940155029 - Precision: 0.5922558903694153 - Recall: 0.6298075914382935 - F1: 0.5819063782691956%\n",
      "-----------\n",
      "> Fold 2 - Loss: 0.01665506139397621 - Accuracy: 0.9977908730506897 - Precision: 0.6134408116340637 - Recall: 0.6505417823791504 - F1: 0.6020514965057373%\n",
      "-----------\n",
      "> Fold 3 - Loss: 0.017834406346082687 - Accuracy: 0.9976081848144531 - Precision: 0.568251371383667 - Recall: 0.6278537511825562 - F1: 0.5686147809028625%\n",
      "-----------\n",
      "> Fold 4 - Loss: 0.018074942752718925 - Accuracy: 0.9976130127906799 - Precision: 0.5596749186515808 - Recall: 0.6129063367843628 - F1: 0.5587538480758667%\n",
      "-----------\n",
      "> Fold 5 - Loss: 0.0173063725233078 - Accuracy: 0.9976599216461182 - Precision: 0.5783995985984802 - Recall: 0.6454018950462341 - F1: 0.583759605884552%\n",
      "------------\n",
      "Average scores for all folds:\n",
      "> Accuracy: 0.9976714372634887 (+- 6.633408816846438e-05)\n",
      "> Precision: 0.5824045181274414 (+- 0.018938250633025476)\n",
      "> Recall: 0.6333022713661194 (+- 0.013427545871236119)\n",
      "> F1: 0.5790172219276428 (+- 0.0146985056004385)\n",
      "> Loss: 0.017381690070033075\n",
      "------------\n"
     ]
    }
   ],
   "source": [
    "print('Score per fold')\n",
    "for i in range(0, len(acc_per_fold)):\n",
    "    print(\"-----------\")\n",
    "    print(f'> Fold {i+1} - Loss: {loss_per_fold[i]} - Accuracy: {acc_per_fold[i]} - Precision: {precision_per_fold[i]} - Recall: {recall_per_fold[i]} - F1: {f1_per_fold[i]}%')\n",
    "print('------------')\n",
    "print('Average scores for all folds:')\n",
    "print(f'> Accuracy: {np.mean(acc_per_fold)} (+- {np.std(acc_per_fold)})')\n",
    "print(f'> Precision: {np.mean(precision_per_fold)} (+- {np.std(precision_per_fold)})')\n",
    "print(f'> Recall: {np.mean(recall_per_fold)} (+- {np.std(recall_per_fold)})')\n",
    "print(f'> F1: {np.mean(f1_per_fold)} (+- {np.std(f1_per_fold)})')\n",
    "print(f'> Loss: {np.mean(loss_per_fold)}')\n",
    "print('------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
