{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras.backend as K\n",
    "from tensorflow.python.keras.backend import get_session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import imblearn\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence</th>\n",
       "      <th>Word</th>\n",
       "      <th>Tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sentence: 1</td>\n",
       "      <td>RECORD</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sentence: 2</td>\n",
       "      <td>OC</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>AM</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>gallstone</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>pancreatitis</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>949802</th>\n",
       "      <td>NaN</td>\n",
       "      <td>M.D.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>949803</th>\n",
       "      <td>Sentence: 132094</td>\n",
       "      <td>END</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>949804</th>\n",
       "      <td>NaN</td>\n",
       "      <td>OF</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>949805</th>\n",
       "      <td>NaN</td>\n",
       "      <td>DISCHARGE</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>949806</th>\n",
       "      <td>NaN</td>\n",
       "      <td>ORDERS</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>949807 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                Sentence          Word  Tag\n",
       "0            Sentence: 1        RECORD    0\n",
       "1            Sentence: 2            OC    0\n",
       "2                    NaN            AM    0\n",
       "3                    NaN     gallstone    0\n",
       "4                    NaN  pancreatitis    0\n",
       "...                  ...           ...  ...\n",
       "949802               NaN          M.D.    0\n",
       "949803  Sentence: 132094           END    0\n",
       "949804               NaN            OF    0\n",
       "949805               NaN     DISCHARGE    0\n",
       "949806               NaN        ORDERS    0\n",
       "\n",
       "[949807 rows x 3 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('./OUTPUT/dataset.csv', encoding= 'unicode_escape')\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Groupby"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-5-73aff18756c8>:2: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
      "  data_group = data_fillna.groupby(['Sentence'],as_index=False\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence</th>\n",
       "      <th>Word</th>\n",
       "      <th>Tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sentence: 1</td>\n",
       "      <td>[RECORD]</td>\n",
       "      <td>[0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sentence: 10</td>\n",
       "      <td>[WILL, D/C, ORDER, BE, USED, AS, THE, D/C, SUM...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Sentence: 100</td>\n",
       "      <td>[prandial, N/V/severe, upper, abdominal, pain....</td>\n",
       "      <td>[0, 1, 0, 1, 1, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Sentence: 1000</td>\n",
       "      <td>[normal, limits., Cardiac, catheterization, da...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sentence: 10000</td>\n",
       "      <td>[year, old, Black, female, with, significant, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132089</th>\n",
       "      <td>Sentence: 99995</td>\n",
       "      <td>[Height, foot, inch, and, weight, kg., Tempera...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132090</th>\n",
       "      <td>Sentence: 99996</td>\n",
       "      <td>[degrees, heart, rate, and, sinus, blood, pres...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132091</th>\n",
       "      <td>Sentence: 99997</td>\n",
       "      <td>[blood, pressure, left, arm, and, oxygen, satu...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132092</th>\n",
       "      <td>Sentence: 99998</td>\n",
       "      <td>[No, carotid, bruits, regular, rate, and, rhyt...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132093</th>\n",
       "      <td>Sentence: 99999</td>\n",
       "      <td>[systolic, murmur, along, the, right, upper, s...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>132094 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               Sentence                                               Word  \\\n",
       "0           Sentence: 1                                           [RECORD]   \n",
       "1          Sentence: 10  [WILL, D/C, ORDER, BE, USED, AS, THE, D/C, SUM...   \n",
       "2         Sentence: 100  [prandial, N/V/severe, upper, abdominal, pain....   \n",
       "3        Sentence: 1000  [normal, limits., Cardiac, catheterization, da...   \n",
       "4       Sentence: 10000  [year, old, Black, female, with, significant, ...   \n",
       "...                 ...                                                ...   \n",
       "132089  Sentence: 99995  [Height, foot, inch, and, weight, kg., Tempera...   \n",
       "132090  Sentence: 99996  [degrees, heart, rate, and, sinus, blood, pres...   \n",
       "132091  Sentence: 99997  [blood, pressure, left, arm, and, oxygen, satu...   \n",
       "132092  Sentence: 99998  [No, carotid, bruits, regular, rate, and, rhyt...   \n",
       "132093  Sentence: 99999  [systolic, murmur, along, the, right, upper, s...   \n",
       "\n",
       "                                   Tag  \n",
       "0                                  [0]  \n",
       "1       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]  \n",
       "2          [0, 1, 0, 1, 1, 0, 0, 0, 0]  \n",
       "3             [0, 0, 0, 0, 0, 0, 0, 0]  \n",
       "4       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]  \n",
       "...                                ...  \n",
       "132089           [0, 0, 0, 0, 0, 0, 0]  \n",
       "132090     [0, 0, 0, 0, 0, 0, 0, 0, 0]  \n",
       "132091           [0, 0, 0, 0, 0, 0, 0]  \n",
       "132092     [0, 0, 0, 0, 0, 0, 0, 0, 0]  \n",
       "132093     [0, 0, 0, 0, 0, 0, 0, 0, 0]  \n",
       "\n",
       "[132094 rows x 3 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_fillna = data.fillna(method='ffill', axis=0)\n",
    "data_group = data_fillna.groupby(['Sentence'],as_index=False\n",
    "                                )['Word', 'Tag'].agg(lambda x: list(x))\n",
    "\n",
    "#data_fillna\n",
    "data_group"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = data_group['Word'].tolist()  \n",
    "labels = data_group['Tag'].tolist()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 34275 unique tokens.\n",
      "[[  115     0     0 ...     0     0     0]\n",
      " [   44   145   106 ...     0     0     0]\n",
      " [ 6315 15212   259 ...     0     0     0]\n",
      " ...\n",
      " [   42    70    33 ...     0     0     0]\n",
      " [   13   421  1398 ...     0     0     0]\n",
      " [  327   561  1373 ...     0     0     0]]\n",
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 1 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n",
      "Shape of data tensor: (132094, 49)\n",
      "Shape of label tensor: (132094, 49)\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(texts)\n",
    "sequences = tokenizer.texts_to_sequences(texts)\n",
    "\n",
    "word_index = tokenizer.word_index\n",
    "print('Found %s unique tokens.' % len(word_index))\n",
    "\n",
    "pad_tokens = pad_sequences(sequences, maxlen=49, dtype='int32', padding='post', value= 0)\n",
    "print(pad_tokens)\n",
    "pad_tags = pad_sequences(labels, maxlen=49, dtype='int32', padding='post', value= 0)\n",
    "train_tokens, test_tokens, train_tags, test_tags = train_test_split(pad_tokens, pad_tags, test_size=0.3, train_size=0.7, random_state=2020)\n",
    "print(pad_tags)\n",
    "print('Shape of data tensor:', pad_tokens.shape)\n",
    "print('Shape of label tensor:', pad_tags.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GLOVE Embedding Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 400000 word vectors.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "embeddings_index = {}\n",
    "f = open(os.path.join(r'./GLOVE', 'glove.6B.300d.txt'), encoding=\"utf8\")\n",
    "for line in f:\n",
    "    values = line.split()\n",
    "    word = values[0]\n",
    "    coefs = np.asarray(values[1:], dtype='float32')\n",
    "    embeddings_index[word] = coefs\n",
    "f.close()\n",
    "\n",
    "print('Found %s word vectors.' % len(embeddings_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_matrix = np.zeros((len(word_index) + 1, 300))\n",
    "for word, i in word_index.items():\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        # words not found in embedding index will be all-zeros.\n",
    "        embedding_matrix[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Embedding\n",
    "\n",
    "embedding_layer = Embedding(len(word_index) + 1,\n",
    "                            300,\n",
    "                            weights=[embedding_matrix],\n",
    "                            input_length=49,\n",
    "                            trainable=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import Sequential, Model, Input\n",
    "from tensorflow.keras.layers import LSTM, Embedding, Dense, TimeDistributed, Dropout, Bidirectional\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from keras import backend as K\n",
    "import keras as keras\n",
    "from keras.datasets import mnist\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from keras import metrics\n",
    "from sklearn.utils import class_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recall_m(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    recall = true_positives / (possible_positives + K.epsilon())\n",
    "    return recall\n",
    "\n",
    "def precision_m(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\n",
    "    return precision\n",
    "\n",
    "def f1_m(y_true, y_pred):\n",
    "    precision = precision_m(y_true, y_pred)\n",
    "    recall = recall_m(y_true, y_pred)\n",
    "    return 2*((precision*recall)/(precision+recall+K.epsilon()))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bilstm_lstm_model():\n",
    "    model = Sequential()\n",
    "\n",
    "    # Add Embedding layer\n",
    "    model.add(embedding_layer)\n",
    "    # Add bidirectional LSTM\n",
    "    model.add(Bidirectional(LSTM(units=32, return_sequences=True, dropout=0.5, recurrent_dropout=0.5), merge_mode = 'concat'))\n",
    "\n",
    "    \n",
    "    # Add LSTM\n",
    "    model.add(LSTM(units=32, return_sequences=True, dropout=0.5, recurrent_dropout=0.5))\n",
    "    model.add(LSTM(units=32, return_sequences=True, dropout=0.5, recurrent_dropout=0.5))\n",
    "    # Add timeDistributed Layer\n",
    "    model.add(TimeDistributed(Dense(1, activation=\"sigmoid\")))\n",
    "    \n",
    "    #Optimiser \n",
    "    adam = tf.keras.optimizers.Adam(learning_rate=0.001, beta_1=0.9, beta_2=0.999)\n",
    "    \n",
    "    # Compile model\n",
    "    model.compile(loss='binary_crossentropy', sample_weight_mode=\"temporal\", optimizer='adam', metrics=['acc', precision_m, recall_m, f1_m])\n",
    "    model.summary()\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jonat\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:666: UserWarning: The least populated class in y has only 3 members, which is less than n_splits=10.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on fold 1/10..........\n",
      "1: started assigning sample weights\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jonat\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:70: FutureWarning: Pass classes=[0 1], y=[0 0 0 ... 0 0 0] as keyword args. From version 1.0 (renaming of 0.25) passing these as positional arguments will result in an error\n",
      "  warnings.warn(f\"Pass {args_msg} as keyword args. From version \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1: finished assigning sample weights\n",
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_1 (Embedding)     (None, 49, 300)           10282800  \n",
      "                                                                 \n",
      " bidirectional_3 (Bidirectio  (None, 49, 64)           85248     \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " lstm_10 (LSTM)              (None, 49, 32)            12416     \n",
      "                                                                 \n",
      " lstm_11 (LSTM)              (None, 49, 32)            8320      \n",
      "                                                                 \n",
      " time_distributed_3 (TimeDis  (None, 49, 1)            33        \n",
      " tributed)                                                       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 10,388,817\n",
      "Trainable params: 10,388,817\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "1858/1858 [==============================] - 579s 304ms/step - loss: 0.0167 - acc: 0.9968 - precision_m: 0.5397 - recall_m: 0.3879 - f1_m: 0.4233\n",
      "Epoch 2/20\n",
      "1858/1858 [==============================] - 616s 332ms/step - loss: 0.0061 - acc: 0.9982 - precision_m: 0.7708 - recall_m: 0.7010 - f1_m: 0.7152\n",
      "Epoch 3/20\n",
      "1858/1858 [==============================] - 624s 336ms/step - loss: 0.0052 - acc: 0.9984 - precision_m: 0.7993 - recall_m: 0.7388 - f1_m: 0.7496\n",
      "Epoch 4/20\n",
      "1858/1858 [==============================] - 625s 337ms/step - loss: 0.0045 - acc: 0.9986 - precision_m: 0.8238 - recall_m: 0.7673 - f1_m: 0.7787\n",
      "Epoch 5/20\n",
      "1858/1858 [==============================] - 607s 327ms/step - loss: 0.0040 - acc: 0.9987 - precision_m: 0.8429 - recall_m: 0.7856 - f1_m: 0.7986\n",
      "Epoch 6/20\n",
      "1858/1858 [==============================] - 612s 330ms/step - loss: 0.0037 - acc: 0.9988 - precision_m: 0.8454 - recall_m: 0.7999 - f1_m: 0.8087\n",
      "Epoch 7/20\n",
      "1858/1858 [==============================] - 611s 329ms/step - loss: 0.0034 - acc: 0.9989 - precision_m: 0.8629 - recall_m: 0.8237 - f1_m: 0.8312\n",
      "Epoch 8/20\n",
      "1858/1858 [==============================] - 608s 327ms/step - loss: 0.0032 - acc: 0.9990 - precision_m: 0.8686 - recall_m: 0.8334 - f1_m: 0.8400\n",
      "Epoch 9/20\n",
      "1858/1858 [==============================] - 606s 326ms/step - loss: 0.0030 - acc: 0.9991 - precision_m: 0.8751 - recall_m: 0.8443 - f1_m: 0.8495\n",
      "Epoch 10/20\n",
      "1858/1858 [==============================] - 606s 326ms/step - loss: 0.0028 - acc: 0.9991 - precision_m: 0.8806 - recall_m: 0.8577 - f1_m: 0.8592\n",
      "Epoch 11/20\n",
      "1858/1858 [==============================] - 606s 326ms/step - loss: 0.0027 - acc: 0.9992 - precision_m: 0.8869 - recall_m: 0.8651 - f1_m: 0.8673\n",
      "Epoch 12/20\n",
      "1858/1858 [==============================] - 604s 325ms/step - loss: 0.0026 - acc: 0.9992 - precision_m: 0.8913 - recall_m: 0.8698 - f1_m: 0.8716\n",
      "Epoch 13/20\n",
      "1858/1858 [==============================] - 606s 326ms/step - loss: 0.0024 - acc: 0.9992 - precision_m: 0.8960 - recall_m: 0.8749 - f1_m: 0.8769\n",
      "Epoch 14/20\n",
      "1858/1858 [==============================] - 601s 324ms/step - loss: 0.0023 - acc: 0.9993 - precision_m: 0.8951 - recall_m: 0.8786 - f1_m: 0.8791\n",
      "Epoch 15/20\n",
      "1858/1858 [==============================] - 604s 325ms/step - loss: 0.0023 - acc: 0.9993 - precision_m: 0.9032 - recall_m: 0.8825 - f1_m: 0.8852\n",
      "Epoch 16/20\n",
      "1858/1858 [==============================] - 602s 324ms/step - loss: 0.0021 - acc: 0.9993 - precision_m: 0.9069 - recall_m: 0.8869 - f1_m: 0.8893\n",
      "Epoch 17/20\n",
      "1858/1858 [==============================] - 602s 324ms/step - loss: 0.0021 - acc: 0.9993 - precision_m: 0.9110 - recall_m: 0.8911 - f1_m: 0.8941\n",
      "Epoch 18/20\n",
      "1858/1858 [==============================] - 602s 324ms/step - loss: 0.0020 - acc: 0.9994 - precision_m: 0.9105 - recall_m: 0.8949 - f1_m: 0.8961\n",
      "Epoch 19/20\n",
      "1858/1858 [==============================] - 598s 322ms/step - loss: 0.0019 - acc: 0.9994 - precision_m: 0.9110 - recall_m: 0.8982 - f1_m: 0.8982\n",
      "Epoch 20/20\n",
      "1858/1858 [==============================] - 626s 337ms/step - loss: 0.0019 - acc: 0.9994 - precision_m: 0.9202 - recall_m: 0.9019 - f1_m: 0.9049\n",
      "Score for fold 1: loss of 0.008424668572843075; acc of 0.9981651306152344; precision_m of 0.7087938189506531; recall_m of 0.669576108455658; f1_m of 0.6605508327484131 %\n",
      "Training on fold 2/10..........\n",
      "2: started assigning sample weights\n",
      "2: finished assigning sample weights\n",
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_1 (Embedding)     (None, 49, 300)           10282800  \n",
      "                                                                 \n",
      " bidirectional_4 (Bidirectio  (None, 49, 64)           85248     \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " lstm_13 (LSTM)              (None, 49, 32)            12416     \n",
      "                                                                 \n",
      " lstm_14 (LSTM)              (None, 49, 32)            8320      \n",
      "                                                                 \n",
      " time_distributed_4 (TimeDis  (None, 49, 1)            33        \n",
      " tributed)                                                       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 10,388,817\n",
      "Trainable params: 10,388,817\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "1858/1858 [==============================] - 558s 290ms/step - loss: 0.0131 - acc: 0.9973 - precision_m: 0.6507 - recall_m: 0.5217 - f1_m: 0.5504\n",
      "Epoch 2/20\n",
      "1858/1858 [==============================] - 539s 290ms/step - loss: 0.0044 - acc: 0.9987 - precision_m: 0.8163 - recall_m: 0.8059 - f1_m: 0.7970\n",
      "Epoch 3/20\n",
      "1858/1858 [==============================] - 539s 290ms/step - loss: 0.0035 - acc: 0.9989 - precision_m: 0.8491 - recall_m: 0.8303 - f1_m: 0.8285\n",
      "Epoch 4/20\n",
      "1858/1858 [==============================] - 541s 291ms/step - loss: 0.0030 - acc: 0.9991 - precision_m: 0.8790 - recall_m: 0.8518 - f1_m: 0.8536\n",
      "Epoch 5/20\n",
      "1858/1858 [==============================] - 541s 291ms/step - loss: 0.0028 - acc: 0.9992 - precision_m: 0.8862 - recall_m: 0.8698 - f1_m: 0.8689\n",
      "Epoch 6/20\n",
      "1858/1858 [==============================] - 542s 292ms/step - loss: 0.0026 - acc: 0.9992 - precision_m: 0.8927 - recall_m: 0.8730 - f1_m: 0.8742\n",
      "Epoch 7/20\n",
      "1858/1858 [==============================] - 543s 292ms/step - loss: 0.0024 - acc: 0.9993 - precision_m: 0.9009 - recall_m: 0.8799 - f1_m: 0.8825\n",
      "Epoch 8/20\n",
      "1858/1858 [==============================] - 542s 292ms/step - loss: 0.0022 - acc: 0.9993 - precision_m: 0.9067 - recall_m: 0.8865 - f1_m: 0.8891\n",
      "Epoch 9/20\n",
      "1858/1858 [==============================] - 543s 292ms/step - loss: 0.0021 - acc: 0.9993 - precision_m: 0.9071 - recall_m: 0.8896 - f1_m: 0.8914\n",
      "Epoch 10/20\n",
      "1858/1858 [==============================] - 544s 293ms/step - loss: 0.0020 - acc: 0.9994 - precision_m: 0.9146 - recall_m: 0.8991 - f1_m: 0.9007\n",
      "Epoch 11/20\n",
      "1858/1858 [==============================] - 543s 292ms/step - loss: 0.0020 - acc: 0.9994 - precision_m: 0.9140 - recall_m: 0.9000 - f1_m: 0.9001\n",
      "Epoch 12/20\n",
      "1858/1858 [==============================] - 543s 293ms/step - loss: 0.0019 - acc: 0.9994 - precision_m: 0.9129 - recall_m: 0.9012 - f1_m: 0.9007\n",
      "Epoch 13/20\n",
      "1858/1858 [==============================] - 543s 292ms/step - loss: 0.0018 - acc: 0.9994 - precision_m: 0.9214 - recall_m: 0.9104 - f1_m: 0.9096\n",
      "Epoch 14/20\n",
      "1858/1858 [==============================] - 543s 292ms/step - loss: 0.0018 - acc: 0.9994 - precision_m: 0.9217 - recall_m: 0.9057 - f1_m: 0.9075\n",
      "Epoch 15/20\n",
      "1858/1858 [==============================] - 541s 291ms/step - loss: 0.0018 - acc: 0.9994 - precision_m: 0.9241 - recall_m: 0.9079 - f1_m: 0.9098\n",
      "Epoch 16/20\n",
      "1858/1858 [==============================] - 542s 292ms/step - loss: 0.0017 - acc: 0.9995 - precision_m: 0.9250 - recall_m: 0.9078 - f1_m: 0.9106\n",
      "Epoch 17/20\n",
      "1858/1858 [==============================] - 548s 295ms/step - loss: 0.0016 - acc: 0.9995 - precision_m: 0.9286 - recall_m: 0.9161 - f1_m: 0.9169\n",
      "Epoch 18/20\n",
      "1858/1858 [==============================] - 515s 277ms/step - loss: 0.0016 - acc: 0.9995 - precision_m: 0.9295 - recall_m: 0.9183 - f1_m: 0.9186\n",
      "Epoch 19/20\n",
      "1858/1858 [==============================] - 552s 297ms/step - loss: 0.0015 - acc: 0.9995 - precision_m: 0.9335 - recall_m: 0.9169 - f1_m: 0.9200\n",
      "Epoch 20/20\n",
      "1858/1858 [==============================] - 553s 298ms/step - loss: 0.0015 - acc: 0.9995 - precision_m: 0.9310 - recall_m: 0.9204 - f1_m: 0.9206\n",
      "Score for fold 2: loss of 0.004767275415360928; acc of 0.9988278746604919; precision_m of 0.7777432799339294; recall_m of 0.7450389266014099; f1_m of 0.744812548160553 %\n",
      "Training on fold 3/10..........\n",
      "3: started assigning sample weights\n",
      "3: finished assigning sample weights\n",
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_1 (Embedding)     (None, 49, 300)           10282800  \n",
      "                                                                 \n",
      " bidirectional_5 (Bidirectio  (None, 49, 64)           85248     \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " lstm_16 (LSTM)              (None, 49, 32)            12416     \n",
      "                                                                 \n",
      " lstm_17 (LSTM)              (None, 49, 32)            8320      \n",
      "                                                                 \n",
      " time_distributed_5 (TimeDis  (None, 49, 1)            33        \n",
      " tributed)                                                       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 10,388,817\n",
      "Trainable params: 10,388,817\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "1858/1858 [==============================] - 819s 430ms/step - loss: 0.0112 - acc: 0.9977 - precision_m: 0.6887 - recall_m: 0.5709 - f1_m: 0.5964\n",
      "Epoch 2/20\n",
      "1858/1858 [==============================] - 800s 431ms/step - loss: 0.0036 - acc: 0.9989 - precision_m: 0.8477 - recall_m: 0.8406 - f1_m: 0.8315\n",
      "Epoch 3/20\n",
      "1858/1858 [==============================] - 802s 432ms/step - loss: 0.0028 - acc: 0.9991 - precision_m: 0.8819 - recall_m: 0.8642 - f1_m: 0.8640\n",
      "Epoch 4/20\n",
      "1858/1858 [==============================] - 802s 432ms/step - loss: 0.0025 - acc: 0.9992 - precision_m: 0.8958 - recall_m: 0.8773 - f1_m: 0.8788\n",
      "Epoch 5/20\n",
      "1858/1858 [==============================] - 802s 431ms/step - loss: 0.0022 - acc: 0.9993 - precision_m: 0.9005 - recall_m: 0.8914 - f1_m: 0.8886\n",
      "Epoch 6/20\n",
      "1858/1858 [==============================] - 799s 430ms/step - loss: 0.0021 - acc: 0.9994 - precision_m: 0.9081 - recall_m: 0.8949 - f1_m: 0.8946\n",
      "Epoch 7/20\n",
      "1858/1858 [==============================] - 801s 431ms/step - loss: 0.0019 - acc: 0.9994 - precision_m: 0.9145 - recall_m: 0.9024 - f1_m: 0.9022\n",
      "Epoch 8/20\n",
      "1858/1858 [==============================] - 801s 431ms/step - loss: 0.0019 - acc: 0.9994 - precision_m: 0.9157 - recall_m: 0.9049 - f1_m: 0.9041\n",
      "Epoch 9/20\n",
      "1858/1858 [==============================] - 803s 432ms/step - loss: 0.0018 - acc: 0.9995 - precision_m: 0.9227 - recall_m: 0.9120 - f1_m: 0.9117\n",
      "Epoch 10/20\n",
      "1858/1858 [==============================] - 726s 391ms/step - loss: 0.0017 - acc: 0.9995 - precision_m: 0.9214 - recall_m: 0.9128 - f1_m: 0.9113\n",
      "Epoch 11/20\n",
      "1858/1858 [==============================] - 710s 382ms/step - loss: 0.0016 - acc: 0.9995 - precision_m: 0.9249 - recall_m: 0.9159 - f1_m: 0.9143\n",
      "Epoch 12/20\n",
      "1858/1858 [==============================] - 711s 382ms/step - loss: 0.0016 - acc: 0.9995 - precision_m: 0.9312 - recall_m: 0.9212 - f1_m: 0.9209\n",
      "Epoch 13/20\n",
      "1858/1858 [==============================] - 713s 384ms/step - loss: 0.0016 - acc: 0.9995 - precision_m: 0.9296 - recall_m: 0.9194 - f1_m: 0.9193\n",
      "Epoch 14/20\n",
      "1858/1858 [==============================] - 711s 383ms/step - loss: 0.0015 - acc: 0.9995 - precision_m: 0.9353 - recall_m: 0.9234 - f1_m: 0.9242\n",
      "Epoch 15/20\n",
      "1858/1858 [==============================] - 711s 383ms/step - loss: 0.0015 - acc: 0.9995 - precision_m: 0.9320 - recall_m: 0.9252 - f1_m: 0.9239\n",
      "Epoch 16/20\n",
      "1858/1858 [==============================] - 712s 383ms/step - loss: 0.0014 - acc: 0.9995 - precision_m: 0.9355 - recall_m: 0.9261 - f1_m: 0.9260\n",
      "Epoch 17/20\n",
      "1858/1858 [==============================] - 711s 383ms/step - loss: 0.0014 - acc: 0.9995 - precision_m: 0.9337 - recall_m: 0.9254 - f1_m: 0.9241\n",
      "Epoch 18/20\n",
      "1858/1858 [==============================] - 711s 383ms/step - loss: 0.0014 - acc: 0.9996 - precision_m: 0.9392 - recall_m: 0.9288 - f1_m: 0.9288\n",
      "Epoch 19/20\n",
      "1858/1858 [==============================] - 711s 383ms/step - loss: 0.0014 - acc: 0.9996 - precision_m: 0.9396 - recall_m: 0.9275 - f1_m: 0.9286\n",
      "Epoch 20/20\n",
      "1858/1858 [==============================] - 711s 383ms/step - loss: 0.0013 - acc: 0.9996 - precision_m: 0.9398 - recall_m: 0.9301 - f1_m: 0.9303\n",
      "Score for fold 3: loss of 0.0038301546592265368; acc of 0.9990360140800476; precision_m of 0.7775216102600098; recall_m of 0.7582077980041504; f1_m of 0.7497233748435974 %\n",
      "Training on fold 4/10..........\n",
      "4: started assigning sample weights\n",
      "4: finished assigning sample weights\n",
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_1 (Embedding)     (None, 49, 300)           10282800  \n",
      "                                                                 \n",
      " bidirectional_6 (Bidirectio  (None, 49, 64)           85248     \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " lstm_19 (LSTM)              (None, 49, 32)            12416     \n",
      "                                                                 \n",
      " lstm_20 (LSTM)              (None, 49, 32)            8320      \n",
      "                                                                 \n",
      " time_distributed_6 (TimeDis  (None, 49, 1)            33        \n",
      " tributed)                                                       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 10,388,817\n",
      "Trainable params: 10,388,817\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "1858/1858 [==============================] - 616s 323ms/step - loss: 0.0117 - acc: 0.9974 - precision_m: 0.6685 - recall_m: 0.5449 - f1_m: 0.5722\n",
      "Epoch 2/20\n",
      "1858/1858 [==============================] - 599s 322ms/step - loss: 0.0035 - acc: 0.9989 - precision_m: 0.8470 - recall_m: 0.8428 - f1_m: 0.8338\n",
      "Epoch 3/20\n",
      "1858/1858 [==============================] - 598s 322ms/step - loss: 0.0026 - acc: 0.9992 - precision_m: 0.8874 - recall_m: 0.8705 - f1_m: 0.8701\n",
      "Epoch 4/20\n",
      "1858/1858 [==============================] - 598s 322ms/step - loss: 0.0022 - acc: 0.9993 - precision_m: 0.9007 - recall_m: 0.8884 - f1_m: 0.8873\n",
      "Epoch 5/20\n",
      "1858/1858 [==============================] - 597s 321ms/step - loss: 0.0020 - acc: 0.9994 - precision_m: 0.9072 - recall_m: 0.8972 - f1_m: 0.8951\n",
      "Epoch 6/20\n",
      "1858/1858 [==============================] - 597s 321ms/step - loss: 0.0019 - acc: 0.9994 - precision_m: 0.9183 - recall_m: 0.9084 - f1_m: 0.9068\n",
      "Epoch 7/20\n",
      "1858/1858 [==============================] - 574s 309ms/step - loss: 0.0017 - acc: 0.9994 - precision_m: 0.9228 - recall_m: 0.9105 - f1_m: 0.9104\n",
      "Epoch 8/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1858/1858 [==============================] - 620s 334ms/step - loss: 0.0017 - acc: 0.9995 - precision_m: 0.9278 - recall_m: 0.9154 - f1_m: 0.9164\n",
      "Epoch 9/20\n",
      "1858/1858 [==============================] - 623s 335ms/step - loss: 0.0016 - acc: 0.9995 - precision_m: 0.9278 - recall_m: 0.9178 - f1_m: 0.9173\n",
      "Epoch 10/20\n",
      "1858/1858 [==============================] - 622s 335ms/step - loss: 0.0016 - acc: 0.9995 - precision_m: 0.9270 - recall_m: 0.9173 - f1_m: 0.9168\n",
      "Epoch 11/20\n",
      "1858/1858 [==============================] - 620s 334ms/step - loss: 0.0015 - acc: 0.9995 - precision_m: 0.9302 - recall_m: 0.9221 - f1_m: 0.9208\n",
      "Epoch 12/20\n",
      "1858/1858 [==============================] - 623s 335ms/step - loss: 0.0015 - acc: 0.9995 - precision_m: 0.9336 - recall_m: 0.9261 - f1_m: 0.9251\n",
      "Epoch 13/20\n",
      "1858/1858 [==============================] - 623s 335ms/step - loss: 0.0014 - acc: 0.9995 - precision_m: 0.9335 - recall_m: 0.9270 - f1_m: 0.9249\n",
      "Epoch 14/20\n",
      "1858/1858 [==============================] - 624s 336ms/step - loss: 0.0014 - acc: 0.9995 - precision_m: 0.9345 - recall_m: 0.9279 - f1_m: 0.9265\n",
      "Epoch 15/20\n",
      "1858/1858 [==============================] - 624s 336ms/step - loss: 0.0014 - acc: 0.9996 - precision_m: 0.9344 - recall_m: 0.9267 - f1_m: 0.9256\n",
      "Epoch 16/20\n",
      "1858/1858 [==============================] - 622s 335ms/step - loss: 0.0013 - acc: 0.9996 - precision_m: 0.9362 - recall_m: 0.9306 - f1_m: 0.9286\n",
      "Epoch 17/20\n",
      "1858/1858 [==============================] - 623s 335ms/step - loss: 0.0013 - acc: 0.9996 - precision_m: 0.9386 - recall_m: 0.9310 - f1_m: 0.9303\n",
      "Epoch 18/20\n",
      "1858/1858 [==============================] - 622s 335ms/step - loss: 0.0013 - acc: 0.9996 - precision_m: 0.9402 - recall_m: 0.9318 - f1_m: 0.9317\n",
      "Epoch 19/20\n",
      "1858/1858 [==============================] - 620s 334ms/step - loss: 0.0013 - acc: 0.9996 - precision_m: 0.9403 - recall_m: 0.9366 - f1_m: 0.9344\n",
      "Epoch 20/20\n",
      "1858/1858 [==============================] - 622s 335ms/step - loss: 0.0012 - acc: 0.9996 - precision_m: 0.9401 - recall_m: 0.9368 - f1_m: 0.9343\n",
      "Score for fold 4: loss of 0.003117585787549615; acc of 0.9991922974586487; precision_m of 0.8177358508110046; recall_m of 0.791504442691803; f1_m of 0.7899191379547119 %\n",
      "Training on fold 5/10..........\n",
      "5: started assigning sample weights\n",
      "5: finished assigning sample weights\n",
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_1 (Embedding)     (None, 49, 300)           10282800  \n",
      "                                                                 \n",
      " bidirectional_7 (Bidirectio  (None, 49, 64)           85248     \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " lstm_22 (LSTM)              (None, 49, 32)            12416     \n",
      "                                                                 \n",
      " lstm_23 (LSTM)              (None, 49, 32)            8320      \n",
      "                                                                 \n",
      " time_distributed_7 (TimeDis  (None, 49, 1)            33        \n",
      " tributed)                                                       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 10,388,817\n",
      "Trainable params: 10,388,817\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "1858/1858 [==============================] - 933s 492ms/step - loss: 0.0098 - acc: 0.9979 - precision_m: 0.7045 - recall_m: 0.5997 - f1_m: 0.6232\n",
      "Epoch 2/20\n",
      "1858/1858 [==============================] - 918s 494ms/step - loss: 0.0032 - acc: 0.9990 - precision_m: 0.8630 - recall_m: 0.8527 - f1_m: 0.8474\n",
      "Epoch 3/20\n",
      "1858/1858 [==============================] - 838s 451ms/step - loss: 0.0025 - acc: 0.9992 - precision_m: 0.8892 - recall_m: 0.8801 - f1_m: 0.8762\n",
      "Epoch 4/20\n",
      "1858/1858 [==============================] - 788s 424ms/step - loss: 0.0021 - acc: 0.9993 - precision_m: 0.9031 - recall_m: 0.8939 - f1_m: 0.8909\n",
      "Epoch 5/20\n",
      "1858/1858 [==============================] - 788s 424ms/step - loss: 0.0019 - acc: 0.9994 - precision_m: 0.9177 - recall_m: 0.9006 - f1_m: 0.9027\n",
      "Epoch 6/20\n",
      "1858/1858 [==============================] - 789s 425ms/step - loss: 0.0017 - acc: 0.9995 - precision_m: 0.9232 - recall_m: 0.9147 - f1_m: 0.9132\n",
      "Epoch 7/20\n",
      "1858/1858 [==============================] - 789s 424ms/step - loss: 0.0016 - acc: 0.9995 - precision_m: 0.9290 - recall_m: 0.9167 - f1_m: 0.9179\n",
      "Epoch 8/20\n",
      "1858/1858 [==============================] - 788s 424ms/step - loss: 0.0016 - acc: 0.9995 - precision_m: 0.9300 - recall_m: 0.9201 - f1_m: 0.9191\n",
      "Epoch 9/20\n",
      "1858/1858 [==============================] - 788s 424ms/step - loss: 0.0015 - acc: 0.9995 - precision_m: 0.9253 - recall_m: 0.9186 - f1_m: 0.9166\n",
      "Epoch 10/20\n",
      "1858/1858 [==============================] - 788s 424ms/step - loss: 0.0014 - acc: 0.9995 - precision_m: 0.9308 - recall_m: 0.9220 - f1_m: 0.9212\n",
      "Epoch 11/20\n",
      "1858/1858 [==============================] - 790s 425ms/step - loss: 0.0014 - acc: 0.9995 - precision_m: 0.9371 - recall_m: 0.9296 - f1_m: 0.9288\n",
      "Epoch 12/20\n",
      "1858/1858 [==============================] - 788s 424ms/step - loss: 0.0013 - acc: 0.9996 - precision_m: 0.9382 - recall_m: 0.9302 - f1_m: 0.9296\n",
      "Epoch 13/20\n",
      "1858/1858 [==============================] - 788s 424ms/step - loss: 0.0013 - acc: 0.9996 - precision_m: 0.9375 - recall_m: 0.9318 - f1_m: 0.9300\n",
      "Epoch 14/20\n",
      "1858/1858 [==============================] - 788s 424ms/step - loss: 0.0013 - acc: 0.9996 - precision_m: 0.9376 - recall_m: 0.9297 - f1_m: 0.9296\n",
      "Epoch 15/20\n",
      "1858/1858 [==============================] - 788s 424ms/step - loss: 0.0013 - acc: 0.9996 - precision_m: 0.9416 - recall_m: 0.9325 - f1_m: 0.9326\n",
      "Epoch 16/20\n",
      "1858/1858 [==============================] - 783s 422ms/step - loss: 0.0012 - acc: 0.9996 - precision_m: 0.9428 - recall_m: 0.9356 - f1_m: 0.9355\n",
      "Epoch 17/20\n",
      "1858/1858 [==============================] - 823s 443ms/step - loss: 0.0012 - acc: 0.9996 - precision_m: 0.9442 - recall_m: 0.9367 - f1_m: 0.9364\n",
      "Epoch 18/20\n",
      "1858/1858 [==============================] - 826s 445ms/step - loss: 0.0012 - acc: 0.9996 - precision_m: 0.9401 - recall_m: 0.9338 - f1_m: 0.9325\n",
      "Epoch 19/20\n",
      "1858/1858 [==============================] - 826s 445ms/step - loss: 0.0012 - acc: 0.9996 - precision_m: 0.9434 - recall_m: 0.9350 - f1_m: 0.9350\n",
      "Epoch 20/20\n",
      "1858/1858 [==============================] - 825s 444ms/step - loss: 0.0012 - acc: 0.9996 - precision_m: 0.9488 - recall_m: 0.9385 - f1_m: 0.9397\n",
      "Score for fold 5: loss of 0.002637598430737853; acc of 0.9993019104003906; precision_m of 0.8417547345161438; recall_m of 0.8206593990325928; f1_m of 0.8203046917915344 %\n",
      "Training on fold 6/10..........\n",
      "6: started assigning sample weights\n",
      "6: finished assigning sample weights\n",
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_1 (Embedding)     (None, 49, 300)           10282800  \n",
      "                                                                 \n",
      " bidirectional_8 (Bidirectio  (None, 49, 64)           85248     \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " lstm_25 (LSTM)              (None, 49, 32)            12416     \n",
      "                                                                 \n",
      " lstm_26 (LSTM)              (None, 49, 32)            8320      \n",
      "                                                                 \n",
      " time_distributed_8 (TimeDis  (None, 49, 1)            33        \n",
      " tributed)                                                       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 10,388,817\n",
      "Trainable params: 10,388,817\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1858/1858 [==============================] - 747s 392ms/step - loss: 0.0114 - acc: 0.9977 - precision_m: 0.6805 - recall_m: 0.5613 - f1_m: 0.5890\n",
      "Epoch 2/20\n",
      "1858/1858 [==============================] - 742s 399ms/step - loss: 0.0034 - acc: 0.9990 - precision_m: 0.8573 - recall_m: 0.8531 - f1_m: 0.8441\n",
      "Epoch 3/20\n",
      "1858/1858 [==============================] - 745s 401ms/step - loss: 0.0025 - acc: 0.9992 - precision_m: 0.8958 - recall_m: 0.8897 - f1_m: 0.8851\n",
      "Epoch 4/20\n",
      "1858/1858 [==============================] - 748s 403ms/step - loss: 0.0021 - acc: 0.9994 - precision_m: 0.9090 - recall_m: 0.9000 - f1_m: 0.8980\n",
      "Epoch 5/20\n",
      "1858/1858 [==============================] - 739s 398ms/step - loss: 0.0018 - acc: 0.9994 - precision_m: 0.9182 - recall_m: 0.9087 - f1_m: 0.9073\n",
      "Epoch 6/20\n",
      "1858/1858 [==============================] - 740s 398ms/step - loss: 0.0017 - acc: 0.9995 - precision_m: 0.9281 - recall_m: 0.9167 - f1_m: 0.9169\n",
      "Epoch 7/20\n",
      "1858/1858 [==============================] - 738s 397ms/step - loss: 0.0016 - acc: 0.9995 - precision_m: 0.9230 - recall_m: 0.9186 - f1_m: 0.9151\n",
      "Epoch 8/20\n",
      "1858/1858 [==============================] - 739s 398ms/step - loss: 0.0015 - acc: 0.9995 - precision_m: 0.9307 - recall_m: 0.9216 - f1_m: 0.9209\n",
      "Epoch 9/20\n",
      "1858/1858 [==============================] - 740s 398ms/step - loss: 0.0014 - acc: 0.9995 - precision_m: 0.9340 - recall_m: 0.9230 - f1_m: 0.9236\n",
      "Epoch 10/20\n",
      "1858/1858 [==============================] - 743s 400ms/step - loss: 0.0014 - acc: 0.9995 - precision_m: 0.9368 - recall_m: 0.9316 - f1_m: 0.9294\n",
      "Epoch 11/20\n",
      "1858/1858 [==============================] - 744s 400ms/step - loss: 0.0013 - acc: 0.9996 - precision_m: 0.9437 - recall_m: 0.9311 - f1_m: 0.9329\n",
      "Epoch 12/20\n",
      "1858/1858 [==============================] - 744s 400ms/step - loss: 0.0013 - acc: 0.9996 - precision_m: 0.9417 - recall_m: 0.9306 - f1_m: 0.9317\n",
      "Epoch 13/20\n",
      "1858/1858 [==============================] - 744s 400ms/step - loss: 0.0013 - acc: 0.9996 - precision_m: 0.9386 - recall_m: 0.9309 - f1_m: 0.9300\n",
      "Epoch 14/20\n",
      "1858/1858 [==============================] - 743s 400ms/step - loss: 0.0012 - acc: 0.9996 - precision_m: 0.9422 - recall_m: 0.9325 - f1_m: 0.9331\n",
      "Epoch 15/20\n",
      "1858/1858 [==============================] - 743s 400ms/step - loss: 0.0012 - acc: 0.9996 - precision_m: 0.9436 - recall_m: 0.9308 - f1_m: 0.9331\n",
      "Epoch 16/20\n",
      "1858/1858 [==============================] - 744s 401ms/step - loss: 0.0012 - acc: 0.9996 - precision_m: 0.9477 - recall_m: 0.9354 - f1_m: 0.9371\n",
      "Epoch 17/20\n",
      "1858/1858 [==============================] - 746s 401ms/step - loss: 0.0012 - acc: 0.9996 - precision_m: 0.9425 - recall_m: 0.9337 - f1_m: 0.9338\n",
      "Epoch 18/20\n",
      "1858/1858 [==============================] - 746s 402ms/step - loss: 0.0011 - acc: 0.9996 - precision_m: 0.9479 - recall_m: 0.9397 - f1_m: 0.9400\n",
      "Epoch 19/20\n",
      "1858/1858 [==============================] - 850s 458ms/step - loss: 0.0011 - acc: 0.9996 - precision_m: 0.9459 - recall_m: 0.9374 - f1_m: 0.9379\n",
      "Epoch 20/20\n",
      "1858/1858 [==============================] - 962s 518ms/step - loss: 0.0011 - acc: 0.9996 - precision_m: 0.9453 - recall_m: 0.9409 - f1_m: 0.9390\n",
      "Score for fold 6: loss of 0.0025533344596624374; acc of 0.9993559718132019; precision_m of 0.8410406708717346; recall_m of 0.8165351748466492; f1_m of 0.8171131610870361 %\n",
      "Training on fold 7/10..........\n",
      "7: started assigning sample weights\n",
      "7: finished assigning sample weights\n",
      "Model: \"sequential_9\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_1 (Embedding)     (None, 49, 300)           10282800  \n",
      "                                                                 \n",
      " bidirectional_9 (Bidirectio  (None, 49, 64)           85248     \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " lstm_28 (LSTM)              (None, 49, 32)            12416     \n",
      "                                                                 \n",
      " lstm_29 (LSTM)              (None, 49, 32)            8320      \n",
      "                                                                 \n",
      " time_distributed_9 (TimeDis  (None, 49, 1)            33        \n",
      " tributed)                                                       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 10,388,817\n",
      "Trainable params: 10,388,817\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "1858/1858 [==============================] - 903s 471ms/step - loss: 0.0119 - acc: 0.9974 - precision_m: 0.6884 - recall_m: 0.5738 - f1_m: 0.5989\n",
      "Epoch 2/20\n",
      "1858/1858 [==============================] - 777s 418ms/step - loss: 0.0033 - acc: 0.9990 - precision_m: 0.8639 - recall_m: 0.8491 - f1_m: 0.8460\n",
      "Epoch 3/20\n",
      "1858/1858 [==============================] - 779s 419ms/step - loss: 0.0024 - acc: 0.9993 - precision_m: 0.9015 - recall_m: 0.8905 - f1_m: 0.8883\n",
      "Epoch 4/20\n",
      "1858/1858 [==============================] - 777s 418ms/step - loss: 0.0020 - acc: 0.9994 - precision_m: 0.9132 - recall_m: 0.9025 - f1_m: 0.9014\n",
      "Epoch 5/20\n",
      "1858/1858 [==============================] - 773s 416ms/step - loss: 0.0017 - acc: 0.9994 - precision_m: 0.9210 - recall_m: 0.9085 - f1_m: 0.9084\n",
      "Epoch 6/20\n",
      "1858/1858 [==============================] - 772s 416ms/step - loss: 0.0016 - acc: 0.9995 - precision_m: 0.9312 - recall_m: 0.9227 - f1_m: 0.9215\n",
      "Epoch 7/20\n",
      "1858/1858 [==============================] - 773s 416ms/step - loss: 0.0015 - acc: 0.9995 - precision_m: 0.9312 - recall_m: 0.9205 - f1_m: 0.9209\n",
      "Epoch 8/20\n",
      "1858/1858 [==============================] - 772s 415ms/step - loss: 0.0014 - acc: 0.9995 - precision_m: 0.9379 - recall_m: 0.9263 - f1_m: 0.9273\n",
      "Epoch 9/20\n",
      "1858/1858 [==============================] - 772s 415ms/step - loss: 0.0014 - acc: 0.9996 - precision_m: 0.9384 - recall_m: 0.9330 - f1_m: 0.9310\n",
      "Epoch 10/20\n",
      "1858/1858 [==============================] - 773s 416ms/step - loss: 0.0013 - acc: 0.9996 - precision_m: 0.9386 - recall_m: 0.9334 - f1_m: 0.9311\n",
      "Epoch 11/20\n",
      "1858/1858 [==============================] - 785s 422ms/step - loss: 0.0013 - acc: 0.9996 - precision_m: 0.9469 - recall_m: 0.9332 - f1_m: 0.9358\n",
      "Epoch 12/20\n",
      "1858/1858 [==============================] - 795s 428ms/step - loss: 0.0012 - acc: 0.9996 - precision_m: 0.9428 - recall_m: 0.9349 - f1_m: 0.9345\n",
      "Epoch 13/20\n",
      "1858/1858 [==============================] - 763s 411ms/step - loss: 0.0012 - acc: 0.9996 - precision_m: 0.9462 - recall_m: 0.9364 - f1_m: 0.9371\n",
      "Epoch 14/20\n",
      "1858/1858 [==============================] - 747s 402ms/step - loss: 0.0012 - acc: 0.9996 - precision_m: 0.9410 - recall_m: 0.9367 - f1_m: 0.9346\n",
      "Epoch 15/20\n",
      "1858/1858 [==============================] - 738s 397ms/step - loss: 0.0012 - acc: 0.9996 - precision_m: 0.9446 - recall_m: 0.9367 - f1_m: 0.9367\n",
      "Epoch 16/20\n",
      "1858/1858 [==============================] - 738s 397ms/step - loss: 0.0011 - acc: 0.9996 - precision_m: 0.9466 - recall_m: 0.9410 - f1_m: 0.9398\n",
      "Epoch 17/20\n",
      "1858/1858 [==============================] - 737s 397ms/step - loss: 0.0011 - acc: 0.9996 - precision_m: 0.9456 - recall_m: 0.9383 - f1_m: 0.9378\n",
      "Epoch 18/20\n",
      "1858/1858 [==============================] - 737s 397ms/step - loss: 0.0011 - acc: 0.9996 - precision_m: 0.9464 - recall_m: 0.9397 - f1_m: 0.9396\n",
      "Epoch 19/20\n",
      "1858/1858 [==============================] - 701s 377ms/step - loss: 0.0011 - acc: 0.9996 - precision_m: 0.9479 - recall_m: 0.9424 - f1_m: 0.9413\n",
      "Epoch 20/20\n",
      "1858/1858 [==============================] - 714s 384ms/step - loss: 0.0011 - acc: 0.9996 - precision_m: 0.9458 - recall_m: 0.9449 - f1_m: 0.9415\n",
      "Score for fold 7: loss of 0.0020163843873888254; acc of 0.999439537525177; precision_m of 0.8270572423934937; recall_m of 0.8159474730491638; f1_m of 0.8119654059410095 %\n",
      "Training on fold 8/10..........\n",
      "8: started assigning sample weights\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jonat\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:70: FutureWarning: Pass classes=[0 1], y=[0 1 0 ... 0 0 0] as keyword args. From version 1.0 (renaming of 0.25) passing these as positional arguments will result in an error\n",
      "  warnings.warn(f\"Pass {args_msg} as keyword args. From version \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8: finished assigning sample weights\n",
      "Model: \"sequential_10\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_1 (Embedding)     (None, 49, 300)           10282800  \n",
      "                                                                 \n",
      " bidirectional_10 (Bidirecti  (None, 49, 64)           85248     \n",
      " onal)                                                           \n",
      "                                                                 \n",
      " lstm_31 (LSTM)              (None, 49, 32)            12416     \n",
      "                                                                 \n",
      " lstm_32 (LSTM)              (None, 49, 32)            8320      \n",
      "                                                                 \n",
      " time_distributed_10 (TimeDi  (None, 49, 1)            33        \n",
      " stributed)                                                      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 10,388,817\n",
      "Trainable params: 10,388,817\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "1858/1858 [==============================] - 658s 348ms/step - loss: 0.0113 - acc: 0.9975 - precision_m: 0.7056 - recall_m: 0.5914 - f1_m: 0.6173\n",
      "Epoch 2/20\n",
      "1858/1858 [==============================] - 652s 351ms/step - loss: 0.0031 - acc: 0.9991 - precision_m: 0.8684 - recall_m: 0.8588 - f1_m: 0.8536\n",
      "Epoch 3/20\n",
      "1858/1858 [==============================] - 655s 352ms/step - loss: 0.0023 - acc: 0.9993 - precision_m: 0.9002 - recall_m: 0.8900 - f1_m: 0.8875\n",
      "Epoch 4/20\n",
      "1858/1858 [==============================] - 655s 352ms/step - loss: 0.0019 - acc: 0.9994 - precision_m: 0.9155 - recall_m: 0.9081 - f1_m: 0.9053\n",
      "Epoch 5/20\n",
      "1858/1858 [==============================] - 657s 353ms/step - loss: 0.0017 - acc: 0.9995 - precision_m: 0.9271 - recall_m: 0.9141 - f1_m: 0.9151\n",
      "Epoch 6/20\n",
      "1858/1858 [==============================] - 655s 352ms/step - loss: 0.0016 - acc: 0.9995 - precision_m: 0.9254 - recall_m: 0.9158 - f1_m: 0.9149\n",
      "Epoch 7/20\n",
      "1858/1858 [==============================] - 654s 352ms/step - loss: 0.0015 - acc: 0.9995 - precision_m: 0.9364 - recall_m: 0.9231 - f1_m: 0.9250\n",
      "Epoch 8/20\n",
      "1858/1858 [==============================] - 654s 352ms/step - loss: 0.0014 - acc: 0.9995 - precision_m: 0.9358 - recall_m: 0.9254 - f1_m: 0.9257\n",
      "Epoch 9/20\n",
      "1858/1858 [==============================] - 654s 352ms/step - loss: 0.0014 - acc: 0.9996 - precision_m: 0.9374 - recall_m: 0.9276 - f1_m: 0.9283\n",
      "Epoch 10/20\n",
      "1858/1858 [==============================] - 653s 352ms/step - loss: 0.0013 - acc: 0.9996 - precision_m: 0.9415 - recall_m: 0.9301 - f1_m: 0.9316\n",
      "Epoch 11/20\n",
      "1858/1858 [==============================] - 654s 352ms/step - loss: 0.0013 - acc: 0.9996 - precision_m: 0.9422 - recall_m: 0.9334 - f1_m: 0.9335\n",
      "Epoch 12/20\n",
      "1858/1858 [==============================] - 653s 352ms/step - loss: 0.0012 - acc: 0.9996 - precision_m: 0.9388 - recall_m: 0.9349 - f1_m: 0.9325\n",
      "Epoch 13/20\n",
      "1858/1858 [==============================] - 653s 352ms/step - loss: 0.0012 - acc: 0.9996 - precision_m: 0.9434 - recall_m: 0.9359 - f1_m: 0.9356\n",
      "Epoch 14/20\n",
      "1858/1858 [==============================] - 653s 352ms/step - loss: 0.0012 - acc: 0.9996 - precision_m: 0.9429 - recall_m: 0.9369 - f1_m: 0.9361\n",
      "Epoch 15/20\n",
      "1858/1858 [==============================] - 654s 352ms/step - loss: 0.0012 - acc: 0.9996 - precision_m: 0.9457 - recall_m: 0.9375 - f1_m: 0.9375\n",
      "Epoch 16/20\n",
      "1858/1858 [==============================] - 653s 352ms/step - loss: 0.0012 - acc: 0.9996 - precision_m: 0.9461 - recall_m: 0.9366 - f1_m: 0.9377\n",
      "Epoch 17/20\n",
      "1858/1858 [==============================] - 654s 352ms/step - loss: 0.0011 - acc: 0.9996 - precision_m: 0.9507 - recall_m: 0.9396 - f1_m: 0.9409\n",
      "Epoch 18/20\n",
      "1858/1858 [==============================] - 653s 352ms/step - loss: 0.0011 - acc: 0.9996 - precision_m: 0.9479 - recall_m: 0.9432 - f1_m: 0.9415\n",
      "Epoch 19/20\n",
      "1858/1858 [==============================] - 653s 352ms/step - loss: 0.0011 - acc: 0.9996 - precision_m: 0.9485 - recall_m: 0.9391 - f1_m: 0.9398\n",
      "Epoch 20/20\n",
      "1858/1858 [==============================] - 653s 352ms/step - loss: 0.0011 - acc: 0.9996 - precision_m: 0.9517 - recall_m: 0.9399 - f1_m: 0.9420\n",
      "Score for fold 8: loss of 0.001911207684315741; acc of 0.9994223117828369; precision_m of 0.8339192867279053; recall_m of 0.8510076999664307; f1_m of 0.8298423290252686 %\n",
      "Training on fold 9/10..........\n",
      "9: started assigning sample weights\n",
      "9: finished assigning sample weights\n",
      "Model: \"sequential_11\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_1 (Embedding)     (None, 49, 300)           10282800  \n",
      "                                                                 \n",
      " bidirectional_11 (Bidirecti  (None, 49, 64)           85248     \n",
      " onal)                                                           \n",
      "                                                                 \n",
      " lstm_34 (LSTM)              (None, 49, 32)            12416     \n",
      "                                                                 \n",
      " lstm_35 (LSTM)              (None, 49, 32)            8320      \n",
      "                                                                 \n",
      " time_distributed_11 (TimeDi  (None, 49, 1)            33        \n",
      " stributed)                                                      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 10,388,817\n",
      "Trainable params: 10,388,817\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "1858/1858 [==============================] - 747s 395ms/step - loss: 0.0120 - acc: 0.9973 - precision_m: 0.6841 - recall_m: 0.5449 - f1_m: 0.5803\n",
      "Epoch 2/20\n",
      "1858/1858 [==============================] - 722s 389ms/step - loss: 0.0034 - acc: 0.9990 - precision_m: 0.8532 - recall_m: 0.8443 - f1_m: 0.8377\n",
      "Epoch 3/20\n",
      "1858/1858 [==============================] - 729s 392ms/step - loss: 0.0024 - acc: 0.9993 - precision_m: 0.8942 - recall_m: 0.8868 - f1_m: 0.8828\n",
      "Epoch 4/20\n",
      "1858/1858 [==============================] - 734s 395ms/step - loss: 0.0019 - acc: 0.9994 - precision_m: 0.9093 - recall_m: 0.9048 - f1_m: 0.9006\n",
      "Epoch 5/20\n",
      "1858/1858 [==============================] - 734s 395ms/step - loss: 0.0017 - acc: 0.9995 - precision_m: 0.9240 - recall_m: 0.9155 - f1_m: 0.9140\n",
      "Epoch 6/20\n",
      "1858/1858 [==============================] - 732s 394ms/step - loss: 0.0015 - acc: 0.9995 - precision_m: 0.9298 - recall_m: 0.9204 - f1_m: 0.9201\n",
      "Epoch 7/20\n",
      "1858/1858 [==============================] - 733s 395ms/step - loss: 0.0014 - acc: 0.9995 - precision_m: 0.9350 - recall_m: 0.9248 - f1_m: 0.9248\n",
      "Epoch 8/20\n",
      "1858/1858 [==============================] - 733s 394ms/step - loss: 0.0014 - acc: 0.9996 - precision_m: 0.9330 - recall_m: 0.9263 - f1_m: 0.9251\n",
      "Epoch 9/20\n",
      "1858/1858 [==============================] - 733s 394ms/step - loss: 0.0013 - acc: 0.9996 - precision_m: 0.9394 - recall_m: 0.9348 - f1_m: 0.9328\n",
      "Epoch 10/20\n",
      "1858/1858 [==============================] - 732s 394ms/step - loss: 0.0013 - acc: 0.9996 - precision_m: 0.9421 - recall_m: 0.9352 - f1_m: 0.9344\n",
      "Epoch 11/20\n",
      "1858/1858 [==============================] - 732s 394ms/step - loss: 0.0012 - acc: 0.9996 - precision_m: 0.9434 - recall_m: 0.9379 - f1_m: 0.9369\n",
      "Epoch 12/20\n",
      "1858/1858 [==============================] - 732s 394ms/step - loss: 0.0012 - acc: 0.9996 - precision_m: 0.9454 - recall_m: 0.9369 - f1_m: 0.9371\n",
      "Epoch 13/20\n",
      "1858/1858 [==============================] - 734s 395ms/step - loss: 0.0012 - acc: 0.9996 - precision_m: 0.9421 - recall_m: 0.9333 - f1_m: 0.9331\n",
      "Epoch 14/20\n",
      "1858/1858 [==============================] - 734s 395ms/step - loss: 0.0012 - acc: 0.9996 - precision_m: 0.9468 - recall_m: 0.9413 - f1_m: 0.9405\n",
      "Epoch 15/20\n",
      "1858/1858 [==============================] - 732s 394ms/step - loss: 0.0011 - acc: 0.9996 - precision_m: 0.9438 - recall_m: 0.9408 - f1_m: 0.9384\n",
      "Epoch 16/20\n",
      "1858/1858 [==============================] - 733s 394ms/step - loss: 0.0011 - acc: 0.9996 - precision_m: 0.9474 - recall_m: 0.9449 - f1_m: 0.9428\n",
      "Epoch 17/20\n",
      "1858/1858 [==============================] - 753s 406ms/step - loss: 0.0011 - acc: 0.9996 - precision_m: 0.9500 - recall_m: 0.9445 - f1_m: 0.9436\n",
      "Epoch 18/20\n",
      "1858/1858 [==============================] - 787s 424ms/step - loss: 0.0011 - acc: 0.9996 - precision_m: 0.9504 - recall_m: 0.9448 - f1_m: 0.9439\n",
      "Epoch 19/20\n",
      "1858/1858 [==============================] - 788s 424ms/step - loss: 0.0011 - acc: 0.9996 - precision_m: 0.9478 - recall_m: 0.9413 - f1_m: 0.9411\n",
      "Epoch 20/20\n",
      "1858/1858 [==============================] - 788s 424ms/step - loss: 0.0011 - acc: 0.9996 - precision_m: 0.9489 - recall_m: 0.9449 - f1_m: 0.9434\n",
      "Score for fold 9: loss of 0.001563865109346807; acc of 0.9995338320732117; precision_m of 0.8733651041984558; recall_m of 0.8636382222175598; f1_m of 0.8616543412208557 %\n",
      "Training on fold 10/10..........\n",
      "10: started assigning sample weights\n",
      "10: finished assigning sample weights\n",
      "Model: \"sequential_12\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_1 (Embedding)     (None, 49, 300)           10282800  \n",
      "                                                                 \n",
      " bidirectional_12 (Bidirecti  (None, 49, 64)           85248     \n",
      " onal)                                                           \n",
      "                                                                 \n",
      " lstm_37 (LSTM)              (None, 49, 32)            12416     \n",
      "                                                                 \n",
      " lstm_38 (LSTM)              (None, 49, 32)            8320      \n",
      "                                                                 \n",
      " time_distributed_12 (TimeDi  (None, 49, 1)            33        \n",
      " stributed)                                                      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 10,388,817\n",
      "Trainable params: 10,388,817\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "1858/1858 [==============================] - 765s 402ms/step - loss: 0.0113 - acc: 0.9975 - precision_m: 0.6915 - recall_m: 0.5784 - f1_m: 0.6030\n",
      "Epoch 2/20\n",
      "1858/1858 [==============================] - 733s 395ms/step - loss: 0.0032 - acc: 0.9990 - precision_m: 0.8587 - recall_m: 0.8624 - f1_m: 0.8501\n",
      "Epoch 3/20\n",
      "1858/1858 [==============================] - 641s 345ms/step - loss: 0.0023 - acc: 0.9993 - precision_m: 0.8955 - recall_m: 0.8949 - f1_m: 0.8882\n",
      "Epoch 4/20\n",
      "1858/1858 [==============================] - 642s 345ms/step - loss: 0.0019 - acc: 0.9994 - precision_m: 0.9124 - recall_m: 0.9087 - f1_m: 0.9043\n",
      "Epoch 5/20\n",
      "1858/1858 [==============================] - 644s 347ms/step - loss: 0.0017 - acc: 0.9995 - precision_m: 0.9216 - recall_m: 0.9184 - f1_m: 0.9136\n",
      "Epoch 6/20\n",
      "1858/1858 [==============================] - 647s 348ms/step - loss: 0.0015 - acc: 0.9995 - precision_m: 0.9328 - recall_m: 0.9257 - f1_m: 0.9239\n",
      "Epoch 7/20\n",
      "1858/1858 [==============================] - 645s 347ms/step - loss: 0.0014 - acc: 0.9995 - precision_m: 0.9338 - recall_m: 0.9312 - f1_m: 0.9279\n",
      "Epoch 8/20\n",
      "1858/1858 [==============================] - 641s 345ms/step - loss: 0.0014 - acc: 0.9996 - precision_m: 0.9373 - recall_m: 0.9357 - f1_m: 0.9318\n",
      "Epoch 9/20\n",
      "1858/1858 [==============================] - 641s 345ms/step - loss: 0.0013 - acc: 0.9996 - precision_m: 0.9427 - recall_m: 0.9350 - f1_m: 0.9343\n",
      "Epoch 10/20\n",
      "1858/1858 [==============================] - 562s 303ms/step - loss: 0.0012 - acc: 0.9996 - precision_m: 0.9441 - recall_m: 0.9395 - f1_m: 0.9374\n",
      "Epoch 11/20\n",
      "1858/1858 [==============================] - 520s 280ms/step - loss: 0.0012 - acc: 0.9996 - precision_m: 0.9448 - recall_m: 0.9362 - f1_m: 0.9366\n",
      "Epoch 12/20\n",
      "1858/1858 [==============================] - 518s 279ms/step - loss: 0.0012 - acc: 0.9996 - precision_m: 0.9459 - recall_m: 0.9436 - f1_m: 0.9406\n",
      "Epoch 13/20\n",
      "1858/1858 [==============================] - 518s 279ms/step - loss: 0.0011 - acc: 0.9996 - precision_m: 0.9495 - recall_m: 0.9433 - f1_m: 0.9430\n",
      "Epoch 14/20\n",
      "1858/1858 [==============================] - 522s 281ms/step - loss: 0.0011 - acc: 0.9996 - precision_m: 0.9483 - recall_m: 0.9439 - f1_m: 0.9424\n",
      "Epoch 15/20\n",
      "1858/1858 [==============================] - 521s 280ms/step - loss: 0.0011 - acc: 0.9996 - precision_m: 0.9484 - recall_m: 0.9409 - f1_m: 0.9409\n",
      "Epoch 16/20\n",
      "1858/1858 [==============================] - 519s 279ms/step - loss: 0.0011 - acc: 0.9996 - precision_m: 0.9440 - recall_m: 0.9361 - f1_m: 0.9362\n",
      "Epoch 17/20\n",
      "1858/1858 [==============================] - 519s 279ms/step - loss: 0.0011 - acc: 0.9996 - precision_m: 0.9495 - recall_m: 0.9435 - f1_m: 0.9432\n",
      "Epoch 18/20\n",
      "1858/1858 [==============================] - 519s 279ms/step - loss: 0.0010 - acc: 0.9997 - precision_m: 0.9484 - recall_m: 0.9418 - f1_m: 0.9416\n",
      "Epoch 19/20\n",
      "1858/1858 [==============================] - 520s 280ms/step - loss: 0.0010 - acc: 0.9997 - precision_m: 0.9544 - recall_m: 0.9489 - f1_m: 0.9481\n",
      "Epoch 20/20\n",
      "1858/1858 [==============================] - 520s 280ms/step - loss: 0.0010 - acc: 0.9997 - precision_m: 0.9500 - recall_m: 0.9429 - f1_m: 0.9428\n",
      "Score for fold 10: loss of 0.0019598212093114853; acc of 0.9994767308235168; precision_m of 0.8616210222244263; recall_m of 0.8214491605758667; f1_m of 0.8328932523727417 %\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "skf = StratifiedKFold(n_splits = 10, shuffle = True, random_state = 999)\n",
    "\n",
    "fold_number = 1\n",
    "f1_per_fold = []\n",
    "recall_per_fold = []\n",
    "precision_per_fold = []\n",
    "acc_per_fold = []\n",
    "loss_per_fold = []\n",
    "\n",
    "for i, (train_index, val_index) in enumerate(skf.split(pad_tokens, np.sum(pad_tags, axis = 1))):\n",
    "    \n",
    "    print(\"Training on fold \" + str(i+1) + \"/10..........\")\n",
    "    \n",
    "    #Split training set and validation set\n",
    "    x_train, x_val = pad_tokens[train_index], pad_tokens[val_index]\n",
    "    y_train, y_val = pad_tags[train_index], pad_tags[val_index]\n",
    "    \n",
    "    #Assigning sample weights in training set\n",
    "    print(str(fold_number) + \": started assigning sample weights\")\n",
    "    weights = class_weight.compute_class_weight('balanced',\n",
    "                                                 np.unique(np.ravel(y_train,order='C')),\n",
    "                                                 np.ravel(y_train,order='C'))\n",
    "    \n",
    "    train_tags2 = np.copy(y_train)\n",
    "    train_tokens2 = np.copy(x_train)\n",
    "    train_tags2 = train_tags2.astype(float)\n",
    "    \n",
    "    indexTotal = 0\n",
    "    for tags in train_tags2:\n",
    "        indexTags = 0\n",
    "        for symptom in tags:\n",
    "            if symptom == 1:\n",
    "                train_tags2[indexTotal][indexTags] = float(weights[1]+5.00)\n",
    "            else:\n",
    "                train_tags2[indexTotal][indexTags] = float(weights[0])\n",
    "            indexTags = indexTags+1\n",
    "        indexTotal = indexTotal + 1\n",
    "   \n",
    "    weights = train_tags2.reshape((-1, 49, 1))\n",
    "    print(str(fold_number) + \": finished assigning sample weights\")\n",
    "    \n",
    "    #Getting Model Architecture\n",
    "    model = get_bilstm_lstm_model()\n",
    "    \n",
    "    #Running Model\n",
    "    history = model.fit(x_train, y_train, sample_weight = weights, batch_size=64, verbose=1, epochs=20)\n",
    "    \n",
    "    #Evaluate model\n",
    "    scores = model.evaluate(x_val, y_val, verbose = 0)\n",
    "    print(f'Score for fold {fold_number}: {model.metrics_names[0]} of {scores[0]}; {model.metrics_names[1]} of {scores[1]}; {model.metrics_names[2]} of {scores[2]}; {model.metrics_names[3]} of {scores[3]}; {model.metrics_names[4]} of {scores[4]} %')\n",
    "    f1_per_fold.append(scores[4])\n",
    "    recall_per_fold.append(scores[3])\n",
    "    precision_per_fold.append(scores[2])\n",
    "    acc_per_fold.append(scores[1])\n",
    "    loss_per_fold.append(scores[0])\n",
    "    \n",
    "    #Increase fold number\n",
    "    fold_number = fold_number + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score per fold\n",
      "-----------\n",
      "> Fold 1 - Loss: 0.008424668572843075 - Accuracy: 0.9981651306152344 - Precision: 0.7087938189506531 - Recall: 0.669576108455658 - F1: 0.6605508327484131%\n",
      "-----------\n",
      "> Fold 2 - Loss: 0.004767275415360928 - Accuracy: 0.9988278746604919 - Precision: 0.7777432799339294 - Recall: 0.7450389266014099 - F1: 0.744812548160553%\n",
      "-----------\n",
      "> Fold 3 - Loss: 0.0038301546592265368 - Accuracy: 0.9990360140800476 - Precision: 0.7775216102600098 - Recall: 0.7582077980041504 - F1: 0.7497233748435974%\n",
      "-----------\n",
      "> Fold 4 - Loss: 0.003117585787549615 - Accuracy: 0.9991922974586487 - Precision: 0.8177358508110046 - Recall: 0.791504442691803 - F1: 0.7899191379547119%\n",
      "-----------\n",
      "> Fold 5 - Loss: 0.002637598430737853 - Accuracy: 0.9993019104003906 - Precision: 0.8417547345161438 - Recall: 0.8206593990325928 - F1: 0.8203046917915344%\n",
      "-----------\n",
      "> Fold 6 - Loss: 0.0025533344596624374 - Accuracy: 0.9993559718132019 - Precision: 0.8410406708717346 - Recall: 0.8165351748466492 - F1: 0.8171131610870361%\n",
      "-----------\n",
      "> Fold 7 - Loss: 0.0020163843873888254 - Accuracy: 0.999439537525177 - Precision: 0.8270572423934937 - Recall: 0.8159474730491638 - F1: 0.8119654059410095%\n",
      "-----------\n",
      "> Fold 8 - Loss: 0.001911207684315741 - Accuracy: 0.9994223117828369 - Precision: 0.8339192867279053 - Recall: 0.8510076999664307 - F1: 0.8298423290252686%\n",
      "-----------\n",
      "> Fold 9 - Loss: 0.001563865109346807 - Accuracy: 0.9995338320732117 - Precision: 0.8733651041984558 - Recall: 0.8636382222175598 - F1: 0.8616543412208557%\n",
      "-----------\n",
      "> Fold 10 - Loss: 0.0019598212093114853 - Accuracy: 0.9994767308235168 - Precision: 0.8616210222244263 - Recall: 0.8214491605758667 - F1: 0.8328932523727417%\n",
      "------------\n",
      "Average scores for all folds:\n",
      "> Accuracy: 0.9991751611232758 (+- 0.00039493675667279693)\n",
      "> Precision: 0.8160552620887757 (+- 0.046417721662987035)\n",
      "> Recall: 0.7953564405441285 (+- 0.0544981350292552)\n",
      "> F1: 0.7918779075145721 (+- 0.055752582196816336)\n",
      "> Loss: 0.0032781895715743303\n",
      "------------\n"
     ]
    }
   ],
   "source": [
    "print('Score per fold')\n",
    "for i in range(0, len(acc_per_fold)):\n",
    "    print(\"-----------\")\n",
    "    print(f'> Fold {i+1} - Loss: {loss_per_fold[i]} - Accuracy: {acc_per_fold[i]} - Precision: {precision_per_fold[i]} - Recall: {recall_per_fold[i]} - F1: {f1_per_fold[i]}%')\n",
    "print('------------')\n",
    "print('Average scores for all folds:')\n",
    "print(f'> Accuracy: {np.mean(acc_per_fold)} (+- {np.std(acc_per_fold)})')\n",
    "print(f'> Precision: {np.mean(precision_per_fold)} (+- {np.std(precision_per_fold)})')\n",
    "print(f'> Recall: {np.mean(recall_per_fold)} (+- {np.std(recall_per_fold)})')\n",
    "print(f'> F1: {np.mean(f1_per_fold)} (+- {np.std(f1_per_fold)})')\n",
    "print(f'> Loss: {np.mean(loss_per_fold)}')\n",
    "print('------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Self Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_tags = model.predict(test_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "truePositive = 0 \n",
    "falsePositive = 0\n",
    "trueNegative = 0 \n",
    "falseNegative = 0\n",
    "index = 0\n",
    "for tag, predTag in zip(test_tags, predict_tags):\n",
    "    for symptomTag, symptomPred in zip (tag, predTag):\n",
    "        if symptomPred >= 0.50 and symptomTag == 1:\n",
    "            truePositive = truePositive + 1\n",
    "        elif symptomPred >= 0.50 and symptomTag == 0:\n",
    "            falsePositive = falsePositive + 1\n",
    "        elif symptomPred < 0.50 and symptomTag == 0:\n",
    "            trueNegative = trueNegative + 1\n",
    "        elif symptomPred < 0.50 and symptomTag == 1:\n",
    "            falseNegative = falseNegative + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True postitive: 6887\n",
      "False postitive: 359\n",
      "True negative: 1934322\n",
      "False negative: 253\n"
     ]
    }
   ],
   "source": [
    "print('True postitive: ' + str(truePositive))\n",
    "print('False postitive: ' + str(falsePositive))\n",
    "print('True negative: ' + str(trueNegative))\n",
    "print('False negative: ' + str(falseNegative))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision = (truePositive)/(truePositive+falsePositive)\n",
    "recall = (truePositive)/(truePositive+falseNegative)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.999684831918081\n",
      "Precision: 0.9504554236820315\n",
      "Recall: 0.9645658263305322\n",
      "F1: 0.9574586403447796\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy: ' + str((truePositive+trueNegative)/(truePositive+trueNegative+falsePositive+falseNegative)))\n",
    "print('Precision: ' + str((truePositive)/(truePositive+falsePositive)))\n",
    "print('Recall: ' + str((truePositive)/(truePositive+falseNegative)))\n",
    "print('F1: ' + str((2*precision*recall)/(precision+recall)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4128/4128 [==============================] - 215s 52ms/step - loss: 0.0010 - acc: 0.9997 - precision_m: 0.6882 - recall_m: 0.6997 - f1_m: 0.6890\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.0010336712002754211,\n",
       " 0.9996744990348816,\n",
       " 0.6881966590881348,\n",
       " 0.6996971368789673,\n",
       " 0.6890236735343933]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(pad_tokens, pad_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
