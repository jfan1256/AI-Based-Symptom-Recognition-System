{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import imblearn\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence</th>\n",
       "      <th>Word</th>\n",
       "      <th>Tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sentence: 1</td>\n",
       "      <td>RECORD</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sentence: 2</td>\n",
       "      <td>OC</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>AM</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>gallstone</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>pancreatitis</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>949802</th>\n",
       "      <td>NaN</td>\n",
       "      <td>M.D.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>949803</th>\n",
       "      <td>Sentence: 132094</td>\n",
       "      <td>END</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>949804</th>\n",
       "      <td>NaN</td>\n",
       "      <td>OF</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>949805</th>\n",
       "      <td>NaN</td>\n",
       "      <td>DISCHARGE</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>949806</th>\n",
       "      <td>NaN</td>\n",
       "      <td>ORDERS</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>949807 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                Sentence          Word  Tag\n",
       "0            Sentence: 1        RECORD    0\n",
       "1            Sentence: 2            OC    0\n",
       "2                    NaN            AM    0\n",
       "3                    NaN     gallstone    0\n",
       "4                    NaN  pancreatitis    0\n",
       "...                  ...           ...  ...\n",
       "949802               NaN          M.D.    0\n",
       "949803  Sentence: 132094           END    0\n",
       "949804               NaN            OF    0\n",
       "949805               NaN     DISCHARGE    0\n",
       "949806               NaN        ORDERS    0\n",
       "\n",
       "[949807 rows x 3 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('./OUTPUT/dataset.csv', encoding= 'unicode_escape')\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Extract mappings required for the neural network\n",
    "To train a neural network, we will use two mappings as given below. The neural network will only take integers as input. So lets convert all the unique tokens in the corpus to its respective index.\n",
    "- {token} to {token id}: address the row in embeddings matrix for the current token.\n",
    "- {tag} to {tag id}: one-hot ground truth probability distribution vectors for computing the loss at the output of the network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import chain\n",
    "def get_dict_map(data, token_or_tag):\n",
    "    tok2idx = {}\n",
    "    idx2tok = {}\n",
    "    \n",
    "    if token_or_tag == 'token':\n",
    "        vocab = list(set(data['Word'].to_list()))\n",
    "    else:\n",
    "        vocab = list(set(data['Tag'].to_list()))\n",
    "    \n",
    "    idx2tok = {idx:tok for  idx, tok in enumerate(vocab)}\n",
    "    tok2idx = {tok:idx for  idx, tok in enumerate(vocab)}\n",
    "    return tok2idx, idx2tok\n",
    "\n",
    "\n",
    "token2idx, idx2token = get_dict_map(data, 'token')\n",
    "tag2idx, idx2tag = get_dict_map(data, 'tag')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Word_idx'] = data['Word'].map(token2idx)\n",
    "data['Tag_idx'] = data['Tag'].map(tag2idx) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence</th>\n",
       "      <th>Word</th>\n",
       "      <th>Tag</th>\n",
       "      <th>Word_idx</th>\n",
       "      <th>Tag_idx</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sentence: 1</td>\n",
       "      <td>RECORD</td>\n",
       "      <td>0</td>\n",
       "      <td>16071</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sentence: 2</td>\n",
       "      <td>OC</td>\n",
       "      <td>0</td>\n",
       "      <td>30408</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>AM</td>\n",
       "      <td>0</td>\n",
       "      <td>31374</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>gallstone</td>\n",
       "      <td>0</td>\n",
       "      <td>31312</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>pancreatitis</td>\n",
       "      <td>0</td>\n",
       "      <td>22405</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>949802</th>\n",
       "      <td>NaN</td>\n",
       "      <td>M.D.</td>\n",
       "      <td>0</td>\n",
       "      <td>13767</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>949803</th>\n",
       "      <td>Sentence: 132094</td>\n",
       "      <td>END</td>\n",
       "      <td>0</td>\n",
       "      <td>10433</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>949804</th>\n",
       "      <td>NaN</td>\n",
       "      <td>OF</td>\n",
       "      <td>0</td>\n",
       "      <td>28067</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>949805</th>\n",
       "      <td>NaN</td>\n",
       "      <td>DISCHARGE</td>\n",
       "      <td>0</td>\n",
       "      <td>38362</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>949806</th>\n",
       "      <td>NaN</td>\n",
       "      <td>ORDERS</td>\n",
       "      <td>0</td>\n",
       "      <td>41627</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>949807 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                Sentence          Word  Tag  Word_idx  Tag_idx\n",
       "0            Sentence: 1        RECORD    0     16071        0\n",
       "1            Sentence: 2            OC    0     30408        0\n",
       "2                    NaN            AM    0     31374        0\n",
       "3                    NaN     gallstone    0     31312        0\n",
       "4                    NaN  pancreatitis    0     22405        0\n",
       "...                  ...           ...  ...       ...      ...\n",
       "949802               NaN          M.D.    0     13767        0\n",
       "949803  Sentence: 132094           END    0     10433        0\n",
       "949804               NaN            OF    0     28067        0\n",
       "949805               NaN     DISCHARGE    0     38362        0\n",
       "949806               NaN        ORDERS    0     41627        0\n",
       "\n",
       "[949807 rows x 5 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv('./OUTPUT/view.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Transform columns to extract sequential data\n",
    "Next, lets fill NaN in 'sentence #' column using method ffill in fillna. Thereafter groupby on the sentence column to get a list of tokens and tags for each sentence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-6-2d54414e46a7>:2: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
      "  data_group = data_fillna.groupby(['Sentence'],as_index=False\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence</th>\n",
       "      <th>Word</th>\n",
       "      <th>Tag</th>\n",
       "      <th>Word_idx</th>\n",
       "      <th>Tag_idx</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sentence: 1</td>\n",
       "      <td>[RECORD]</td>\n",
       "      <td>[0]</td>\n",
       "      <td>[16071]</td>\n",
       "      <td>[0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sentence: 10</td>\n",
       "      <td>[WILL, D/C, ORDER, BE, USED, AS, THE, D/C, SUM...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>[27498, 18986, 25777, 8130, 13255, 32306, 1555...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Sentence: 100</td>\n",
       "      <td>[prandial, N/V/severe, upper, abdominal, pain....</td>\n",
       "      <td>[0, 1, 0, 1, 1, 0, 0, 0, 0]</td>\n",
       "      <td>[6133, 33586, 16313, 7084, 23815, 39962, 18546...</td>\n",
       "      <td>[0, 1, 0, 1, 1, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Sentence: 1000</td>\n",
       "      <td>[normal, limits., Cardiac, catheterization, da...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>[18338, 30998, 24500, 701, 23250, 17456, 16231...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sentence: 10000</td>\n",
       "      <td>[year, old, Black, female, with, significant, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>[23644, 30760, 37744, 18947, 38424, 5121, 2330...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132089</th>\n",
       "      <td>Sentence: 99995</td>\n",
       "      <td>[Height, foot, inch, and, weight, kg., Tempera...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>[17049, 31137, 40718, 13764, 15185, 31331, 3378]</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132090</th>\n",
       "      <td>Sentence: 99996</td>\n",
       "      <td>[degrees, heart, rate, and, sinus, blood, pres...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>[28073, 37775, 9250, 13764, 13120, 11272, 1704...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132091</th>\n",
       "      <td>Sentence: 99997</td>\n",
       "      <td>[blood, pressure, left, arm, and, oxygen, satu...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>[11272, 1704, 39996, 35976, 13764, 40190, 14052]</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132092</th>\n",
       "      <td>Sentence: 99998</td>\n",
       "      <td>[No, carotid, bruits, regular, rate, and, rhyt...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>[21884, 23965, 19754, 34309, 9250, 13764, 1516...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132093</th>\n",
       "      <td>Sentence: 99999</td>\n",
       "      <td>[systolic, murmur, along, the, right, upper, s...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>[3125, 14295, 11806, 23638, 15878, 16313, 1355...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>132094 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               Sentence                                               Word  \\\n",
       "0           Sentence: 1                                           [RECORD]   \n",
       "1          Sentence: 10  [WILL, D/C, ORDER, BE, USED, AS, THE, D/C, SUM...   \n",
       "2         Sentence: 100  [prandial, N/V/severe, upper, abdominal, pain....   \n",
       "3        Sentence: 1000  [normal, limits., Cardiac, catheterization, da...   \n",
       "4       Sentence: 10000  [year, old, Black, female, with, significant, ...   \n",
       "...                 ...                                                ...   \n",
       "132089  Sentence: 99995  [Height, foot, inch, and, weight, kg., Tempera...   \n",
       "132090  Sentence: 99996  [degrees, heart, rate, and, sinus, blood, pres...   \n",
       "132091  Sentence: 99997  [blood, pressure, left, arm, and, oxygen, satu...   \n",
       "132092  Sentence: 99998  [No, carotid, bruits, regular, rate, and, rhyt...   \n",
       "132093  Sentence: 99999  [systolic, murmur, along, the, right, upper, s...   \n",
       "\n",
       "                                   Tag  \\\n",
       "0                                  [0]   \n",
       "1       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]   \n",
       "2          [0, 1, 0, 1, 1, 0, 0, 0, 0]   \n",
       "3             [0, 0, 0, 0, 0, 0, 0, 0]   \n",
       "4       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]   \n",
       "...                                ...   \n",
       "132089           [0, 0, 0, 0, 0, 0, 0]   \n",
       "132090     [0, 0, 0, 0, 0, 0, 0, 0, 0]   \n",
       "132091           [0, 0, 0, 0, 0, 0, 0]   \n",
       "132092     [0, 0, 0, 0, 0, 0, 0, 0, 0]   \n",
       "132093     [0, 0, 0, 0, 0, 0, 0, 0, 0]   \n",
       "\n",
       "                                                 Word_idx  \\\n",
       "0                                                 [16071]   \n",
       "1       [27498, 18986, 25777, 8130, 13255, 32306, 1555...   \n",
       "2       [6133, 33586, 16313, 7084, 23815, 39962, 18546...   \n",
       "3       [18338, 30998, 24500, 701, 23250, 17456, 16231...   \n",
       "4       [23644, 30760, 37744, 18947, 38424, 5121, 2330...   \n",
       "...                                                   ...   \n",
       "132089   [17049, 31137, 40718, 13764, 15185, 31331, 3378]   \n",
       "132090  [28073, 37775, 9250, 13764, 13120, 11272, 1704...   \n",
       "132091   [11272, 1704, 39996, 35976, 13764, 40190, 14052]   \n",
       "132092  [21884, 23965, 19754, 34309, 9250, 13764, 1516...   \n",
       "132093  [3125, 14295, 11806, 23638, 15878, 16313, 1355...   \n",
       "\n",
       "                               Tag_idx  \n",
       "0                                  [0]  \n",
       "1       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]  \n",
       "2          [0, 1, 0, 1, 1, 0, 0, 0, 0]  \n",
       "3             [0, 0, 0, 0, 0, 0, 0, 0]  \n",
       "4       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]  \n",
       "...                                ...  \n",
       "132089           [0, 0, 0, 0, 0, 0, 0]  \n",
       "132090     [0, 0, 0, 0, 0, 0, 0, 0, 0]  \n",
       "132091           [0, 0, 0, 0, 0, 0, 0]  \n",
       "132092     [0, 0, 0, 0, 0, 0, 0, 0, 0]  \n",
       "132093     [0, 0, 0, 0, 0, 0, 0, 0, 0]  \n",
       "\n",
       "[132094 rows x 5 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_fillna = data.fillna(method='ffill', axis=0)\n",
    "data_group = data_fillna.groupby(['Sentence'],as_index=False\n",
    "                                )['Word', 'Tag', 'Word_idx', 'Tag_idx'].agg(lambda x: list(x))\n",
    "\n",
    "#data_fillna\n",
    "data_group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_group.to_csv('./OUTPUT/datagroup.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Pad sequences and split the dataset into train, test\n",
    "Padding: The LSTM layers accept sequences of same length only. Therefore we will want to transform our list of token_sequences ('Word_idx') which is lists of integers into a matrix of shape (token_sequences, max_len). We can use any length as max_len. In this project we will be using length of the longest sequence as max_len. The sequences that are shorter than max_len are padded with a specified value at the end.\n",
    "Import required packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_padTokens_padTags(data_group, data):\n",
    "    n_token = len(list(set(data['Word'].to_list())))\n",
    "    n_tag = len(list(set(data['Tag'].to_list())))\n",
    "    tokens = data_group['Word_idx'].tolist()\n",
    "    maxlen = max([len(s) for s in tokens])\n",
    "    pad_tokens = pad_sequences(tokens, maxlen=maxlen, dtype='int32', padding='post', value= 0)\n",
    "    tags = data_group['Tag_idx'].tolist()\n",
    "    pad_tags = pad_sequences(tags, maxlen=maxlen, dtype='int32', padding='post', value= 0)\n",
    "\n",
    "    return pad_tokens, pad_tags\n",
    "\n",
    "pad_tokens, pad_tags = get_padTokens_padTags(data_group, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of tokens 132094\n",
      "length of tags 132094\n"
     ]
    }
   ],
   "source": [
    "print('length of tokens ' + str(len(pad_tokens)))\n",
    "print('length of tags ' + str(len(pad_tags)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## StratifiedKFold Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import Sequential, Model, Input\n",
    "from tensorflow.keras.layers import LSTM, Embedding, Dense, TimeDistributed, Dropout, Bidirectional\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from keras import backend as K\n",
    "import keras as keras\n",
    "from keras.datasets import mnist\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from keras import metrics\n",
    "from sklearn.utils import class_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy.random import seed\n",
    "seed(1)\n",
    "tf.random.set_seed(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_dim:  42057 \n",
      "output_dim:  32 \n",
      "input_length:  49 \n",
      "n_tags:  2\n"
     ]
    }
   ],
   "source": [
    "input_dim = len(list(set(data['Word'].to_list())))+1\n",
    "output_dim = 32\n",
    "input_length = max([len(s) for s in data_group['Word_idx'].tolist()])\n",
    "n_tags = len(tag2idx)\n",
    "print('input_dim: ', input_dim, '\\noutput_dim: ', output_dim, '\\ninput_length: ', input_length, '\\nn_tags: ', n_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recall_m(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    recall = true_positives / (possible_positives + K.epsilon())\n",
    "    return recall\n",
    "\n",
    "def precision_m(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\n",
    "    return precision\n",
    "\n",
    "def f1_m(y_true, y_pred):\n",
    "    precision = precision_m(y_true, y_pred)\n",
    "    recall = recall_m(y_true, y_pred)\n",
    "    return 2*((precision*recall)/(precision+recall+K.epsilon()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bilstm_lstm_model():\n",
    "    model = Sequential()\n",
    "\n",
    "    # Add Embedding layer\n",
    "    model.add(Embedding(input_dim=input_dim, output_dim=output_dim, input_length=input_length))\n",
    "\n",
    "    # Add bidirectional LSTM\n",
    "    model.add(Bidirectional(LSTM(units=output_dim, return_sequences=True, dropout=0.2, recurrent_dropout=0.2), merge_mode = 'concat'))\n",
    "\n",
    "    \n",
    "    # Add LSTM\n",
    "    model.add(LSTM(units=output_dim, return_sequences=True, dropout=0.5, recurrent_dropout=0.5))\n",
    "\n",
    "    # Add timeDistributed Layer\n",
    "    model.add(TimeDistributed(Dense(1, activation=\"sigmoid\")))\n",
    "    \n",
    "    #Optimiser \n",
    "    adam = tf.keras.optimizers.Adam(learning_rate=0.0005, beta_1=0.9, beta_2=0.999)\n",
    "    \n",
    "    # Compile model\n",
    "    model.compile(loss='binary_crossentropy', sample_weight_mode=\"temporal\", optimizer='adam', metrics=['acc', precision_m, recall_m, f1_m])\n",
    "    model.summary()\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jonat\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:666: UserWarning: The least populated class in y has only 3 members, which is less than n_splits=10.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on fold 1/10..........\n",
      "1: started oversampling\n",
      "1: finished assigning sample weights\n",
      "1: started oversampling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jonat\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:70: FutureWarning: Pass classes=[0 1], y=[0 1 1 ... 0 0 0] as keyword args. From version 1.0 (renaming of 0.25) passing these as positional arguments will result in an error\n",
      "  warnings.warn(f\"Pass {args_msg} as keyword args. From version \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1: finished assigning sample weights\n",
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_3 (Embedding)     (None, 49, 32)            1345824   \n",
      "                                                                 \n",
      " bidirectional_3 (Bidirectio  (None, 49, 64)           16640     \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " lstm_7 (LSTM)               (None, 49, 32)            12416     \n",
      "                                                                 \n",
      " time_distributed_3 (TimeDis  (None, 49, 1)            33        \n",
      " tributed)                                                       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,374,913\n",
      "Trainable params: 1,374,913\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "2526/2526 [==============================] - 230s 89ms/step - loss: 0.0273 - acc: 0.9912 - precision_m: 0.8341 - recall_m: 0.7924 - f1_m: 0.8022\n",
      "Epoch 2/20\n",
      "2526/2526 [==============================] - 224s 89ms/step - loss: 0.0090 - acc: 0.9970 - precision_m: 0.9390 - recall_m: 0.9554 - f1_m: 0.9469\n",
      "Epoch 3/20\n",
      "2526/2526 [==============================] - 222s 88ms/step - loss: 0.0062 - acc: 0.9979 - precision_m: 0.9559 - recall_m: 0.9716 - f1_m: 0.9635\n",
      "Epoch 4/20\n",
      "2526/2526 [==============================] - 220s 87ms/step - loss: 0.0047 - acc: 0.9984 - precision_m: 0.9654 - recall_m: 0.9781 - f1_m: 0.9716\n",
      "Epoch 5/20\n",
      "2526/2526 [==============================] - 219s 87ms/step - loss: 0.0037 - acc: 0.9987 - precision_m: 0.9724 - recall_m: 0.9824 - f1_m: 0.9773\n",
      "Epoch 6/20\n",
      "2526/2526 [==============================] - 220s 87ms/step - loss: 0.0031 - acc: 0.9989 - precision_m: 0.9769 - recall_m: 0.9850 - f1_m: 0.9808\n",
      "Epoch 7/20\n",
      "2526/2526 [==============================] - 220s 87ms/step - loss: 0.0027 - acc: 0.9991 - precision_m: 0.9803 - recall_m: 0.9873 - f1_m: 0.9837\n",
      "Epoch 8/20\n",
      "2526/2526 [==============================] - 219s 87ms/step - loss: 0.0024 - acc: 0.9992 - precision_m: 0.9827 - recall_m: 0.9885 - f1_m: 0.9855\n",
      "Epoch 9/20\n",
      "2526/2526 [==============================] - 219s 87ms/step - loss: 0.0021 - acc: 0.9993 - precision_m: 0.9847 - recall_m: 0.9900 - f1_m: 0.9873\n",
      "Epoch 10/20\n",
      "2526/2526 [==============================] - 219s 87ms/step - loss: 0.0019 - acc: 0.9993 - precision_m: 0.9862 - recall_m: 0.9909 - f1_m: 0.9885\n",
      "Epoch 11/20\n",
      "2526/2526 [==============================] - 218s 86ms/step - loss: 0.0018 - acc: 0.9994 - precision_m: 0.9869 - recall_m: 0.9913 - f1_m: 0.9891\n",
      "Epoch 12/20\n",
      "2526/2526 [==============================] - 219s 87ms/step - loss: 0.0017 - acc: 0.9994 - precision_m: 0.9881 - recall_m: 0.9921 - f1_m: 0.9900\n",
      "Epoch 13/20\n",
      "2526/2526 [==============================] - 218s 86ms/step - loss: 0.0016 - acc: 0.9995 - precision_m: 0.9888 - recall_m: 0.9926 - f1_m: 0.9907\n",
      "Epoch 14/20\n",
      "2526/2526 [==============================] - 218s 86ms/step - loss: 0.0015 - acc: 0.9995 - precision_m: 0.9896 - recall_m: 0.9929 - f1_m: 0.9912\n",
      "Epoch 15/20\n",
      "2526/2526 [==============================] - 219s 87ms/step - loss: 0.0014 - acc: 0.9995 - precision_m: 0.9902 - recall_m: 0.9935 - f1_m: 0.9918\n",
      "Epoch 16/20\n",
      "2526/2526 [==============================] - 218s 86ms/step - loss: 0.0013 - acc: 0.9996 - precision_m: 0.9907 - recall_m: 0.9938 - f1_m: 0.9922\n",
      "Epoch 17/20\n",
      "2526/2526 [==============================] - 218s 86ms/step - loss: 0.0013 - acc: 0.9996 - precision_m: 0.9911 - recall_m: 0.9942 - f1_m: 0.9926\n",
      "Epoch 18/20\n",
      "2526/2526 [==============================] - 220s 87ms/step - loss: 0.0012 - acc: 0.9996 - precision_m: 0.9913 - recall_m: 0.9942 - f1_m: 0.9927\n",
      "Epoch 19/20\n",
      "2526/2526 [==============================] - 218s 86ms/step - loss: 0.0012 - acc: 0.9996 - precision_m: 0.9920 - recall_m: 0.9947 - f1_m: 0.9933\n",
      "Epoch 20/20\n",
      "2526/2526 [==============================] - 218s 86ms/step - loss: 0.0011 - acc: 0.9996 - precision_m: 0.9920 - recall_m: 0.9947 - f1_m: 0.9933\n",
      "Score for fold 1: loss of 0.017939984798431396; acc of 0.9976244568824768; precision_m of 0.5960526466369629; recall_m of 0.6512682437896729; f1_m of 0.5915733575820923 %\n",
      "Training on fold 2/10..........\n",
      "2: started oversampling\n",
      "2: finished assigning sample weights\n",
      "2: started oversampling\n",
      "2: finished assigning sample weights\n",
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_4 (Embedding)     (None, 49, 32)            1345824   \n",
      "                                                                 \n",
      " bidirectional_4 (Bidirectio  (None, 49, 64)           16640     \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " lstm_9 (LSTM)               (None, 49, 32)            12416     \n",
      "                                                                 \n",
      " time_distributed_4 (TimeDis  (None, 49, 1)            33        \n",
      " tributed)                                                       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,374,913\n",
      "Trainable params: 1,374,913\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "2526/2526 [==============================] - 214s 83ms/step - loss: 0.0277 - acc: 0.9913 - precision_m: 0.8268 - recall_m: 0.7877 - f1_m: 0.7976\n",
      "Epoch 2/20\n",
      "2526/2526 [==============================] - 217s 86ms/step - loss: 0.0093 - acc: 0.9968 - precision_m: 0.9360 - recall_m: 0.9538 - f1_m: 0.9446\n",
      "Epoch 3/20\n",
      "2526/2526 [==============================] - 221s 87ms/step - loss: 0.0065 - acc: 0.9979 - precision_m: 0.9548 - recall_m: 0.9704 - f1_m: 0.9624\n",
      "Epoch 4/20\n",
      "2526/2526 [==============================] - 220s 87ms/step - loss: 0.0050 - acc: 0.9983 - precision_m: 0.9644 - recall_m: 0.9774 - f1_m: 0.9707\n",
      "Epoch 5/20\n",
      "2526/2526 [==============================] - 220s 87ms/step - loss: 0.0041 - acc: 0.9986 - precision_m: 0.9702 - recall_m: 0.9815 - f1_m: 0.9757\n",
      "Epoch 6/20\n",
      "2526/2526 [==============================] - 221s 87ms/step - loss: 0.0035 - acc: 0.9988 - precision_m: 0.9746 - recall_m: 0.9843 - f1_m: 0.9794\n",
      "Epoch 7/20\n",
      "2526/2526 [==============================] - 221s 87ms/step - loss: 0.0030 - acc: 0.9990 - precision_m: 0.9777 - recall_m: 0.9863 - f1_m: 0.9819\n",
      "Epoch 8/20\n",
      "2526/2526 [==============================] - 221s 88ms/step - loss: 0.0026 - acc: 0.9991 - precision_m: 0.9806 - recall_m: 0.9878 - f1_m: 0.9841\n",
      "Epoch 9/20\n",
      "2526/2526 [==============================] - 222s 88ms/step - loss: 0.0024 - acc: 0.9992 - precision_m: 0.9826 - recall_m: 0.9891 - f1_m: 0.9858\n",
      "Epoch 10/20\n",
      "2526/2526 [==============================] - 221s 87ms/step - loss: 0.0021 - acc: 0.9993 - precision_m: 0.9844 - recall_m: 0.9904 - f1_m: 0.9873\n",
      "Epoch 11/20\n",
      "2526/2526 [==============================] - 221s 88ms/step - loss: 0.0020 - acc: 0.9993 - precision_m: 0.9854 - recall_m: 0.9908 - f1_m: 0.9881\n",
      "Epoch 12/20\n",
      "2526/2526 [==============================] - 221s 88ms/step - loss: 0.0018 - acc: 0.9994 - precision_m: 0.9870 - recall_m: 0.9917 - f1_m: 0.9893\n",
      "Epoch 13/20\n",
      "2526/2526 [==============================] - 222s 88ms/step - loss: 0.0017 - acc: 0.9994 - precision_m: 0.9876 - recall_m: 0.9921 - f1_m: 0.9898\n",
      "Epoch 14/20\n",
      "2526/2526 [==============================] - 223s 88ms/step - loss: 0.0016 - acc: 0.9995 - precision_m: 0.9884 - recall_m: 0.9925 - f1_m: 0.9904\n",
      "Epoch 15/20\n",
      "2526/2526 [==============================] - 223s 88ms/step - loss: 0.0015 - acc: 0.9995 - precision_m: 0.9890 - recall_m: 0.9930 - f1_m: 0.9910\n",
      "Epoch 16/20\n",
      "2526/2526 [==============================] - 225s 89ms/step - loss: 0.0014 - acc: 0.9995 - precision_m: 0.9897 - recall_m: 0.9935 - f1_m: 0.9915\n",
      "Epoch 17/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2526/2526 [==============================] - 222s 88ms/step - loss: 0.0014 - acc: 0.9995 - precision_m: 0.9904 - recall_m: 0.9937 - f1_m: 0.9920\n",
      "Epoch 18/20\n",
      "2526/2526 [==============================] - 228s 90ms/step - loss: 0.0013 - acc: 0.9996 - precision_m: 0.9908 - recall_m: 0.9940 - f1_m: 0.9924\n",
      "Epoch 19/20\n",
      "2526/2526 [==============================] - 227s 90ms/step - loss: 0.0013 - acc: 0.9996 - precision_m: 0.9911 - recall_m: 0.9941 - f1_m: 0.9926\n",
      "Epoch 20/20\n",
      "2526/2526 [==============================] - 222s 88ms/step - loss: 0.0012 - acc: 0.9996 - precision_m: 0.9915 - recall_m: 0.9945 - f1_m: 0.9930\n",
      "Score for fold 2: loss of 0.016830148175358772; acc of 0.9977466464042664; precision_m of 0.6145405769348145; recall_m of 0.6440485119819641; f1_m of 0.5997841358184814 %\n",
      "Training on fold 3/10..........\n",
      "3: started oversampling\n",
      "3: finished assigning sample weights\n",
      "3: started oversampling\n",
      "3: finished assigning sample weights\n",
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_5 (Embedding)     (None, 49, 32)            1345824   \n",
      "                                                                 \n",
      " bidirectional_5 (Bidirectio  (None, 49, 64)           16640     \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " lstm_11 (LSTM)              (None, 49, 32)            12416     \n",
      "                                                                 \n",
      " time_distributed_5 (TimeDis  (None, 49, 1)            33        \n",
      " tributed)                                                       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,374,913\n",
      "Trainable params: 1,374,913\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "2526/2526 [==============================] - 215s 83ms/step - loss: 0.0301 - acc: 0.9903 - precision_m: 0.8014 - recall_m: 0.7666 - f1_m: 0.7758\n",
      "Epoch 2/20\n",
      "2526/2526 [==============================] - 215s 85ms/step - loss: 0.0100 - acc: 0.9966 - precision_m: 0.9329 - recall_m: 0.9484 - f1_m: 0.9404\n",
      "Epoch 3/20\n",
      "2526/2526 [==============================] - 216s 86ms/step - loss: 0.0065 - acc: 0.9978 - precision_m: 0.9554 - recall_m: 0.9689 - f1_m: 0.9619\n",
      "Epoch 4/20\n",
      "2526/2526 [==============================] - 219s 87ms/step - loss: 0.0048 - acc: 0.9984 - precision_m: 0.9660 - recall_m: 0.9775 - f1_m: 0.9716\n",
      "Epoch 5/20\n",
      "2526/2526 [==============================] - 221s 87ms/step - loss: 0.0039 - acc: 0.9987 - precision_m: 0.9723 - recall_m: 0.9813 - f1_m: 0.9767\n",
      "Epoch 6/20\n",
      "2526/2526 [==============================] - 222s 88ms/step - loss: 0.0032 - acc: 0.9989 - precision_m: 0.9768 - recall_m: 0.9849 - f1_m: 0.9808\n",
      "Epoch 7/20\n",
      "2526/2526 [==============================] - 222s 88ms/step - loss: 0.0028 - acc: 0.9990 - precision_m: 0.9800 - recall_m: 0.9866 - f1_m: 0.9832\n",
      "Epoch 8/20\n",
      "2526/2526 [==============================] - 222s 88ms/step - loss: 0.0025 - acc: 0.9991 - precision_m: 0.9822 - recall_m: 0.9881 - f1_m: 0.9851\n",
      "Epoch 9/20\n",
      "2526/2526 [==============================] - 221s 88ms/step - loss: 0.0022 - acc: 0.9992 - precision_m: 0.9840 - recall_m: 0.9893 - f1_m: 0.9866\n",
      "Epoch 10/20\n",
      "2526/2526 [==============================] - 222s 88ms/step - loss: 0.0020 - acc: 0.9993 - precision_m: 0.9855 - recall_m: 0.9904 - f1_m: 0.9879\n",
      "Epoch 11/20\n",
      "2526/2526 [==============================] - 222s 88ms/step - loss: 0.0019 - acc: 0.9994 - precision_m: 0.9867 - recall_m: 0.9913 - f1_m: 0.9889\n",
      "Epoch 12/20\n",
      "2526/2526 [==============================] - 223s 88ms/step - loss: 0.0017 - acc: 0.9994 - precision_m: 0.9878 - recall_m: 0.9918 - f1_m: 0.9898\n",
      "Epoch 13/20\n",
      "2526/2526 [==============================] - 222s 88ms/step - loss: 0.0016 - acc: 0.9994 - precision_m: 0.9884 - recall_m: 0.9924 - f1_m: 0.9904\n",
      "Epoch 14/20\n",
      "2526/2526 [==============================] - 222s 88ms/step - loss: 0.0015 - acc: 0.9995 - precision_m: 0.9891 - recall_m: 0.9928 - f1_m: 0.9909\n",
      "Epoch 15/20\n",
      "2526/2526 [==============================] - 222s 88ms/step - loss: 0.0015 - acc: 0.9995 - precision_m: 0.9897 - recall_m: 0.9933 - f1_m: 0.9915\n",
      "Epoch 16/20\n",
      "2526/2526 [==============================] - 223s 88ms/step - loss: 0.0014 - acc: 0.9995 - precision_m: 0.9903 - recall_m: 0.9936 - f1_m: 0.9919\n",
      "Epoch 17/20\n",
      "2526/2526 [==============================] - 222s 88ms/step - loss: 0.0013 - acc: 0.9996 - precision_m: 0.9906 - recall_m: 0.9938 - f1_m: 0.9922\n",
      "Epoch 18/20\n",
      "2526/2526 [==============================] - 222s 88ms/step - loss: 0.0013 - acc: 0.9996 - precision_m: 0.9913 - recall_m: 0.9943 - f1_m: 0.9928\n",
      "Epoch 19/20\n",
      "2526/2526 [==============================] - 222s 88ms/step - loss: 0.0012 - acc: 0.9996 - precision_m: 0.9913 - recall_m: 0.9943 - f1_m: 0.9928\n",
      "Epoch 20/20\n",
      "2526/2526 [==============================] - 222s 88ms/step - loss: 0.0012 - acc: 0.9996 - precision_m: 0.9918 - recall_m: 0.9946 - f1_m: 0.9932\n",
      "Score for fold 3: loss of 0.01750924065709114; acc of 0.9977114796638489; precision_m of 0.6023048758506775; recall_m of 0.6435322165489197; f1_m of 0.5898712277412415 %\n",
      "Training on fold 4/10..........\n",
      "4: started oversampling\n",
      "4: finished assigning sample weights\n",
      "4: started oversampling\n",
      "4: finished assigning sample weights\n",
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_6 (Embedding)     (None, 49, 32)            1345824   \n",
      "                                                                 \n",
      " bidirectional_6 (Bidirectio  (None, 49, 64)           16640     \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " lstm_13 (LSTM)              (None, 49, 32)            12416     \n",
      "                                                                 \n",
      " time_distributed_6 (TimeDis  (None, 49, 1)            33        \n",
      " tributed)                                                       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,374,913\n",
      "Trainable params: 1,374,913\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "2526/2526 [==============================] - 267s 104ms/step - loss: 0.0278 - acc: 0.9912 - precision_m: 0.8259 - recall_m: 0.7914 - f1_m: 0.7996\n",
      "Epoch 2/20\n",
      "2526/2526 [==============================] - 265s 105ms/step - loss: 0.0094 - acc: 0.9968 - precision_m: 0.9359 - recall_m: 0.9540 - f1_m: 0.9446\n",
      "Epoch 3/20\n",
      "2526/2526 [==============================] - 262s 104ms/step - loss: 0.0067 - acc: 0.9978 - precision_m: 0.9537 - recall_m: 0.9701 - f1_m: 0.9617\n",
      "Epoch 4/20\n",
      "2526/2526 [==============================] - 261s 103ms/step - loss: 0.0051 - acc: 0.9983 - precision_m: 0.9640 - recall_m: 0.9773 - f1_m: 0.9705\n",
      "Epoch 5/20\n",
      "2526/2526 [==============================] - 261s 103ms/step - loss: 0.0040 - acc: 0.9986 - precision_m: 0.9708 - recall_m: 0.9815 - f1_m: 0.9761\n",
      "Epoch 6/20\n",
      "2526/2526 [==============================] - 265s 105ms/step - loss: 0.0034 - acc: 0.9988 - precision_m: 0.9755 - recall_m: 0.9844 - f1_m: 0.9798\n",
      "Epoch 7/20\n",
      "2526/2526 [==============================] - 265s 105ms/step - loss: 0.0029 - acc: 0.9990 - precision_m: 0.9788 - recall_m: 0.9865 - f1_m: 0.9826\n",
      "Epoch 8/20\n",
      "2526/2526 [==============================] - 261s 103ms/step - loss: 0.0026 - acc: 0.9991 - precision_m: 0.9813 - recall_m: 0.9880 - f1_m: 0.9846\n",
      "Epoch 9/20\n",
      "2526/2526 [==============================] - 261s 103ms/step - loss: 0.0023 - acc: 0.9992 - precision_m: 0.9832 - recall_m: 0.9894 - f1_m: 0.9862\n",
      "Epoch 10/20\n",
      "2526/2526 [==============================] - 262s 104ms/step - loss: 0.0021 - acc: 0.9993 - precision_m: 0.9852 - recall_m: 0.9905 - f1_m: 0.9878\n",
      "Epoch 11/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2526/2526 [==============================] - 265s 105ms/step - loss: 0.0019 - acc: 0.9994 - precision_m: 0.9862 - recall_m: 0.9913 - f1_m: 0.9887\n",
      "Epoch 12/20\n",
      "2526/2526 [==============================] - 265s 105ms/step - loss: 0.0018 - acc: 0.9994 - precision_m: 0.9876 - recall_m: 0.9921 - f1_m: 0.9898\n",
      "Epoch 13/20\n",
      "2526/2526 [==============================] - 266s 105ms/step - loss: 0.0016 - acc: 0.9995 - precision_m: 0.9884 - recall_m: 0.9926 - f1_m: 0.9905\n",
      "Epoch 14/20\n",
      "2526/2526 [==============================] - 263s 104ms/step - loss: 0.0016 - acc: 0.9995 - precision_m: 0.9892 - recall_m: 0.9929 - f1_m: 0.9910\n",
      "Epoch 15/20\n",
      "2526/2526 [==============================] - 266s 105ms/step - loss: 0.0015 - acc: 0.9995 - precision_m: 0.9895 - recall_m: 0.9932 - f1_m: 0.9913\n",
      "Epoch 16/20\n",
      "2526/2526 [==============================] - 263s 104ms/step - loss: 0.0014 - acc: 0.9995 - precision_m: 0.9902 - recall_m: 0.9937 - f1_m: 0.9919\n",
      "Epoch 17/20\n",
      "2526/2526 [==============================] - 262s 104ms/step - loss: 0.0013 - acc: 0.9996 - precision_m: 0.9906 - recall_m: 0.9939 - f1_m: 0.9922\n",
      "Epoch 18/20\n",
      "2526/2526 [==============================] - 266s 105ms/step - loss: 0.0013 - acc: 0.9996 - precision_m: 0.9910 - recall_m: 0.9942 - f1_m: 0.9926\n",
      "Epoch 19/20\n",
      "2526/2526 [==============================] - 263s 104ms/step - loss: 0.0012 - acc: 0.9996 - precision_m: 0.9915 - recall_m: 0.9944 - f1_m: 0.9929\n",
      "Epoch 20/20\n",
      "2526/2526 [==============================] - 265s 105ms/step - loss: 0.0012 - acc: 0.9996 - precision_m: 0.9919 - recall_m: 0.9948 - f1_m: 0.9934\n",
      "Score for fold 4: loss of 0.01724899932742119; acc of 0.9976000785827637; precision_m of 0.6020651459693909; recall_m of 0.6472711563110352; f1_m of 0.5964069366455078 %\n",
      "Training on fold 5/10..........\n",
      "5: started oversampling\n",
      "5: finished assigning sample weights\n",
      "5: started oversampling\n",
      "5: finished assigning sample weights\n",
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_7 (Embedding)     (None, 49, 32)            1345824   \n",
      "                                                                 \n",
      " bidirectional_7 (Bidirectio  (None, 49, 64)           16640     \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " lstm_15 (LSTM)              (None, 49, 32)            12416     \n",
      "                                                                 \n",
      " time_distributed_7 (TimeDis  (None, 49, 1)            33        \n",
      " tributed)                                                       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,374,913\n",
      "Trainable params: 1,374,913\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "2526/2526 [==============================] - 306s 119ms/step - loss: 0.0285 - acc: 0.9910 - precision_m: 0.8262 - recall_m: 0.7832 - f1_m: 0.7919\n",
      "Epoch 2/20\n",
      "2526/2526 [==============================] - 297s 118ms/step - loss: 0.0093 - acc: 0.9969 - precision_m: 0.9365 - recall_m: 0.9544 - f1_m: 0.9452\n",
      "Epoch 3/20\n",
      "2526/2526 [==============================] - 294s 116ms/step - loss: 0.0067 - acc: 0.9978 - precision_m: 0.9529 - recall_m: 0.9702 - f1_m: 0.9613\n",
      "Epoch 4/20\n",
      "2526/2526 [==============================] - 294s 116ms/step - loss: 0.0050 - acc: 0.9983 - precision_m: 0.9640 - recall_m: 0.9783 - f1_m: 0.9710\n",
      "Epoch 5/20\n",
      "2526/2526 [==============================] - 294s 116ms/step - loss: 0.0040 - acc: 0.9987 - precision_m: 0.9709 - recall_m: 0.9826 - f1_m: 0.9766\n",
      "Epoch 6/20\n",
      "2526/2526 [==============================] - 294s 116ms/step - loss: 0.0033 - acc: 0.9989 - precision_m: 0.9754 - recall_m: 0.9849 - f1_m: 0.9800\n",
      "Epoch 7/20\n",
      "2526/2526 [==============================] - 294s 116ms/step - loss: 0.0029 - acc: 0.9990 - precision_m: 0.9790 - recall_m: 0.9870 - f1_m: 0.9829\n",
      "Epoch 8/20\n",
      "2526/2526 [==============================] - 294s 116ms/step - loss: 0.0025 - acc: 0.9991 - precision_m: 0.9820 - recall_m: 0.9884 - f1_m: 0.9852\n",
      "Epoch 9/20\n",
      "2526/2526 [==============================] - 294s 117ms/step - loss: 0.0022 - acc: 0.9992 - precision_m: 0.9837 - recall_m: 0.9898 - f1_m: 0.9867\n",
      "Epoch 10/20\n",
      "2526/2526 [==============================] - 294s 116ms/step - loss: 0.0021 - acc: 0.9993 - precision_m: 0.9852 - recall_m: 0.9903 - f1_m: 0.9877\n",
      "Epoch 11/20\n",
      "2526/2526 [==============================] - 294s 116ms/step - loss: 0.0019 - acc: 0.9994 - precision_m: 0.9866 - recall_m: 0.9912 - f1_m: 0.9889\n",
      "Epoch 12/20\n",
      "2526/2526 [==============================] - 294s 116ms/step - loss: 0.0018 - acc: 0.9994 - precision_m: 0.9876 - recall_m: 0.9919 - f1_m: 0.9897\n",
      "Epoch 13/20\n",
      "2526/2526 [==============================] - 294s 116ms/step - loss: 0.0016 - acc: 0.9995 - precision_m: 0.9887 - recall_m: 0.9925 - f1_m: 0.9906\n",
      "Epoch 14/20\n",
      "2526/2526 [==============================] - 294s 116ms/step - loss: 0.0015 - acc: 0.9995 - precision_m: 0.9891 - recall_m: 0.9930 - f1_m: 0.9910\n",
      "Epoch 15/20\n",
      "2526/2526 [==============================] - 294s 117ms/step - loss: 0.0015 - acc: 0.9995 - precision_m: 0.9897 - recall_m: 0.9932 - f1_m: 0.9915\n",
      "Epoch 16/20\n",
      "2526/2526 [==============================] - 294s 117ms/step - loss: 0.0014 - acc: 0.9996 - precision_m: 0.9906 - recall_m: 0.9938 - f1_m: 0.9921\n",
      "Epoch 17/20\n",
      "2526/2526 [==============================] - 294s 117ms/step - loss: 0.0013 - acc: 0.9996 - precision_m: 0.9907 - recall_m: 0.9939 - f1_m: 0.9923\n",
      "Epoch 18/20\n",
      "2526/2526 [==============================] - 294s 117ms/step - loss: 0.0012 - acc: 0.9996 - precision_m: 0.9914 - recall_m: 0.9943 - f1_m: 0.9928\n",
      "Epoch 19/20\n",
      "2526/2526 [==============================] - 294s 117ms/step - loss: 0.0012 - acc: 0.9996 - precision_m: 0.9916 - recall_m: 0.9944 - f1_m: 0.9930\n",
      "Epoch 20/20\n",
      "2526/2526 [==============================] - 294s 117ms/step - loss: 0.0012 - acc: 0.9996 - precision_m: 0.9920 - recall_m: 0.9947 - f1_m: 0.9933\n",
      "Score for fold 5: loss of 0.01699858531355858; acc of 0.9977681636810303; precision_m of 0.5992124080657959; recall_m of 0.6220497488975525; f1_m of 0.580924391746521 %\n",
      "Training on fold 6/10..........\n",
      "6: started oversampling\n",
      "6: finished assigning sample weights\n",
      "6: started oversampling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jonat\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:70: FutureWarning: Pass classes=[0 1], y=[0 0 0 ... 0 0 0] as keyword args. From version 1.0 (renaming of 0.25) passing these as positional arguments will result in an error\n",
      "  warnings.warn(f\"Pass {args_msg} as keyword args. From version \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6: finished assigning sample weights\n",
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_8 (Embedding)     (None, 49, 32)            1345824   \n",
      "                                                                 \n",
      " bidirectional_8 (Bidirectio  (None, 49, 64)           16640     \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " lstm_17 (LSTM)              (None, 49, 32)            12416     \n",
      "                                                                 \n",
      " time_distributed_8 (TimeDis  (None, 49, 1)            33        \n",
      " tributed)                                                       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,374,913\n",
      "Trainable params: 1,374,913\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "2526/2526 [==============================] - 250s 97ms/step - loss: 0.0275 - acc: 0.9912 - precision_m: 0.8390 - recall_m: 0.7926 - f1_m: 0.8033\n",
      "Epoch 2/20\n",
      "2526/2526 [==============================] - 245s 97ms/step - loss: 0.0090 - acc: 0.9970 - precision_m: 0.9385 - recall_m: 0.9563 - f1_m: 0.9471\n",
      "Epoch 3/20\n",
      "2526/2526 [==============================] - 250s 99ms/step - loss: 0.0064 - acc: 0.9979 - precision_m: 0.9551 - recall_m: 0.9716 - f1_m: 0.9631\n",
      "Epoch 4/20\n",
      "2526/2526 [==============================] - 251s 99ms/step - loss: 0.0049 - acc: 0.9984 - precision_m: 0.9654 - recall_m: 0.9788 - f1_m: 0.9720\n",
      "Epoch 5/20\n",
      "2526/2526 [==============================] - 251s 99ms/step - loss: 0.0040 - acc: 0.9987 - precision_m: 0.9713 - recall_m: 0.9829 - f1_m: 0.9770\n",
      "Epoch 6/20\n",
      "2526/2526 [==============================] - 251s 99ms/step - loss: 0.0033 - acc: 0.9989 - precision_m: 0.9757 - recall_m: 0.9855 - f1_m: 0.9805\n",
      "Epoch 7/20\n",
      "2526/2526 [==============================] - 252s 100ms/step - loss: 0.0029 - acc: 0.9990 - precision_m: 0.9789 - recall_m: 0.9872 - f1_m: 0.9829\n",
      "Epoch 8/20\n",
      "2526/2526 [==============================] - 250s 99ms/step - loss: 0.0025 - acc: 0.9991 - precision_m: 0.9814 - recall_m: 0.9888 - f1_m: 0.9851\n",
      "Epoch 9/20\n",
      "2526/2526 [==============================] - 248s 98ms/step - loss: 0.0023 - acc: 0.9992 - precision_m: 0.9833 - recall_m: 0.9898 - f1_m: 0.9865\n",
      "Epoch 10/20\n",
      "2526/2526 [==============================] - 252s 100ms/step - loss: 0.0021 - acc: 0.9993 - precision_m: 0.9849 - recall_m: 0.9905 - f1_m: 0.9877\n",
      "Epoch 11/20\n",
      "2526/2526 [==============================] - 253s 100ms/step - loss: 0.0019 - acc: 0.9993 - precision_m: 0.9862 - recall_m: 0.9911 - f1_m: 0.9886\n",
      "Epoch 12/20\n",
      "2526/2526 [==============================] - 252s 100ms/step - loss: 0.0018 - acc: 0.9994 - precision_m: 0.9873 - recall_m: 0.9920 - f1_m: 0.9896\n",
      "Epoch 13/20\n",
      "2526/2526 [==============================] - 252s 100ms/step - loss: 0.0016 - acc: 0.9994 - precision_m: 0.9881 - recall_m: 0.9926 - f1_m: 0.9903\n",
      "Epoch 14/20\n",
      "2526/2526 [==============================] - 252s 100ms/step - loss: 0.0016 - acc: 0.9995 - precision_m: 0.9889 - recall_m: 0.9928 - f1_m: 0.9909\n",
      "Epoch 15/20\n",
      "2526/2526 [==============================] - 253s 100ms/step - loss: 0.0015 - acc: 0.9995 - precision_m: 0.9896 - recall_m: 0.9934 - f1_m: 0.9915\n",
      "Epoch 16/20\n",
      "2526/2526 [==============================] - 251s 99ms/step - loss: 0.0014 - acc: 0.9995 - precision_m: 0.9899 - recall_m: 0.9936 - f1_m: 0.9917\n",
      "Epoch 17/20\n",
      "2526/2526 [==============================] - 246s 97ms/step - loss: 0.0013 - acc: 0.9996 - precision_m: 0.9905 - recall_m: 0.9940 - f1_m: 0.9922\n",
      "Epoch 18/20\n",
      "2526/2526 [==============================] - 249s 98ms/step - loss: 0.0013 - acc: 0.9996 - precision_m: 0.9909 - recall_m: 0.9942 - f1_m: 0.9925\n",
      "Epoch 19/20\n",
      "2526/2526 [==============================] - 242s 96ms/step - loss: 0.0012 - acc: 0.9996 - precision_m: 0.9912 - recall_m: 0.9943 - f1_m: 0.9927\n",
      "Epoch 20/20\n",
      "2526/2526 [==============================] - 243s 96ms/step - loss: 0.0012 - acc: 0.9996 - precision_m: 0.9918 - recall_m: 0.9946 - f1_m: 0.9931\n",
      "Score for fold 6: loss of 0.01711213029921055; acc of 0.9976215362548828; precision_m of 0.5959658026695251; recall_m of 0.6533404588699341; f1_m of 0.5917242765426636 %\n",
      "Training on fold 7/10..........\n",
      "7: started oversampling\n",
      "7: finished assigning sample weights\n",
      "7: started oversampling\n",
      "7: finished assigning sample weights\n",
      "Model: \"sequential_9\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_9 (Embedding)     (None, 49, 32)            1345824   \n",
      "                                                                 \n",
      " bidirectional_9 (Bidirectio  (None, 49, 64)           16640     \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " lstm_19 (LSTM)              (None, 49, 32)            12416     \n",
      "                                                                 \n",
      " time_distributed_9 (TimeDis  (None, 49, 1)            33        \n",
      " tributed)                                                       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,374,913\n",
      "Trainable params: 1,374,913\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "2526/2526 [==============================] - 258s 101ms/step - loss: 0.0285 - acc: 0.9909 - precision_m: 0.8201 - recall_m: 0.7816 - f1_m: 0.7916\n",
      "Epoch 2/20\n",
      "2526/2526 [==============================] - 256s 101ms/step - loss: 0.0097 - acc: 0.9967 - precision_m: 0.9352 - recall_m: 0.9517 - f1_m: 0.9432\n",
      "Epoch 3/20\n",
      "2526/2526 [==============================] - 259s 103ms/step - loss: 0.0067 - acc: 0.9978 - precision_m: 0.9534 - recall_m: 0.9689 - f1_m: 0.9610\n",
      "Epoch 4/20\n",
      "2526/2526 [==============================] - 260s 103ms/step - loss: 0.0051 - acc: 0.9983 - precision_m: 0.9637 - recall_m: 0.9768 - f1_m: 0.9701\n",
      "Epoch 5/20\n",
      "2526/2526 [==============================] - 261s 103ms/step - loss: 0.0041 - acc: 0.9986 - precision_m: 0.9705 - recall_m: 0.9811 - f1_m: 0.9757\n",
      "Epoch 6/20\n",
      "2526/2526 [==============================] - 260s 103ms/step - loss: 0.0035 - acc: 0.9988 - precision_m: 0.9751 - recall_m: 0.9839 - f1_m: 0.9794\n",
      "Epoch 7/20\n",
      "2526/2526 [==============================] - 256s 101ms/step - loss: 0.0030 - acc: 0.9990 - precision_m: 0.9787 - recall_m: 0.9863 - f1_m: 0.9824\n",
      "Epoch 8/20\n",
      "2526/2526 [==============================] - 261s 103ms/step - loss: 0.0026 - acc: 0.9991 - precision_m: 0.9809 - recall_m: 0.9877 - f1_m: 0.9842\n",
      "Epoch 9/20\n",
      "2526/2526 [==============================] - 258s 102ms/step - loss: 0.0024 - acc: 0.9992 - precision_m: 0.9831 - recall_m: 0.9890 - f1_m: 0.9860\n",
      "Epoch 10/20\n",
      "2526/2526 [==============================] - 256s 101ms/step - loss: 0.0022 - acc: 0.9993 - precision_m: 0.9846 - recall_m: 0.9900 - f1_m: 0.9873\n",
      "Epoch 11/20\n",
      "2526/2526 [==============================] - 258s 102ms/step - loss: 0.0020 - acc: 0.9993 - precision_m: 0.9861 - recall_m: 0.9908 - f1_m: 0.9884\n",
      "Epoch 12/20\n",
      "2526/2526 [==============================] - 256s 102ms/step - loss: 0.0018 - acc: 0.9994 - precision_m: 0.9871 - recall_m: 0.9915 - f1_m: 0.9892\n",
      "Epoch 13/20\n",
      "2526/2526 [==============================] - 262s 104ms/step - loss: 0.0017 - acc: 0.9994 - precision_m: 0.9881 - recall_m: 0.9920 - f1_m: 0.9900\n",
      "Epoch 14/20\n",
      "2526/2526 [==============================] - 259s 102ms/step - loss: 0.0016 - acc: 0.9995 - precision_m: 0.9889 - recall_m: 0.9926 - f1_m: 0.9907\n",
      "Epoch 15/20\n",
      "2526/2526 [==============================] - 255s 101ms/step - loss: 0.0015 - acc: 0.9995 - precision_m: 0.9896 - recall_m: 0.9931 - f1_m: 0.9914\n",
      "Epoch 16/20\n",
      "2526/2526 [==============================] - 257s 102ms/step - loss: 0.0014 - acc: 0.9995 - precision_m: 0.9899 - recall_m: 0.9934 - f1_m: 0.9916\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/20\n",
      "2526/2526 [==============================] - 259s 103ms/step - loss: 0.0014 - acc: 0.9995 - precision_m: 0.9905 - recall_m: 0.9937 - f1_m: 0.9921\n",
      "Epoch 18/20\n",
      "2526/2526 [==============================] - 259s 102ms/step - loss: 0.0013 - acc: 0.9996 - precision_m: 0.9909 - recall_m: 0.9940 - f1_m: 0.9924\n",
      "Epoch 19/20\n",
      "2526/2526 [==============================] - 260s 103ms/step - loss: 0.0013 - acc: 0.9996 - precision_m: 0.9913 - recall_m: 0.9942 - f1_m: 0.9928\n",
      "Epoch 20/20\n",
      "2526/2526 [==============================] - 255s 101ms/step - loss: 0.0012 - acc: 0.9996 - precision_m: 0.9916 - recall_m: 0.9944 - f1_m: 0.9930\n",
      "Score for fold 7: loss of 0.015936661511659622; acc of 0.9977186322212219; precision_m of 0.5936220288276672; recall_m of 0.6753342151641846; f1_m of 0.6041651368141174 %\n",
      "Training on fold 8/10..........\n",
      "8: started oversampling\n",
      "8: finished assigning sample weights\n",
      "8: started oversampling\n",
      "8: finished assigning sample weights\n",
      "Model: \"sequential_10\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_10 (Embedding)    (None, 49, 32)            1345824   \n",
      "                                                                 \n",
      " bidirectional_10 (Bidirecti  (None, 49, 64)           16640     \n",
      " onal)                                                           \n",
      "                                                                 \n",
      " lstm_21 (LSTM)              (None, 49, 32)            12416     \n",
      "                                                                 \n",
      " time_distributed_10 (TimeDi  (None, 49, 1)            33        \n",
      " stributed)                                                      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,374,913\n",
      "Trainable params: 1,374,913\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "2526/2526 [==============================] - 299s 117ms/step - loss: 0.0274 - acc: 0.9914 - precision_m: 0.8252 - recall_m: 0.7933 - f1_m: 0.8010\n",
      "Epoch 2/20\n",
      "2526/2526 [==============================] - 295s 117ms/step - loss: 0.0090 - acc: 0.9970 - precision_m: 0.9393 - recall_m: 0.9556 - f1_m: 0.9472\n",
      "Epoch 3/20\n",
      "2526/2526 [==============================] - 294s 117ms/step - loss: 0.0062 - acc: 0.9980 - precision_m: 0.9575 - recall_m: 0.9723 - f1_m: 0.9647\n",
      "Epoch 4/20\n",
      "2526/2526 [==============================] - 294s 117ms/step - loss: 0.0049 - acc: 0.9984 - precision_m: 0.9660 - recall_m: 0.9789 - f1_m: 0.9723\n",
      "Epoch 5/20\n",
      "2526/2526 [==============================] - 294s 117ms/step - loss: 0.0040 - acc: 0.9987 - precision_m: 0.9715 - recall_m: 0.9827 - f1_m: 0.9770\n",
      "Epoch 6/20\n",
      "2526/2526 [==============================] - 295s 117ms/step - loss: 0.0034 - acc: 0.9989 - precision_m: 0.9759 - recall_m: 0.9856 - f1_m: 0.9806\n",
      "Epoch 7/20\n",
      "2526/2526 [==============================] - 295s 117ms/step - loss: 0.0029 - acc: 0.9990 - precision_m: 0.9793 - recall_m: 0.9873 - f1_m: 0.9832\n",
      "Epoch 8/20\n",
      "2526/2526 [==============================] - 295s 117ms/step - loss: 0.0025 - acc: 0.9991 - precision_m: 0.9815 - recall_m: 0.9886 - f1_m: 0.9850\n",
      "Epoch 9/20\n",
      "2526/2526 [==============================] - 295s 117ms/step - loss: 0.0023 - acc: 0.9992 - precision_m: 0.9837 - recall_m: 0.9898 - f1_m: 0.9867\n",
      "Epoch 10/20\n",
      "2526/2526 [==============================] - 295s 117ms/step - loss: 0.0021 - acc: 0.9993 - precision_m: 0.9854 - recall_m: 0.9907 - f1_m: 0.9880\n",
      "Epoch 11/20\n",
      "2526/2526 [==============================] - 295s 117ms/step - loss: 0.0019 - acc: 0.9994 - precision_m: 0.9867 - recall_m: 0.9914 - f1_m: 0.9890\n",
      "Epoch 12/20\n",
      "2526/2526 [==============================] - 294s 116ms/step - loss: 0.0018 - acc: 0.9994 - precision_m: 0.9873 - recall_m: 0.9920 - f1_m: 0.9896\n",
      "Epoch 13/20\n",
      "2526/2526 [==============================] - 295s 117ms/step - loss: 0.0016 - acc: 0.9995 - precision_m: 0.9884 - recall_m: 0.9926 - f1_m: 0.9904\n",
      "Epoch 14/20\n",
      "2526/2526 [==============================] - 295s 117ms/step - loss: 0.0015 - acc: 0.9995 - precision_m: 0.9893 - recall_m: 0.9931 - f1_m: 0.9911\n",
      "Epoch 15/20\n",
      "2526/2526 [==============================] - 294s 117ms/step - loss: 0.0014 - acc: 0.9995 - precision_m: 0.9899 - recall_m: 0.9935 - f1_m: 0.9917\n",
      "Epoch 16/20\n",
      "2526/2526 [==============================] - 294s 117ms/step - loss: 0.0014 - acc: 0.9996 - precision_m: 0.9906 - recall_m: 0.9938 - f1_m: 0.9922\n",
      "Epoch 17/20\n",
      "2526/2526 [==============================] - 294s 117ms/step - loss: 0.0013 - acc: 0.9996 - precision_m: 0.9908 - recall_m: 0.9939 - f1_m: 0.9923\n",
      "Epoch 18/20\n",
      "2526/2526 [==============================] - 295s 117ms/step - loss: 0.0013 - acc: 0.9996 - precision_m: 0.9911 - recall_m: 0.9942 - f1_m: 0.9926\n",
      "Epoch 19/20\n",
      "2526/2526 [==============================] - 295s 117ms/step - loss: 0.0012 - acc: 0.9996 - precision_m: 0.9916 - recall_m: 0.9945 - f1_m: 0.9931\n",
      "Epoch 20/20\n",
      "2526/2526 [==============================] - 295s 117ms/step - loss: 0.0012 - acc: 0.9996 - precision_m: 0.9920 - recall_m: 0.9948 - f1_m: 0.9934\n",
      "Score for fold 8: loss of 0.01637945882976055; acc of 0.9976826906204224; precision_m of 0.6018729209899902; recall_m of 0.6506146192550659; f1_m of 0.5968582034111023 %\n",
      "Training on fold 9/10..........\n",
      "9: started oversampling\n",
      "9: finished assigning sample weights\n",
      "9: started oversampling\n",
      "9: finished assigning sample weights\n",
      "Model: \"sequential_11\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_11 (Embedding)    (None, 49, 32)            1345824   \n",
      "                                                                 \n",
      " bidirectional_11 (Bidirecti  (None, 49, 64)           16640     \n",
      " onal)                                                           \n",
      "                                                                 \n",
      " lstm_23 (LSTM)              (None, 49, 32)            12416     \n",
      "                                                                 \n",
      " time_distributed_11 (TimeDi  (None, 49, 1)            33        \n",
      " stributed)                                                      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,374,913\n",
      "Trainable params: 1,374,913\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "2526/2526 [==============================] - 309s 121ms/step - loss: 0.0281 - acc: 0.9909 - precision_m: 0.8220 - recall_m: 0.7877 - f1_m: 0.7951\n",
      "Epoch 2/20\n",
      "2526/2526 [==============================] - 305s 121ms/step - loss: 0.0090 - acc: 0.9970 - precision_m: 0.9395 - recall_m: 0.9567 - f1_m: 0.9478\n",
      "Epoch 3/20\n",
      "2526/2526 [==============================] - 305s 121ms/step - loss: 0.0062 - acc: 0.9979 - precision_m: 0.9570 - recall_m: 0.9714 - f1_m: 0.9640\n",
      "Epoch 4/20\n",
      "2526/2526 [==============================] - 305s 121ms/step - loss: 0.0048 - acc: 0.9984 - precision_m: 0.9666 - recall_m: 0.9778 - f1_m: 0.9720\n",
      "Epoch 5/20\n",
      "2526/2526 [==============================] - 305s 121ms/step - loss: 0.0038 - acc: 0.9987 - precision_m: 0.9725 - recall_m: 0.9824 - f1_m: 0.9774\n",
      "Epoch 6/20\n",
      "2526/2526 [==============================] - 305s 121ms/step - loss: 0.0033 - acc: 0.9989 - precision_m: 0.9764 - recall_m: 0.9848 - f1_m: 0.9805\n",
      "Epoch 7/20\n",
      "2526/2526 [==============================] - 305s 121ms/step - loss: 0.0028 - acc: 0.9990 - precision_m: 0.9798 - recall_m: 0.9868 - f1_m: 0.9832\n",
      "Epoch 8/20\n",
      "2526/2526 [==============================] - 305s 121ms/step - loss: 0.0025 - acc: 0.9992 - precision_m: 0.9822 - recall_m: 0.9885 - f1_m: 0.9853\n",
      "Epoch 9/20\n",
      "2526/2526 [==============================] - 305s 121ms/step - loss: 0.0022 - acc: 0.9993 - precision_m: 0.9842 - recall_m: 0.9898 - f1_m: 0.9869\n",
      "Epoch 10/20\n",
      "2526/2526 [==============================] - 305s 121ms/step - loss: 0.0020 - acc: 0.9993 - precision_m: 0.9856 - recall_m: 0.9905 - f1_m: 0.9880\n",
      "Epoch 11/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2526/2526 [==============================] - 305s 121ms/step - loss: 0.0018 - acc: 0.9994 - precision_m: 0.9869 - recall_m: 0.9914 - f1_m: 0.9891\n",
      "Epoch 12/20\n",
      "2526/2526 [==============================] - 305s 121ms/step - loss: 0.0017 - acc: 0.9994 - precision_m: 0.9879 - recall_m: 0.9922 - f1_m: 0.9900\n",
      "Epoch 13/20\n",
      "2526/2526 [==============================] - 305s 121ms/step - loss: 0.0016 - acc: 0.9995 - precision_m: 0.9886 - recall_m: 0.9928 - f1_m: 0.9907\n",
      "Epoch 14/20\n",
      "2526/2526 [==============================] - 307s 121ms/step - loss: 0.0015 - acc: 0.9995 - precision_m: 0.9895 - recall_m: 0.9931 - f1_m: 0.9912\n",
      "Epoch 15/20\n",
      "2526/2526 [==============================] - 307s 122ms/step - loss: 0.0014 - acc: 0.9995 - precision_m: 0.9901 - recall_m: 0.9936 - f1_m: 0.9918\n",
      "Epoch 16/20\n",
      "2526/2526 [==============================] - 302s 120ms/step - loss: 0.0013 - acc: 0.9996 - precision_m: 0.9906 - recall_m: 0.9938 - f1_m: 0.9922\n",
      "Epoch 17/20\n",
      "2526/2526 [==============================] - 302s 120ms/step - loss: 0.0013 - acc: 0.9996 - precision_m: 0.9909 - recall_m: 0.9941 - f1_m: 0.9925\n",
      "Epoch 18/20\n",
      "2526/2526 [==============================] - 302s 120ms/step - loss: 0.0012 - acc: 0.9996 - precision_m: 0.9913 - recall_m: 0.9943 - f1_m: 0.9928\n",
      "Epoch 19/20\n",
      "2526/2526 [==============================] - 300s 119ms/step - loss: 0.0012 - acc: 0.9996 - precision_m: 0.9918 - recall_m: 0.9947 - f1_m: 0.9932\n",
      "Epoch 20/20\n",
      "2526/2526 [==============================] - 300s 119ms/step - loss: 0.0011 - acc: 0.9996 - precision_m: 0.9920 - recall_m: 0.9948 - f1_m: 0.9934\n",
      "Score for fold 9: loss of 0.01721785217523575; acc of 0.99766606092453; precision_m of 0.5998965501785278; recall_m of 0.628982424736023; f1_m of 0.5877277851104736 %\n",
      "Training on fold 10/10..........\n",
      "10: started oversampling\n",
      "10: finished assigning sample weights\n",
      "10: started oversampling\n",
      "10: finished assigning sample weights\n",
      "Model: \"sequential_12\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_12 (Embedding)    (None, 49, 32)            1345824   \n",
      "                                                                 \n",
      " bidirectional_12 (Bidirecti  (None, 49, 64)           16640     \n",
      " onal)                                                           \n",
      "                                                                 \n",
      " lstm_25 (LSTM)              (None, 49, 32)            12416     \n",
      "                                                                 \n",
      " time_distributed_12 (TimeDi  (None, 49, 1)            33        \n",
      " stributed)                                                      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,374,913\n",
      "Trainable params: 1,374,913\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "2526/2526 [==============================] - 292s 114ms/step - loss: 0.0279 - acc: 0.9910 - precision_m: 0.8266 - recall_m: 0.7912 - f1_m: 0.8002\n",
      "Epoch 2/20\n",
      "2526/2526 [==============================] - 293s 116ms/step - loss: 0.0090 - acc: 0.9970 - precision_m: 0.9382 - recall_m: 0.9564 - f1_m: 0.9470\n",
      "Epoch 3/20\n",
      "2526/2526 [==============================] - 295s 117ms/step - loss: 0.0062 - acc: 0.9979 - precision_m: 0.9564 - recall_m: 0.9718 - f1_m: 0.9639\n",
      "Epoch 4/20\n",
      "2526/2526 [==============================] - 290s 115ms/step - loss: 0.0047 - acc: 0.9984 - precision_m: 0.9665 - recall_m: 0.9780 - f1_m: 0.9721\n",
      "Epoch 5/20\n",
      "2526/2526 [==============================] - 291s 115ms/step - loss: 0.0038 - acc: 0.9987 - precision_m: 0.9731 - recall_m: 0.9825 - f1_m: 0.9777\n",
      "Epoch 6/20\n",
      "2526/2526 [==============================] - 295s 117ms/step - loss: 0.0032 - acc: 0.9989 - precision_m: 0.9772 - recall_m: 0.9845 - f1_m: 0.9808\n",
      "Epoch 7/20\n",
      "2526/2526 [==============================] - 292s 115ms/step - loss: 0.0027 - acc: 0.9991 - precision_m: 0.9805 - recall_m: 0.9869 - f1_m: 0.9836\n",
      "Epoch 8/20\n",
      "2526/2526 [==============================] - 292s 116ms/step - loss: 0.0024 - acc: 0.9992 - precision_m: 0.9829 - recall_m: 0.9885 - f1_m: 0.9856\n",
      "Epoch 9/20\n",
      "2526/2526 [==============================] - 294s 117ms/step - loss: 0.0022 - acc: 0.9993 - precision_m: 0.9848 - recall_m: 0.9899 - f1_m: 0.9873\n",
      "Epoch 10/20\n",
      "2526/2526 [==============================] - 289s 114ms/step - loss: 0.0020 - acc: 0.9993 - precision_m: 0.9861 - recall_m: 0.9905 - f1_m: 0.9883\n",
      "Epoch 11/20\n",
      "2526/2526 [==============================] - 289s 114ms/step - loss: 0.0018 - acc: 0.9994 - precision_m: 0.9876 - recall_m: 0.9915 - f1_m: 0.9895\n",
      "Epoch 12/20\n",
      "2526/2526 [==============================] - 275s 109ms/step - loss: 0.0017 - acc: 0.9994 - precision_m: 0.9884 - recall_m: 0.9921 - f1_m: 0.9902\n",
      "Epoch 13/20\n",
      "2526/2526 [==============================] - 274s 108ms/step - loss: 0.0016 - acc: 0.9995 - precision_m: 0.9890 - recall_m: 0.9926 - f1_m: 0.9908\n",
      "Epoch 14/20\n",
      "2526/2526 [==============================] - 274s 109ms/step - loss: 0.0015 - acc: 0.9995 - precision_m: 0.9899 - recall_m: 0.9933 - f1_m: 0.9916\n",
      "Epoch 15/20\n",
      "2526/2526 [==============================] - 276s 109ms/step - loss: 0.0014 - acc: 0.9995 - precision_m: 0.9905 - recall_m: 0.9937 - f1_m: 0.9921\n",
      "Epoch 16/20\n",
      "2526/2526 [==============================] - 275s 109ms/step - loss: 0.0013 - acc: 0.9996 - precision_m: 0.9911 - recall_m: 0.9941 - f1_m: 0.9926\n",
      "Epoch 17/20\n",
      "2526/2526 [==============================] - 274s 108ms/step - loss: 0.0013 - acc: 0.9996 - precision_m: 0.9914 - recall_m: 0.9941 - f1_m: 0.9927\n",
      "Epoch 18/20\n",
      "2526/2526 [==============================] - 275s 109ms/step - loss: 0.0012 - acc: 0.9996 - precision_m: 0.9916 - recall_m: 0.9946 - f1_m: 0.9930\n",
      "Epoch 19/20\n",
      "2526/2526 [==============================] - 277s 110ms/step - loss: 0.0011 - acc: 0.9996 - precision_m: 0.9921 - recall_m: 0.9946 - f1_m: 0.9933\n",
      "Epoch 20/20\n",
      "2526/2526 [==============================] - 308s 122ms/step - loss: 0.0011 - acc: 0.9996 - precision_m: 0.9923 - recall_m: 0.9949 - f1_m: 0.9936\n",
      "Score for fold 10: loss of 0.01771022379398346; acc of 0.9976566433906555; precision_m of 0.6163442730903625; recall_m of 0.6595322489738464; f1_m of 0.6025930643081665 %\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "skf = StratifiedKFold(n_splits = 10, shuffle = True)\n",
    "\n",
    "fold_number = 1\n",
    "f1_per_fold = []\n",
    "recall_per_fold = []\n",
    "precision_per_fold = []\n",
    "acc_per_fold = []\n",
    "loss_per_fold = []\n",
    "\n",
    "for i, (train_index, val_index) in enumerate(skf.split(pad_tokens, np.sum(pad_tags, axis = 1))):\n",
    "    \n",
    "    print(\"Training on fold \" + str(i+1) + \"/10..........\")\n",
    "    \n",
    "    #Split training set and validation set\n",
    "    x_train, x_val = pad_tokens[train_index], pad_tokens[val_index]\n",
    "    y_train, y_val = pad_tags[train_index], pad_tags[val_index]\n",
    "    \n",
    "    #Oversample minority class in training set\n",
    "    print(str(fold_number) + \": started oversampling\")\n",
    "    index = 0\n",
    "    for token, tag in zip(x_train, y_train):\n",
    "        if np.sum(tag) >= 1:\n",
    "            token_arr = np.tile(token, 20).reshape((-1, len(token)))\n",
    "            tag_arr = np.tile(tag, 20).reshape((-1, len(tag)))\n",
    "            x_train = np.append(token_arr, x_train, axis=0)\n",
    "            y_train = np.append(tag_arr, y_train, axis=0)\n",
    "        index = index + 1\n",
    "    print(str(fold_number) + \": finished assigning sample weights\")\n",
    "    \n",
    "    #Assigning sample weights in training set\n",
    "    print(str(fold_number) + \": started oversampling\")\n",
    "    weights = class_weight.compute_class_weight('balanced',\n",
    "                                                 np.unique(np.ravel(y_train,order='C')),\n",
    "                                                 np.ravel(y_train,order='C'))\n",
    "    \n",
    "    train_tags2 = np.copy(y_train)\n",
    "    train_tokens2 = np.copy(x_train)\n",
    "    train_tags2 = train_tags2.astype(float)\n",
    "    \n",
    "    indexTotal = 0\n",
    "    for tags in train_tags2:\n",
    "        indexTags = 0\n",
    "        for symptom in tags:\n",
    "            if symptom == 1:\n",
    "                train_tags2[indexTotal][indexTags] = float(weights[1])\n",
    "            else:\n",
    "                train_tags2[indexTotal][indexTags] = float(weights[0])\n",
    "            indexTags = indexTags+1\n",
    "        indexTotal = indexTotal + 1\n",
    "   \n",
    "    weights = train_tags2.reshape((-1, 49, 1))\n",
    "    print(str(fold_number) + \": finished assigning sample weights\")\n",
    "    \n",
    "    #Getting Model Architecture\n",
    "    model = get_bilstm_lstm_model()\n",
    "    \n",
    "    #Running Model\n",
    "    history = model.fit(x_train, y_train, sample_weight = weights, batch_size=128, verbose=1, epochs=20)\n",
    "    \n",
    "    #Evaluate model\n",
    "    scores = model.evaluate(x_val, y_val, verbose = 0)\n",
    "    print(f'Score for fold {fold_number}: {model.metrics_names[0]} of {scores[0]}; {model.metrics_names[1]} of {scores[1]}; {model.metrics_names[2]} of {scores[2]}; {model.metrics_names[3]} of {scores[3]}; {model.metrics_names[4]} of {scores[4]} %')\n",
    "    f1_per_fold.append(scores[4])\n",
    "    recall_per_fold.append(scores[3])\n",
    "    precision_per_fold.append(scores[2])\n",
    "    acc_per_fold.append(scores[1])\n",
    "    loss_per_fold.append(scores[0])\n",
    "    \n",
    "    #Increase fold number\n",
    "    fold_number = fold_number + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score per fold\n",
      "-----------\n",
      "> Fold 1 - Loss: 0.017939984798431396 - Accuracy: 0.9976244568824768 - Precision: 0.5960526466369629 - Recall: 0.6512682437896729 - F1: 0.5915733575820923%\n",
      "-----------\n",
      "> Fold 2 - Loss: 0.016830148175358772 - Accuracy: 0.9977466464042664 - Precision: 0.6145405769348145 - Recall: 0.6440485119819641 - F1: 0.5997841358184814%\n",
      "-----------\n",
      "> Fold 3 - Loss: 0.01750924065709114 - Accuracy: 0.9977114796638489 - Precision: 0.6023048758506775 - Recall: 0.6435322165489197 - F1: 0.5898712277412415%\n",
      "-----------\n",
      "> Fold 4 - Loss: 0.01724899932742119 - Accuracy: 0.9976000785827637 - Precision: 0.6020651459693909 - Recall: 0.6472711563110352 - F1: 0.5964069366455078%\n",
      "-----------\n",
      "> Fold 5 - Loss: 0.01699858531355858 - Accuracy: 0.9977681636810303 - Precision: 0.5992124080657959 - Recall: 0.6220497488975525 - F1: 0.580924391746521%\n",
      "-----------\n",
      "> Fold 6 - Loss: 0.01711213029921055 - Accuracy: 0.9976215362548828 - Precision: 0.5959658026695251 - Recall: 0.6533404588699341 - F1: 0.5917242765426636%\n",
      "-----------\n",
      "> Fold 7 - Loss: 0.015936661511659622 - Accuracy: 0.9977186322212219 - Precision: 0.5936220288276672 - Recall: 0.6753342151641846 - F1: 0.6041651368141174%\n",
      "-----------\n",
      "> Fold 8 - Loss: 0.01637945882976055 - Accuracy: 0.9976826906204224 - Precision: 0.6018729209899902 - Recall: 0.6506146192550659 - F1: 0.5968582034111023%\n",
      "-----------\n",
      "> Fold 9 - Loss: 0.01721785217523575 - Accuracy: 0.99766606092453 - Precision: 0.5998965501785278 - Recall: 0.628982424736023 - F1: 0.5877277851104736%\n",
      "-----------\n",
      "> Fold 10 - Loss: 0.01771022379398346 - Accuracy: 0.9976566433906555 - Precision: 0.6163442730903625 - Recall: 0.6595322489738464 - F1: 0.6025930643081665%\n",
      "------------\n",
      "Average scores for all folds:\n",
      "> Accuracy: 0.9976796388626099 (+- 5.322991658695932e-05)\n",
      "> Precision: 0.6021877229213715 (+- 0.007189946481780827)\n",
      "> Recall: 0.6475973844528198 (+- 0.014127135255790695)\n",
      "> F1: 0.5941628515720367 (+- 0.0068025799083320316)\n",
      "> Loss: 0.0170883284881711\n",
      "------------\n"
     ]
    }
   ],
   "source": [
    "print('Score per fold')\n",
    "for i in range(0, len(acc_per_fold)):\n",
    "    print(\"-----------\")\n",
    "    print(f'> Fold {i+1} - Loss: {loss_per_fold[i]} - Accuracy: {acc_per_fold[i]} - Precision: {precision_per_fold[i]} - Recall: {recall_per_fold[i]} - F1: {f1_per_fold[i]}%')\n",
    "print('------------')\n",
    "print('Average scores for all folds:')\n",
    "print(f'> Accuracy: {np.mean(acc_per_fold)} (+- {np.std(acc_per_fold)})')\n",
    "print(f'> Precision: {np.mean(precision_per_fold)} (+- {np.std(precision_per_fold)})')\n",
    "print(f'> Recall: {np.mean(recall_per_fold)} (+- {np.std(recall_per_fold)})')\n",
    "print(f'> F1: {np.mean(f1_per_fold)} (+- {np.std(f1_per_fold)})')\n",
    "print(f'> Loss: {np.mean(loss_per_fold)}')\n",
    "print('------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
