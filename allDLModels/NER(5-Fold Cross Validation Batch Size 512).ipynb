{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import imblearn\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence</th>\n",
       "      <th>Word</th>\n",
       "      <th>Tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sentence: 1</td>\n",
       "      <td>RECORD</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sentence: 2</td>\n",
       "      <td>OC</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>AM</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>gallstone</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>pancreatitis</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>949802</th>\n",
       "      <td>NaN</td>\n",
       "      <td>M.D.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>949803</th>\n",
       "      <td>Sentence: 132094</td>\n",
       "      <td>END</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>949804</th>\n",
       "      <td>NaN</td>\n",
       "      <td>OF</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>949805</th>\n",
       "      <td>NaN</td>\n",
       "      <td>DISCHARGE</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>949806</th>\n",
       "      <td>NaN</td>\n",
       "      <td>ORDERS</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>949807 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                Sentence          Word  Tag\n",
       "0            Sentence: 1        RECORD    0\n",
       "1            Sentence: 2            OC    0\n",
       "2                    NaN            AM    0\n",
       "3                    NaN     gallstone    0\n",
       "4                    NaN  pancreatitis    0\n",
       "...                  ...           ...  ...\n",
       "949802               NaN          M.D.    0\n",
       "949803  Sentence: 132094           END    0\n",
       "949804               NaN            OF    0\n",
       "949805               NaN     DISCHARGE    0\n",
       "949806               NaN        ORDERS    0\n",
       "\n",
       "[949807 rows x 3 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('./OUTPUT/dataset.csv', encoding= 'unicode_escape')\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Extract mappings required for the neural network\n",
    "To train a neural network, we will use two mappings as given below. The neural network will only take integers as input. So lets convert all the unique tokens in the corpus to its respective index.\n",
    "- {token} to {token id}: address the row in embeddings matrix for the current token.\n",
    "- {tag} to {tag id}: one-hot ground truth probability distribution vectors for computing the loss at the output of the network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import chain\n",
    "def get_dict_map(data, token_or_tag):\n",
    "    tok2idx = {}\n",
    "    idx2tok = {}\n",
    "    \n",
    "    if token_or_tag == 'token':\n",
    "        vocab = list(set(data['Word'].to_list()))\n",
    "    else:\n",
    "        vocab = list(set(data['Tag'].to_list()))\n",
    "    \n",
    "    idx2tok = {idx:tok for  idx, tok in enumerate(vocab)}\n",
    "    tok2idx = {tok:idx for  idx, tok in enumerate(vocab)}\n",
    "    return tok2idx, idx2tok\n",
    "\n",
    "\n",
    "token2idx, idx2token = get_dict_map(data, 'token')\n",
    "tag2idx, idx2tag = get_dict_map(data, 'tag')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Word_idx'] = data['Word'].map(token2idx)\n",
    "data['Tag_idx'] = data['Tag'].map(tag2idx) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence</th>\n",
       "      <th>Word</th>\n",
       "      <th>Tag</th>\n",
       "      <th>Word_idx</th>\n",
       "      <th>Tag_idx</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sentence: 1</td>\n",
       "      <td>RECORD</td>\n",
       "      <td>0</td>\n",
       "      <td>2520</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sentence: 2</td>\n",
       "      <td>OC</td>\n",
       "      <td>0</td>\n",
       "      <td>20753</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>AM</td>\n",
       "      <td>0</td>\n",
       "      <td>14691</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>gallstone</td>\n",
       "      <td>0</td>\n",
       "      <td>11989</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>pancreatitis</td>\n",
       "      <td>0</td>\n",
       "      <td>20468</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>949802</th>\n",
       "      <td>NaN</td>\n",
       "      <td>M.D.</td>\n",
       "      <td>0</td>\n",
       "      <td>3733</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>949803</th>\n",
       "      <td>Sentence: 132094</td>\n",
       "      <td>END</td>\n",
       "      <td>0</td>\n",
       "      <td>5528</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>949804</th>\n",
       "      <td>NaN</td>\n",
       "      <td>OF</td>\n",
       "      <td>0</td>\n",
       "      <td>30357</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>949805</th>\n",
       "      <td>NaN</td>\n",
       "      <td>DISCHARGE</td>\n",
       "      <td>0</td>\n",
       "      <td>10076</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>949806</th>\n",
       "      <td>NaN</td>\n",
       "      <td>ORDERS</td>\n",
       "      <td>0</td>\n",
       "      <td>27188</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>949807 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                Sentence          Word  Tag  Word_idx  Tag_idx\n",
       "0            Sentence: 1        RECORD    0      2520        0\n",
       "1            Sentence: 2            OC    0     20753        0\n",
       "2                    NaN            AM    0     14691        0\n",
       "3                    NaN     gallstone    0     11989        0\n",
       "4                    NaN  pancreatitis    0     20468        0\n",
       "...                  ...           ...  ...       ...      ...\n",
       "949802               NaN          M.D.    0      3733        0\n",
       "949803  Sentence: 132094           END    0      5528        0\n",
       "949804               NaN            OF    0     30357        0\n",
       "949805               NaN     DISCHARGE    0     10076        0\n",
       "949806               NaN        ORDERS    0     27188        0\n",
       "\n",
       "[949807 rows x 5 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv('./OUTPUT/view.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Transform columns to extract sequential data\n",
    "Next, lets fill NaN in 'sentence #' column using method ffill in fillna. Thereafter groupby on the sentence column to get a list of tokens and tags for each sentence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-6-2d54414e46a7>:2: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
      "  data_group = data_fillna.groupby(['Sentence'],as_index=False\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence</th>\n",
       "      <th>Word</th>\n",
       "      <th>Tag</th>\n",
       "      <th>Word_idx</th>\n",
       "      <th>Tag_idx</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sentence: 1</td>\n",
       "      <td>[RECORD]</td>\n",
       "      <td>[0]</td>\n",
       "      <td>[2520]</td>\n",
       "      <td>[0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sentence: 10</td>\n",
       "      <td>[WILL, D/C, ORDER, BE, USED, AS, THE, D/C, SUM...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>[34590, 22185, 31829, 34288, 10444, 4420, 2431...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Sentence: 100</td>\n",
       "      <td>[prandial, N/V/severe, upper, abdominal, pain....</td>\n",
       "      <td>[0, 1, 0, 1, 1, 0, 0, 0, 0]</td>\n",
       "      <td>[17608, 19836, 36207, 10525, 32989, 34606, 410...</td>\n",
       "      <td>[0, 1, 0, 1, 1, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Sentence: 1000</td>\n",
       "      <td>[normal, limits., Cardiac, catheterization, da...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>[24734, 33070, 39642, 37294, 11090, 36270, 287...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sentence: 10000</td>\n",
       "      <td>[year, old, Black, female, with, significant, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>[4329, 26776, 14658, 10830, 32477, 37827, 1520...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132089</th>\n",
       "      <td>Sentence: 99995</td>\n",
       "      <td>[Height, foot, inch, and, weight, kg., Tempera...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>[4383, 12344, 28242, 3997, 7545, 13603, 41574]</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132090</th>\n",
       "      <td>Sentence: 99996</td>\n",
       "      <td>[degrees, heart, rate, and, sinus, blood, pres...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>[2907, 34458, 7365, 3997, 39125, 23380, 15643,...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132091</th>\n",
       "      <td>Sentence: 99997</td>\n",
       "      <td>[blood, pressure, left, arm, and, oxygen, satu...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>[23380, 15643, 36959, 7753, 3997, 17438, 39659]</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132092</th>\n",
       "      <td>Sentence: 99998</td>\n",
       "      <td>[No, carotid, bruits, regular, rate, and, rhyt...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>[26610, 34683, 13010, 28794, 7365, 3997, 28800...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132093</th>\n",
       "      <td>Sentence: 99999</td>\n",
       "      <td>[systolic, murmur, along, the, right, upper, s...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>[41529, 17988, 27206, 3777, 38798, 36207, 3769...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>132094 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               Sentence                                               Word  \\\n",
       "0           Sentence: 1                                           [RECORD]   \n",
       "1          Sentence: 10  [WILL, D/C, ORDER, BE, USED, AS, THE, D/C, SUM...   \n",
       "2         Sentence: 100  [prandial, N/V/severe, upper, abdominal, pain....   \n",
       "3        Sentence: 1000  [normal, limits., Cardiac, catheterization, da...   \n",
       "4       Sentence: 10000  [year, old, Black, female, with, significant, ...   \n",
       "...                 ...                                                ...   \n",
       "132089  Sentence: 99995  [Height, foot, inch, and, weight, kg., Tempera...   \n",
       "132090  Sentence: 99996  [degrees, heart, rate, and, sinus, blood, pres...   \n",
       "132091  Sentence: 99997  [blood, pressure, left, arm, and, oxygen, satu...   \n",
       "132092  Sentence: 99998  [No, carotid, bruits, regular, rate, and, rhyt...   \n",
       "132093  Sentence: 99999  [systolic, murmur, along, the, right, upper, s...   \n",
       "\n",
       "                                   Tag  \\\n",
       "0                                  [0]   \n",
       "1       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]   \n",
       "2          [0, 1, 0, 1, 1, 0, 0, 0, 0]   \n",
       "3             [0, 0, 0, 0, 0, 0, 0, 0]   \n",
       "4       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]   \n",
       "...                                ...   \n",
       "132089           [0, 0, 0, 0, 0, 0, 0]   \n",
       "132090     [0, 0, 0, 0, 0, 0, 0, 0, 0]   \n",
       "132091           [0, 0, 0, 0, 0, 0, 0]   \n",
       "132092     [0, 0, 0, 0, 0, 0, 0, 0, 0]   \n",
       "132093     [0, 0, 0, 0, 0, 0, 0, 0, 0]   \n",
       "\n",
       "                                                 Word_idx  \\\n",
       "0                                                  [2520]   \n",
       "1       [34590, 22185, 31829, 34288, 10444, 4420, 2431...   \n",
       "2       [17608, 19836, 36207, 10525, 32989, 34606, 410...   \n",
       "3       [24734, 33070, 39642, 37294, 11090, 36270, 287...   \n",
       "4       [4329, 26776, 14658, 10830, 32477, 37827, 1520...   \n",
       "...                                                   ...   \n",
       "132089     [4383, 12344, 28242, 3997, 7545, 13603, 41574]   \n",
       "132090  [2907, 34458, 7365, 3997, 39125, 23380, 15643,...   \n",
       "132091    [23380, 15643, 36959, 7753, 3997, 17438, 39659]   \n",
       "132092  [26610, 34683, 13010, 28794, 7365, 3997, 28800...   \n",
       "132093  [41529, 17988, 27206, 3777, 38798, 36207, 3769...   \n",
       "\n",
       "                               Tag_idx  \n",
       "0                                  [0]  \n",
       "1       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]  \n",
       "2          [0, 1, 0, 1, 1, 0, 0, 0, 0]  \n",
       "3             [0, 0, 0, 0, 0, 0, 0, 0]  \n",
       "4       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]  \n",
       "...                                ...  \n",
       "132089           [0, 0, 0, 0, 0, 0, 0]  \n",
       "132090     [0, 0, 0, 0, 0, 0, 0, 0, 0]  \n",
       "132091           [0, 0, 0, 0, 0, 0, 0]  \n",
       "132092     [0, 0, 0, 0, 0, 0, 0, 0, 0]  \n",
       "132093     [0, 0, 0, 0, 0, 0, 0, 0, 0]  \n",
       "\n",
       "[132094 rows x 5 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_fillna = data.fillna(method='ffill', axis=0)\n",
    "data_group = data_fillna.groupby(['Sentence'],as_index=False\n",
    "                                )['Word', 'Tag', 'Word_idx', 'Tag_idx'].agg(lambda x: list(x))\n",
    "\n",
    "#data_fillna\n",
    "data_group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_group.to_csv('./OUTPUT/datagroup.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Pad sequences and split the dataset into train, test\n",
    "Padding: The LSTM layers accept sequences of same length only. Therefore we will want to transform our list of token_sequences ('Word_idx') which is lists of integers into a matrix of shape (token_sequences, max_len). We can use any length as max_len. In this project we will be using length of the longest sequence as max_len. The sequences that are shorter than max_len are padded with a specified value at the end.\n",
    "Import required packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_padTokens_padTags(data_group, data):\n",
    "    n_token = len(list(set(data['Word'].to_list())))\n",
    "    n_tag = len(list(set(data['Tag'].to_list())))\n",
    "    tokens = data_group['Word_idx'].tolist()\n",
    "    maxlen = max([len(s) for s in tokens])\n",
    "    pad_tokens = pad_sequences(tokens, maxlen=maxlen, dtype='int32', padding='post', value= 0)\n",
    "    tags = data_group['Tag_idx'].tolist()\n",
    "    pad_tags = pad_sequences(tags, maxlen=maxlen, dtype='int32', padding='post', value= 0)\n",
    "\n",
    "    return pad_tokens, pad_tags\n",
    "\n",
    "pad_tokens, pad_tags = get_padTokens_padTags(data_group, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of tokens 132094\n",
      "length of tags 132094\n"
     ]
    }
   ],
   "source": [
    "print('length of tokens ' + str(len(pad_tokens)))\n",
    "print('length of tags ' + str(len(pad_tags)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## StratifiedKFold Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import Sequential, Model, Input\n",
    "from tensorflow.keras.layers import LSTM, Embedding, Dense, TimeDistributed, Dropout, Bidirectional\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from keras import backend as K\n",
    "import keras as keras\n",
    "from keras.datasets import mnist\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from keras import metrics\n",
    "from sklearn.utils import class_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy.random import seed\n",
    "seed(1)\n",
    "tf.random.set_seed(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_dim:  42057 \n",
      "output_dim:  32 \n",
      "input_length:  49 \n",
      "n_tags:  2\n"
     ]
    }
   ],
   "source": [
    "input_dim = len(list(set(data['Word'].to_list())))+1\n",
    "output_dim = 32\n",
    "input_length = max([len(s) for s in data_group['Word_idx'].tolist()])\n",
    "n_tags = len(tag2idx)\n",
    "print('input_dim: ', input_dim, '\\noutput_dim: ', output_dim, '\\ninput_length: ', input_length, '\\nn_tags: ', n_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recall_m(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    recall = true_positives / (possible_positives + K.epsilon())\n",
    "    return recall\n",
    "\n",
    "def precision_m(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\n",
    "    return precision\n",
    "\n",
    "def f1_m(y_true, y_pred):\n",
    "    precision = precision_m(y_true, y_pred)\n",
    "    recall = recall_m(y_true, y_pred)\n",
    "    return 2*((precision*recall)/(precision+recall+K.epsilon()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bilstm_lstm_model():\n",
    "    model = Sequential()\n",
    "\n",
    "    # Add Embedding layer\n",
    "    model.add(Embedding(input_dim=input_dim, output_dim=output_dim, input_length=input_length))\n",
    "\n",
    "    # Add bidirectional LSTM\n",
    "    model.add(Bidirectional(LSTM(units=output_dim, return_sequences=True, dropout=0.2, recurrent_dropout=0.2), merge_mode = 'concat'))\n",
    "\n",
    "    \n",
    "    # Add LSTM\n",
    "    model.add(LSTM(units=output_dim, return_sequences=True, dropout=0.5, recurrent_dropout=0.5))\n",
    "\n",
    "    # Add timeDistributed Layer\n",
    "    model.add(TimeDistributed(Dense(1, activation=\"sigmoid\")))\n",
    "    \n",
    "    #Optimiser \n",
    "    adam = tf.keras.optimizers.Adam(learning_rate=0.0005, beta_1=0.9, beta_2=0.999)\n",
    "    \n",
    "    # Compile model\n",
    "    model.compile(loss='binary_crossentropy', sample_weight_mode=\"temporal\", optimizer='adam', metrics=['acc', precision_m, recall_m, f1_m])\n",
    "    model.summary()\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jonat\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:666: UserWarning: The least populated class in y has only 3 members, which is less than n_splits=5.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on fold 1/5..........\n",
      "1: started oversampling\n",
      "1: finished assigning sample weights\n",
      "1: started oversampling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jonat\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:70: FutureWarning: Pass classes=[0 1], y=[0 1 1 ... 0 0 0] as keyword args. From version 1.0 (renaming of 0.25) passing these as positional arguments will result in an error\n",
      "  warnings.warn(f\"Pass {args_msg} as keyword args. From version \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1: finished assigning sample weights\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 49, 32)            1345824   \n",
      "                                                                 \n",
      " bidirectional (Bidirectiona  (None, 49, 64)           16640     \n",
      " l)                                                              \n",
      "                                                                 \n",
      " lstm_1 (LSTM)               (None, 49, 32)            12416     \n",
      "                                                                 \n",
      " time_distributed (TimeDistr  (None, 49, 1)            33        \n",
      " ibuted)                                                         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,374,913\n",
      "Trainable params: 1,374,913\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "562/562 [==============================] - 288s 494ms/step - loss: 0.0654 - acc: 0.9814 - precision_m: 0.5973 - recall_m: 0.4455 - f1_m: 0.4788\n",
      "Epoch 2/20\n",
      "562/562 [==============================] - 299s 532ms/step - loss: 0.0170 - acc: 0.9941 - precision_m: 0.9001 - recall_m: 0.8928 - f1_m: 0.8963\n",
      "Epoch 3/20\n",
      "562/562 [==============================] - 302s 538ms/step - loss: 0.0115 - acc: 0.9962 - precision_m: 0.9271 - recall_m: 0.9386 - f1_m: 0.9327\n",
      "Epoch 4/20\n",
      "562/562 [==============================] - 305s 542ms/step - loss: 0.0091 - acc: 0.9970 - precision_m: 0.9404 - recall_m: 0.9552 - f1_m: 0.9477\n",
      "Epoch 5/20\n",
      "562/562 [==============================] - 307s 546ms/step - loss: 0.0077 - acc: 0.9975 - precision_m: 0.9491 - recall_m: 0.9648 - f1_m: 0.9568\n",
      "Epoch 6/20\n",
      "562/562 [==============================] - 300s 534ms/step - loss: 0.0067 - acc: 0.9979 - precision_m: 0.9556 - recall_m: 0.9709 - f1_m: 0.9631\n",
      "Epoch 7/20\n",
      "562/562 [==============================] - 304s 540ms/step - loss: 0.0059 - acc: 0.9982 - precision_m: 0.9609 - recall_m: 0.9752 - f1_m: 0.9680\n",
      "Epoch 8/20\n",
      "562/562 [==============================] - 304s 541ms/step - loss: 0.0052 - acc: 0.9984 - precision_m: 0.9650 - recall_m: 0.9782 - f1_m: 0.9716\n",
      "Epoch 9/20\n",
      "562/562 [==============================] - 315s 561ms/step - loss: 0.0047 - acc: 0.9985 - precision_m: 0.9684 - recall_m: 0.9808 - f1_m: 0.9745\n",
      "Epoch 10/20\n",
      "562/562 [==============================] - 305s 542ms/step - loss: 0.0043 - acc: 0.9987 - precision_m: 0.9710 - recall_m: 0.9828 - f1_m: 0.9768\n",
      "Epoch 11/20\n",
      "562/562 [==============================] - 305s 542ms/step - loss: 0.0038 - acc: 0.9988 - precision_m: 0.9736 - recall_m: 0.9843 - f1_m: 0.9789\n",
      "Epoch 12/20\n",
      "562/562 [==============================] - 305s 543ms/step - loss: 0.0035 - acc: 0.9989 - precision_m: 0.9754 - recall_m: 0.9856 - f1_m: 0.9805\n",
      "Epoch 13/20\n",
      "562/562 [==============================] - 307s 546ms/step - loss: 0.0031 - acc: 0.9990 - precision_m: 0.9777 - recall_m: 0.9868 - f1_m: 0.9822\n",
      "Epoch 14/20\n",
      "562/562 [==============================] - 313s 557ms/step - loss: 0.0029 - acc: 0.9990 - precision_m: 0.9791 - recall_m: 0.9877 - f1_m: 0.9834\n",
      "Epoch 15/20\n",
      "562/562 [==============================] - 354s 631ms/step - loss: 0.0026 - acc: 0.9991 - precision_m: 0.9811 - recall_m: 0.9886 - f1_m: 0.9848\n",
      "Epoch 16/20\n",
      "562/562 [==============================] - 288s 512ms/step - loss: 0.0025 - acc: 0.9992 - precision_m: 0.9823 - recall_m: 0.9892 - f1_m: 0.9857\n",
      "Epoch 17/20\n",
      "562/562 [==============================] - 282s 502ms/step - loss: 0.0023 - acc: 0.9992 - precision_m: 0.9836 - recall_m: 0.9900 - f1_m: 0.9868\n",
      "Epoch 18/20\n",
      "562/562 [==============================] - 335s 596ms/step - loss: 0.0022 - acc: 0.9993 - precision_m: 0.9845 - recall_m: 0.9903 - f1_m: 0.9874\n",
      "Epoch 19/20\n",
      "562/562 [==============================] - 401s 713ms/step - loss: 0.0020 - acc: 0.9993 - precision_m: 0.9855 - recall_m: 0.9909 - f1_m: 0.9882\n",
      "Epoch 20/20\n",
      "562/562 [==============================] - 418s 744ms/step - loss: 0.0020 - acc: 0.9994 - precision_m: 0.9863 - recall_m: 0.9913 - f1_m: 0.9888\n",
      "Score for fold 1: loss of 0.015652945265173912; acc of 0.9975422620773315; precision_m of 0.5660622715950012; recall_m of 0.6528862714767456; f1_m of 0.5739668011665344 %\n",
      "Training on fold 2/5..........\n",
      "2: started oversampling\n",
      "2: finished assigning sample weights\n",
      "2: started oversampling\n",
      "2: finished assigning sample weights\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_1 (Embedding)     (None, 49, 32)            1345824   \n",
      "                                                                 \n",
      " bidirectional_1 (Bidirectio  (None, 49, 64)           16640     \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " lstm_3 (LSTM)               (None, 49, 32)            12416     \n",
      "                                                                 \n",
      " time_distributed_1 (TimeDis  (None, 49, 1)            33        \n",
      " tributed)                                                       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,374,913\n",
      "Trainable params: 1,374,913\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "562/562 [==============================] - 411s 688ms/step - loss: 0.0653 - acc: 0.9813 - precision_m: 0.5697 - recall_m: 0.4338 - f1_m: 0.4657\n",
      "Epoch 2/20\n",
      "562/562 [==============================] - 419s 745ms/step - loss: 0.0160 - acc: 0.9944 - precision_m: 0.9038 - recall_m: 0.9004 - f1_m: 0.9020\n",
      "Epoch 3/20\n",
      "562/562 [==============================] - 434s 772ms/step - loss: 0.0109 - acc: 0.9963 - precision_m: 0.9295 - recall_m: 0.9422 - f1_m: 0.9357\n",
      "Epoch 4/20\n",
      "562/562 [==============================] - 331s 589ms/step - loss: 0.0086 - acc: 0.9972 - precision_m: 0.9428 - recall_m: 0.9583 - f1_m: 0.9504\n",
      "Epoch 5/20\n",
      "562/562 [==============================] - 335s 597ms/step - loss: 0.0073 - acc: 0.9976 - precision_m: 0.9509 - recall_m: 0.9661 - f1_m: 0.9584\n",
      "Epoch 6/20\n",
      "562/562 [==============================] - 330s 586ms/step - loss: 0.0063 - acc: 0.9980 - precision_m: 0.9575 - recall_m: 0.9717 - f1_m: 0.9645\n",
      "Epoch 7/20\n",
      "562/562 [==============================] - 333s 592ms/step - loss: 0.0055 - acc: 0.9982 - precision_m: 0.9624 - recall_m: 0.9762 - f1_m: 0.9692\n",
      "Epoch 8/20\n",
      "562/562 [==============================] - 335s 596ms/step - loss: 0.0049 - acc: 0.9984 - precision_m: 0.9663 - recall_m: 0.9789 - f1_m: 0.9726\n",
      "Epoch 9/20\n",
      "562/562 [==============================] - 335s 595ms/step - loss: 0.0043 - acc: 0.9986 - precision_m: 0.9700 - recall_m: 0.9813 - f1_m: 0.9756\n",
      "Epoch 10/20\n",
      "562/562 [==============================] - 270s 480ms/step - loss: 0.0039 - acc: 0.9987 - precision_m: 0.9729 - recall_m: 0.9829 - f1_m: 0.9778\n",
      "Epoch 11/20\n",
      "562/562 [==============================] - 275s 489ms/step - loss: 0.0036 - acc: 0.9988 - precision_m: 0.9752 - recall_m: 0.9847 - f1_m: 0.9799\n",
      "Epoch 12/20\n",
      "562/562 [==============================] - 339s 603ms/step - loss: 0.0032 - acc: 0.9990 - precision_m: 0.9773 - recall_m: 0.9863 - f1_m: 0.9818\n",
      "Epoch 13/20\n",
      "562/562 [==============================] - 338s 602ms/step - loss: 0.0030 - acc: 0.9990 - precision_m: 0.9787 - recall_m: 0.9869 - f1_m: 0.9828\n",
      "Epoch 14/20\n",
      "562/562 [==============================] - 338s 602ms/step - loss: 0.0028 - acc: 0.9991 - precision_m: 0.9805 - recall_m: 0.9882 - f1_m: 0.9843\n",
      "Epoch 15/20\n",
      "562/562 [==============================] - 339s 604ms/step - loss: 0.0026 - acc: 0.9992 - precision_m: 0.9817 - recall_m: 0.9886 - f1_m: 0.9851\n",
      "Epoch 16/20\n",
      "562/562 [==============================] - 340s 605ms/step - loss: 0.0024 - acc: 0.9992 - precision_m: 0.9830 - recall_m: 0.9894 - f1_m: 0.9862\n",
      "Epoch 17/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "562/562 [==============================] - 340s 605ms/step - loss: 0.0022 - acc: 0.9993 - precision_m: 0.9841 - recall_m: 0.9901 - f1_m: 0.9871\n",
      "Epoch 18/20\n",
      "562/562 [==============================] - 340s 604ms/step - loss: 0.0021 - acc: 0.9993 - precision_m: 0.9849 - recall_m: 0.9906 - f1_m: 0.9877\n",
      "Epoch 19/20\n",
      "562/562 [==============================] - 340s 604ms/step - loss: 0.0020 - acc: 0.9993 - precision_m: 0.9859 - recall_m: 0.9913 - f1_m: 0.9886\n",
      "Epoch 20/20\n",
      "562/562 [==============================] - 339s 604ms/step - loss: 0.0019 - acc: 0.9994 - precision_m: 0.9867 - recall_m: 0.9916 - f1_m: 0.9891\n",
      "Score for fold 2: loss of 0.0160928163677454; acc of 0.9975723028182983; precision_m of 0.5760685801506042; recall_m of 0.6384505033493042; f1_m of 0.5769012570381165 %\n",
      "Training on fold 3/5..........\n",
      "3: started oversampling\n",
      "3: finished assigning sample weights\n",
      "3: started oversampling\n",
      "3: finished assigning sample weights\n",
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_2 (Embedding)     (None, 49, 32)            1345824   \n",
      "                                                                 \n",
      " bidirectional_2 (Bidirectio  (None, 49, 64)           16640     \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " lstm_5 (LSTM)               (None, 49, 32)            12416     \n",
      "                                                                 \n",
      " time_distributed_2 (TimeDis  (None, 49, 1)            33        \n",
      " tributed)                                                       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,374,913\n",
      "Trainable params: 1,374,913\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "562/562 [==============================] - 278s 478ms/step - loss: 0.0596 - acc: 0.9825 - precision_m: 0.6407 - recall_m: 0.4904 - f1_m: 0.5243\n",
      "Epoch 2/20\n",
      "562/562 [==============================] - 317s 564ms/step - loss: 0.0152 - acc: 0.9948 - precision_m: 0.9082 - recall_m: 0.9080 - f1_m: 0.9080\n",
      "Epoch 3/20\n",
      "562/562 [==============================] - 260s 463ms/step - loss: 0.0104 - acc: 0.9965 - precision_m: 0.9338 - recall_m: 0.9456 - f1_m: 0.9396\n",
      "Epoch 4/20\n",
      "562/562 [==============================] - 255s 454ms/step - loss: 0.0083 - acc: 0.9973 - precision_m: 0.9461 - recall_m: 0.9600 - f1_m: 0.9529\n",
      "Epoch 5/20\n",
      "562/562 [==============================] - 330s 587ms/step - loss: 0.0071 - acc: 0.9977 - precision_m: 0.9535 - recall_m: 0.9677 - f1_m: 0.9605\n",
      "Epoch 6/20\n",
      "562/562 [==============================] - 332s 591ms/step - loss: 0.0062 - acc: 0.9981 - precision_m: 0.9591 - recall_m: 0.9732 - f1_m: 0.9660\n",
      "Epoch 7/20\n",
      "562/562 [==============================] - 331s 589ms/step - loss: 0.0054 - acc: 0.9983 - precision_m: 0.9638 - recall_m: 0.9774 - f1_m: 0.9706\n",
      "Epoch 8/20\n",
      "562/562 [==============================] - 332s 591ms/step - loss: 0.0049 - acc: 0.9985 - precision_m: 0.9675 - recall_m: 0.9802 - f1_m: 0.9738\n",
      "Epoch 9/20\n",
      "562/562 [==============================] - 332s 591ms/step - loss: 0.0044 - acc: 0.9987 - precision_m: 0.9705 - recall_m: 0.9826 - f1_m: 0.9765\n",
      "Epoch 10/20\n",
      "562/562 [==============================] - 331s 589ms/step - loss: 0.0039 - acc: 0.9988 - precision_m: 0.9729 - recall_m: 0.9842 - f1_m: 0.9785\n",
      "Epoch 11/20\n",
      "562/562 [==============================] - 330s 587ms/step - loss: 0.0036 - acc: 0.9989 - precision_m: 0.9751 - recall_m: 0.9855 - f1_m: 0.9803\n",
      "Epoch 12/20\n",
      "562/562 [==============================] - 330s 588ms/step - loss: 0.0032 - acc: 0.9990 - precision_m: 0.9774 - recall_m: 0.9869 - f1_m: 0.9821\n",
      "Epoch 13/20\n",
      "562/562 [==============================] - 330s 587ms/step - loss: 0.0029 - acc: 0.9991 - precision_m: 0.9792 - recall_m: 0.9876 - f1_m: 0.9834\n",
      "Epoch 14/20\n",
      "562/562 [==============================] - 332s 590ms/step - loss: 0.0027 - acc: 0.9991 - precision_m: 0.9806 - recall_m: 0.9887 - f1_m: 0.9846\n",
      "Epoch 15/20\n",
      "562/562 [==============================] - 330s 587ms/step - loss: 0.0025 - acc: 0.9992 - precision_m: 0.9823 - recall_m: 0.9893 - f1_m: 0.9857\n",
      "Epoch 16/20\n",
      "562/562 [==============================] - 330s 588ms/step - loss: 0.0023 - acc: 0.9992 - precision_m: 0.9833 - recall_m: 0.9899 - f1_m: 0.9866\n",
      "Epoch 17/20\n",
      "562/562 [==============================] - 326s 580ms/step - loss: 0.0021 - acc: 0.9993 - precision_m: 0.9847 - recall_m: 0.9907 - f1_m: 0.9877\n",
      "Epoch 18/20\n",
      "562/562 [==============================] - 258s 459ms/step - loss: 0.0020 - acc: 0.9993 - precision_m: 0.9855 - recall_m: 0.9912 - f1_m: 0.9883\n",
      "Epoch 19/20\n",
      "562/562 [==============================] - 266s 474ms/step - loss: 0.0019 - acc: 0.9994 - precision_m: 0.9863 - recall_m: 0.9917 - f1_m: 0.9890\n",
      "Epoch 20/20\n",
      "562/562 [==============================] - 325s 579ms/step - loss: 0.0018 - acc: 0.9994 - precision_m: 0.9870 - recall_m: 0.9920 - f1_m: 0.9895\n",
      "Score for fold 3: loss of 0.015897518023848534; acc of 0.997536838054657; precision_m of 0.5419842600822449; recall_m of 0.6222488880157471; f1_m of 0.5513389110565186 %\n",
      "Training on fold 4/5..........\n",
      "4: started oversampling\n",
      "4: finished assigning sample weights\n",
      "4: started oversampling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jonat\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:70: FutureWarning: Pass classes=[0 1], y=[0 0 0 ... 0 0 0] as keyword args. From version 1.0 (renaming of 0.25) passing these as positional arguments will result in an error\n",
      "  warnings.warn(f\"Pass {args_msg} as keyword args. From version \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4: finished assigning sample weights\n",
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_3 (Embedding)     (None, 49, 32)            1345824   \n",
      "                                                                 \n",
      " bidirectional_3 (Bidirectio  (None, 49, 64)           16640     \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " lstm_7 (LSTM)               (None, 49, 32)            12416     \n",
      "                                                                 \n",
      " time_distributed_3 (TimeDis  (None, 49, 1)            33        \n",
      " tributed)                                                       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,374,913\n",
      "Trainable params: 1,374,913\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "562/562 [==============================] - 314s 543ms/step - loss: 0.0618 - acc: 0.9828 - precision_m: 0.6302 - recall_m: 0.4725 - f1_m: 0.5071\n",
      "Epoch 2/20\n",
      "562/562 [==============================] - 341s 607ms/step - loss: 0.0169 - acc: 0.9941 - precision_m: 0.8998 - recall_m: 0.8937 - f1_m: 0.8966\n",
      "Epoch 3/20\n",
      "562/562 [==============================] - 347s 617ms/step - loss: 0.0115 - acc: 0.9961 - precision_m: 0.9268 - recall_m: 0.9379 - f1_m: 0.9322\n",
      "Epoch 4/20\n",
      "562/562 [==============================] - 351s 624ms/step - loss: 0.0088 - acc: 0.9971 - precision_m: 0.9419 - recall_m: 0.9562 - f1_m: 0.9489\n",
      "Epoch 5/20\n",
      "562/562 [==============================] - 351s 624ms/step - loss: 0.0074 - acc: 0.9976 - precision_m: 0.9509 - recall_m: 0.9658 - f1_m: 0.9582\n",
      "Epoch 6/20\n",
      "562/562 [==============================] - 357s 635ms/step - loss: 0.0064 - acc: 0.9980 - precision_m: 0.9573 - recall_m: 0.9716 - f1_m: 0.9644\n",
      "Epoch 7/20\n",
      "562/562 [==============================] - 405s 720ms/step - loss: 0.0056 - acc: 0.9982 - precision_m: 0.9624 - recall_m: 0.9753 - f1_m: 0.9688\n",
      "Epoch 8/20\n",
      "562/562 [==============================] - 395s 702ms/step - loss: 0.0050 - acc: 0.9984 - precision_m: 0.9660 - recall_m: 0.9784 - f1_m: 0.9721\n",
      "Epoch 9/20\n",
      "562/562 [==============================] - 482s 857ms/step - loss: 0.0045 - acc: 0.9986 - precision_m: 0.9692 - recall_m: 0.9807 - f1_m: 0.9749\n",
      "Epoch 10/20\n",
      "562/562 [==============================] - 490s 871ms/step - loss: 0.0041 - acc: 0.9987 - precision_m: 0.9723 - recall_m: 0.9825 - f1_m: 0.9774\n",
      "Epoch 11/20\n",
      "562/562 [==============================] - 375s 666ms/step - loss: 0.0037 - acc: 0.9988 - precision_m: 0.9747 - recall_m: 0.9841 - f1_m: 0.9794\n",
      "Epoch 12/20\n",
      "562/562 [==============================] - 327s 582ms/step - loss: 0.0034 - acc: 0.9989 - precision_m: 0.9761 - recall_m: 0.9852 - f1_m: 0.9806\n",
      "Epoch 13/20\n",
      "562/562 [==============================] - 317s 564ms/step - loss: 0.0031 - acc: 0.9990 - precision_m: 0.9780 - recall_m: 0.9866 - f1_m: 0.9823\n",
      "Epoch 14/20\n",
      "562/562 [==============================] - 339s 604ms/step - loss: 0.0029 - acc: 0.9991 - precision_m: 0.9795 - recall_m: 0.9874 - f1_m: 0.9834\n",
      "Epoch 15/20\n",
      "562/562 [==============================] - 339s 602ms/step - loss: 0.0027 - acc: 0.9991 - precision_m: 0.9808 - recall_m: 0.9883 - f1_m: 0.9845\n",
      "Epoch 16/20\n",
      "562/562 [==============================] - 345s 613ms/step - loss: 0.0025 - acc: 0.9992 - precision_m: 0.9824 - recall_m: 0.9889 - f1_m: 0.9856\n",
      "Epoch 17/20\n",
      "562/562 [==============================] - 344s 612ms/step - loss: 0.0023 - acc: 0.9992 - precision_m: 0.9834 - recall_m: 0.9898 - f1_m: 0.9866\n",
      "Epoch 18/20\n",
      "562/562 [==============================] - 341s 606ms/step - loss: 0.0022 - acc: 0.9993 - precision_m: 0.9843 - recall_m: 0.9902 - f1_m: 0.9872\n",
      "Epoch 19/20\n",
      "562/562 [==============================] - 342s 609ms/step - loss: 0.0020 - acc: 0.9993 - precision_m: 0.9854 - recall_m: 0.9909 - f1_m: 0.9881\n",
      "Epoch 20/20\n",
      "562/562 [==============================] - 342s 608ms/step - loss: 0.0019 - acc: 0.9994 - precision_m: 0.9862 - recall_m: 0.9916 - f1_m: 0.9889\n",
      "Score for fold 4: loss of 0.01571137271821499; acc of 0.9976025819778442; precision_m of 0.5791258811950684; recall_m of 0.6506590843200684; f1_m of 0.5838152170181274 %\n",
      "Training on fold 5/5..........\n",
      "5: started oversampling\n",
      "5: finished assigning sample weights\n",
      "5: started oversampling\n",
      "5: finished assigning sample weights\n",
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_4 (Embedding)     (None, 49, 32)            1345824   \n",
      "                                                                 \n",
      " bidirectional_4 (Bidirectio  (None, 49, 64)           16640     \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " lstm_9 (LSTM)               (None, 49, 32)            12416     \n",
      "                                                                 \n",
      " time_distributed_4 (TimeDis  (None, 49, 1)            33        \n",
      " tributed)                                                       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,374,913\n",
      "Trainable params: 1,374,913\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "562/562 [==============================] - 414s 724ms/step - loss: 0.0685 - acc: 0.9798 - precision_m: 0.5342 - recall_m: 0.3955 - f1_m: 0.4270\n",
      "Epoch 2/20\n",
      "562/562 [==============================] - 424s 755ms/step - loss: 0.0173 - acc: 0.9940 - precision_m: 0.8949 - recall_m: 0.8930 - f1_m: 0.8938\n",
      "Epoch 3/20\n",
      "562/562 [==============================] - 426s 758ms/step - loss: 0.0132 - acc: 0.9955 - precision_m: 0.9163 - recall_m: 0.9259 - f1_m: 0.9210\n",
      "Epoch 4/20\n",
      "562/562 [==============================] - 412s 732ms/step - loss: 0.0100 - acc: 0.9967 - precision_m: 0.9343 - recall_m: 0.9495 - f1_m: 0.9417\n",
      "Epoch 5/20\n",
      "562/562 [==============================] - 429s 764ms/step - loss: 0.0080 - acc: 0.9974 - precision_m: 0.9459 - recall_m: 0.9627 - f1_m: 0.9541\n",
      "Epoch 6/20\n",
      "562/562 [==============================] - 423s 753ms/step - loss: 0.0067 - acc: 0.9978 - precision_m: 0.9542 - recall_m: 0.9699 - f1_m: 0.9620\n",
      "Epoch 7/20\n",
      "562/562 [==============================] - 404s 718ms/step - loss: 0.0058 - acc: 0.9981 - precision_m: 0.9601 - recall_m: 0.9745 - f1_m: 0.9672\n",
      "Epoch 8/20\n",
      "562/562 [==============================] - 406s 723ms/step - loss: 0.0051 - acc: 0.9984 - precision_m: 0.9648 - recall_m: 0.9782 - f1_m: 0.9714\n",
      "Epoch 9/20\n",
      "562/562 [==============================] - 423s 752ms/step - loss: 0.0044 - acc: 0.9985 - precision_m: 0.9689 - recall_m: 0.9804 - f1_m: 0.9746\n",
      "Epoch 10/20\n",
      "562/562 [==============================] - 422s 752ms/step - loss: 0.0039 - acc: 0.9987 - precision_m: 0.9725 - recall_m: 0.9827 - f1_m: 0.9775\n",
      "Epoch 11/20\n",
      "562/562 [==============================] - 428s 762ms/step - loss: 0.0036 - acc: 0.9988 - precision_m: 0.9745 - recall_m: 0.9841 - f1_m: 0.9793\n",
      "Epoch 12/20\n",
      "562/562 [==============================] - 420s 748ms/step - loss: 0.0032 - acc: 0.9989 - precision_m: 0.9768 - recall_m: 0.9859 - f1_m: 0.9813\n",
      "Epoch 13/20\n",
      "562/562 [==============================] - 425s 755ms/step - loss: 0.0030 - acc: 0.9990 - precision_m: 0.9786 - recall_m: 0.9866 - f1_m: 0.9826\n",
      "Epoch 14/20\n",
      "562/562 [==============================] - 424s 755ms/step - loss: 0.0028 - acc: 0.9991 - precision_m: 0.9801 - recall_m: 0.9875 - f1_m: 0.9838\n",
      "Epoch 15/20\n",
      "562/562 [==============================] - 424s 755ms/step - loss: 0.0026 - acc: 0.9991 - precision_m: 0.9816 - recall_m: 0.9886 - f1_m: 0.9851\n",
      "Epoch 16/20\n",
      "562/562 [==============================] - 432s 769ms/step - loss: 0.0024 - acc: 0.9992 - precision_m: 0.9829 - recall_m: 0.9895 - f1_m: 0.9862\n",
      "Epoch 17/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "562/562 [==============================] - 404s 719ms/step - loss: 0.0022 - acc: 0.9993 - precision_m: 0.9840 - recall_m: 0.9901 - f1_m: 0.9870\n",
      "Epoch 18/20\n",
      "562/562 [==============================] - 452s 804ms/step - loss: 0.0021 - acc: 0.9993 - precision_m: 0.9844 - recall_m: 0.9905 - f1_m: 0.9875\n",
      "Epoch 19/20\n",
      "562/562 [==============================] - 449s 799ms/step - loss: 0.0020 - acc: 0.9993 - precision_m: 0.9859 - recall_m: 0.9910 - f1_m: 0.9884\n",
      "Epoch 20/20\n",
      "562/562 [==============================] - 451s 803ms/step - loss: 0.0019 - acc: 0.9994 - precision_m: 0.9863 - recall_m: 0.9914 - f1_m: 0.9888\n",
      "Score for fold 5: loss of 0.016536895185709; acc of 0.9975120425224304; precision_m of 0.5547494888305664; recall_m of 0.6376579999923706; f1_m of 0.566363513469696 %\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "skf = StratifiedKFold(n_splits = 5, shuffle = True)\n",
    "\n",
    "fold_number = 1\n",
    "f1_per_fold = []\n",
    "recall_per_fold = []\n",
    "precision_per_fold = []\n",
    "acc_per_fold = []\n",
    "loss_per_fold = []\n",
    "\n",
    "for i, (train_index, val_index) in enumerate(skf.split(pad_tokens, np.sum(pad_tags, axis = 1))):\n",
    "    \n",
    "    print(\"Training on fold \" + str(i+1) + \"/5..........\")\n",
    "    \n",
    "    #Split training set and validation set\n",
    "    x_train, x_val = pad_tokens[train_index], pad_tokens[val_index]\n",
    "    y_train, y_val = pad_tags[train_index], pad_tags[val_index]\n",
    "    \n",
    "    #Oversample minority class in training set\n",
    "    print(str(fold_number) + \": started oversampling\")\n",
    "    index = 0\n",
    "    for token, tag in zip(x_train, y_train):\n",
    "        if np.sum(tag) >= 1:\n",
    "            token_arr = np.tile(token, 20).reshape((-1, len(token)))\n",
    "            tag_arr = np.tile(tag, 20).reshape((-1, len(tag)))\n",
    "            x_train = np.append(token_arr, x_train, axis=0)\n",
    "            y_train = np.append(tag_arr, y_train, axis=0)\n",
    "        index = index + 1\n",
    "    print(str(fold_number) + \": finished assigning sample weights\")\n",
    "    \n",
    "    #Assigning sample weights in training set\n",
    "    print(str(fold_number) + \": started oversampling\")\n",
    "    weights = class_weight.compute_class_weight('balanced',\n",
    "                                                 np.unique(np.ravel(y_train,order='C')),\n",
    "                                                 np.ravel(y_train,order='C'))\n",
    "    \n",
    "    train_tags2 = np.copy(y_train)\n",
    "    train_tokens2 = np.copy(x_train)\n",
    "    train_tags2 = train_tags2.astype(float)\n",
    "    \n",
    "    indexTotal = 0\n",
    "    for tags in train_tags2:\n",
    "        indexTags = 0\n",
    "        for symptom in tags:\n",
    "            if symptom == 1:\n",
    "                train_tags2[indexTotal][indexTags] = float(weights[1])\n",
    "            else:\n",
    "                train_tags2[indexTotal][indexTags] = float(weights[0])\n",
    "            indexTags = indexTags+1\n",
    "        indexTotal = indexTotal + 1\n",
    "   \n",
    "    weights = train_tags2.reshape((-1, 49, 1))\n",
    "    print(str(fold_number) + \": finished assigning sample weights\")\n",
    "    \n",
    "    #Getting Model Architecture\n",
    "    model = get_bilstm_lstm_model()\n",
    "    \n",
    "    #Running Model\n",
    "    history = model.fit(x_train, y_train, sample_weight = weights, batch_size=512, verbose=1, epochs=20)\n",
    "    \n",
    "    #Evaluate model\n",
    "    scores = model.evaluate(x_val, y_val, verbose = 0)\n",
    "    print(f'Score for fold {fold_number}: {model.metrics_names[0]} of {scores[0]}; {model.metrics_names[1]} of {scores[1]}; {model.metrics_names[2]} of {scores[2]}; {model.metrics_names[3]} of {scores[3]}; {model.metrics_names[4]} of {scores[4]} %')\n",
    "    f1_per_fold.append(scores[4])\n",
    "    recall_per_fold.append(scores[3])\n",
    "    precision_per_fold.append(scores[2])\n",
    "    acc_per_fold.append(scores[1])\n",
    "    loss_per_fold.append(scores[0])\n",
    "    \n",
    "    #Increase fold number\n",
    "    fold_number = fold_number + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score per fold\n",
      "-----------\n",
      "> Fold 1 - Loss: 0.015652945265173912 - Accuracy: 0.9975422620773315 - Precision: 0.5660622715950012 - Recall: 0.6528862714767456 - F1: 0.5739668011665344%\n",
      "-----------\n",
      "> Fold 2 - Loss: 0.0160928163677454 - Accuracy: 0.9975723028182983 - Precision: 0.5760685801506042 - Recall: 0.6384505033493042 - F1: 0.5769012570381165%\n",
      "-----------\n",
      "> Fold 3 - Loss: 0.015897518023848534 - Accuracy: 0.997536838054657 - Precision: 0.5419842600822449 - Recall: 0.6222488880157471 - F1: 0.5513389110565186%\n",
      "-----------\n",
      "> Fold 4 - Loss: 0.01571137271821499 - Accuracy: 0.9976025819778442 - Precision: 0.5791258811950684 - Recall: 0.6506590843200684 - F1: 0.5838152170181274%\n",
      "-----------\n",
      "> Fold 5 - Loss: 0.016536895185709 - Accuracy: 0.9975120425224304 - Precision: 0.5547494888305664 - Recall: 0.6376579999923706 - F1: 0.566363513469696%\n",
      "------------\n",
      "Average scores for all folds:\n",
      "> Accuracy: 0.9975532054901123 (+- 3.1256316544471746e-05)\n",
      "> Precision: 0.563598096370697 (+- 0.013770642695940142)\n",
      "> Recall: 0.6403805494308472 (+- 0.010972108843352455)\n",
      "> F1: 0.5704771399497985 (+- 0.011086433544130117)\n",
      "> Loss: 0.015978309512138366\n",
      "------------\n"
     ]
    }
   ],
   "source": [
    "print('Score per fold')\n",
    "for i in range(0, len(acc_per_fold)):\n",
    "    print(\"-----------\")\n",
    "    print(f'> Fold {i+1} - Loss: {loss_per_fold[i]} - Accuracy: {acc_per_fold[i]} - Precision: {precision_per_fold[i]} - Recall: {recall_per_fold[i]} - F1: {f1_per_fold[i]}%')\n",
    "print('------------')\n",
    "print('Average scores for all folds:')\n",
    "print(f'> Accuracy: {np.mean(acc_per_fold)} (+- {np.std(acc_per_fold)})')\n",
    "print(f'> Precision: {np.mean(precision_per_fold)} (+- {np.std(precision_per_fold)})')\n",
    "print(f'> Recall: {np.mean(recall_per_fold)} (+- {np.std(recall_per_fold)})')\n",
    "print(f'> F1: {np.mean(f1_per_fold)} (+- {np.std(f1_per_fold)})')\n",
    "print(f'> Loss: {np.mean(loss_per_fold)}')\n",
    "print('------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
